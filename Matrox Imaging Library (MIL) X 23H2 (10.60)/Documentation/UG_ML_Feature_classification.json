[{
  "id": "UG_ML_Feature_classification",
  "version": "2024020714",
  "title": "Feature classification",
  "subTitles": null,
  "location": "MIL UG P08: Machine learning tasks",
  "pageURL": "content\\UserGuide\\ML_Feature_classification\\ChapterInformation.htm",
  "text": " Chapter 55: Feature classification This chapter explains how to perform feature classification using machine learning with the MIL Classification module. Feature classification overview Steps to perform feature classification Perform all required allocations Build and populate your dataset Train your classifier context Predict with your classifier Save your classification contexts Free your allocated objects Building a dataset for feature classification Create your dataset context Populate the source dataset context Splitting your dataset Augmentation and other data preparations Exporting and importing a dataset Export Import Classifier and training settings for feature classification Setting up a classifier Feature importance Modes Proximity matrix Class weights Training and analysis for feature classification Hook functions Train your classifier Results Training analysis Confusion matrix Feature importance Proximity matrix Prediction for feature classification Prepare for prediction Predict Results Drawing Assisted labeling Feature classification example ",
  "wordCount": 138,
  "subEntries": [
    {
      "id": "UG_ML_Feature_classification_Feature_classification_overview",
      "version": null,
      "title": "Feature classification overview",
      "subTitles": null,
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Feature_classification\\Feature_classification_overview.htm",
      "text": " Feature classification overview This chapter explains how to perform feature classification using machine learning with the MIL Classification module. Note that this chapter expands on topics previously discussed in Machine learning fundamentals. It is recommended to review these topics if you have not already done so. For the most recent documentation of this chapter, particularly as it relates to statistical analysis (MclassStatCalculate()), check for an updated version of the MIL Help online at zebra.com/aurora-imaging-library-help. Feature classification allows you to classifying numerical data; it requires a tree ensemble classifier context that must be trained with a features dataset. An example of feature classification is identifying a type of blob (such as a circle, rectangle, or triangle), given a set of values (such as area and perimeter blob features). In such cases, the classifier learns to identify the blob shape, given a set of blob feature values. Although not required, what you are classifying, and the features used for training, typically traces back to an image, as shown here. For training purposes, you must feed the classifier numerous sets of feature values, such as convex hull, elongation, and perimeter. Each set is an entry in a features dataset and must be labeled with the class that represents the data. For example, you could have 3 classes called Circle, Rectangle, and Triangle. In your dataset, you would provide hundreds of entries that contain feature values (such as convex hull, elongation, and perimeter) and each of those entries would have the label of the class (shape) those features represent. By taking in the labeled sets of feature values, the classifier learns the criteria with which to split the data, node by node, until it is able to properly identify the class that best represents that data (the feature values). Once such a classifier is trained, it should be able to properly identify any similar data that you give it. Feature classification overview ",
      "wordCount": 320,
      "subEntries": []
    },
    {
      "id": "UG_ML_Feature_classification_Steps_to_perform_feature_classification",
      "version": null,
      "title": "Steps to perform feature classification",
      "subTitles": [
        "Perform all required allocations",
        "Build and populate your dataset",
        "Train your classifier context",
        "Predict with your classifier",
        "Save your classification contexts",
        "Free your allocated objects"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Feature_classification\\Steps_to_perform_feature_classification.htm",
      "text": " Steps to perform feature classification The following steps provide a basic methodology to perform feature classification with the MIL Classification module. Perform all required allocations. Build and populate your dataset. Train your classifier context. Predict with your classifier. If necessary, Save your classification contexts. Free your allocated objects. Perform all required allocations These allocations are required to perform feature classification. In many cases, some of these allocations will be imported or restored from previous work, using MclassImport() or MclassRestore(). Allocate a tree ensemble classifier context, using MclassAlloc() with M_CLASSIFIER_TREE_ENSEMBLE. Note, MclassTrain() can automatically allocate a classifier context if none is specified. Allocate a features dataset context to hold all of your data (source dataset), using MclassAlloc() with M_DATASET_FEATURES. Alternatively, you can restore an features dataset context, using MclassRestore(), or you can import data into a features dataset context, using MclassImport(). Allocate a tree ensemble training context, using MclassAlloc() with M_TRAIN_TREE_ENSEMBLE. A training context holds the settings with which to train a classifier context. Allocate a tree ensemble training result buffer to hold training results, using MclassAllocResult() with M_TRAIN_TREE_ENSEMBLE_RESULT. Allocate a tree ensemble result buffer to hold the prediction results, using MclassAllocResult() with M_PREDICT_TREE_ENSEMBLE_RESULT. Object allocation for feature classification is summarized in the table below: MIL allocation Classifier context M_CLASSIFIER_TREE_ENSEMBLE Specific predefined classifier context None Dataset context M_DATASET_FEATURES Data preparation context None Training context M_TRAIN_TREE_ENSEMBLE Training result buffer M_TRAIN_TREE_ENSEMBLE_RESULT Prediction result buffer M_PREDICT_TREE_ENSEMBLE_RESULT Build and populate your dataset If you restore or import a dataset that is fully built, you can skip this step. Otherwise, follow the steps below to build and populate the source dataset. Add class definitions to the source dataset, using MclassControl() with M_CLASS_ADD. Note, the number of classes with which to categorize your data is a key decision to make when performing feature classification. Optionally, you can specify settings to help manage class definitions, using MclassControl(). For example, you can assign a color (M_CLASS_DRAW_COLOR) and an icon image (M_CLASS_ICON_ID) to class definitions. This allows you to draw and visually identify them with MclassDraw(). Add entries to the source dataset, using MclassControl() with M_ENTRY_ADD. Entries in a features dataset require feature data (numerical values in an array). To specify the entry's feature data, use MclassControlEntry() with M_RAW_DATA. For each entry, specify the class definition (ground truth) that is represented, using MclassControlEntry() with M_CLASS_INDEX_GROUND_TRUTH. This step is known as labeling your data. After you build a dataset, you can export it using MclassExport() so you can train a classifier with it at a later time. You can use MclassImport() to import previously defined and exported datasets. You must label your data before training (labeled data is a prerequisite to using the module). The quality, quantity, and proportionality of correctly labeled data is critical to building a good dataset, and developing a properly trained classifier. Optionally, create a development and testing dataset out of your source dataset using MclassSplitDataset(). A development dataset is not required for the training of a tree ensemble classifier, and typically only the training dataset is used. After you build a dataset, you can export it using MclassExport() so you can train a classifier with it at a later time. You can use MclassImport() to import previously defined and exported datasets. Train your classifier context To train your classifier context on your datasets, perform the following: Modify training settings, using MclassControl() and MclassControlEntry(). Optionally, hook functions to training events, using MclassHookFunction(). Preprocess the training context, using MclassPreprocess(). Perform the training operation, using MclassTrain(). Optionally, get information about training events that caused the hook-handler function to execute, using MclassGetHookInfo(). If results indicate that the current training operation will be unsuccessful, stop the training, and modify your training settings and if necessary your dataset, and re-train. Optionally, get training results, using MclassGetResult(). As indicated in the previous step, if results indicate an unsuccessful training, modify your training settings and if necessary your dataset, and re-train. Copy the classification result buffer that MclassTrain() produced into a classifier context, using MclassCopyResult(). Once copied, the classifier context is considered trained. If your training results are unsatisfactory, adjust training settings, contexts, and datasets as required, and call MclassTrain() with the trained classifier context. Predict with your classifier To predict with the trained classifier context, perform the following: Preprocess the trained classifier context, using MclassPreprocess(). Perform the prediction operation with the trained classifier context and the target data that you want to classify, using MclassPredict(). If you are predicting with a test dataset and the predicted classes are not what you expect, when compared to the actual classes in the test dataset (the ground truth), you can adjust your training setup, and continue the training process. Optionally, you can perform the prediction operation with a dataset as your target. In this case, you can hook functions to prediction events, using MclassHookFunction(). Retrieve the required results from the prediction result buffer, using MclassGetResult(). Save your classification contexts If necessary, save your classification contexts, using MclassSave() or MclassStream(). Free your allocated objects Free all your allocated objects, using MclassFree(), unless M_UNIQUE_ID was specified during allocation. Steps to perform feature classification Perform all required allocations Build and populate your dataset Train your classifier context Predict with your classifier Save your classification contexts Free your allocated objects ",
      "wordCount": 872,
      "subEntries": []
    },
    {
      "id": "UG_ML_Feature_classification_Building_a_dataset_for_feature_classification",
      "version": null,
      "title": "Building a dataset for feature classification",
      "subTitles": [
        "Create your dataset context",
        "Populate the source dataset context",
        "Splitting your dataset",
        "Augmentation and other data preparations",
        "Exporting and importing a dataset",
        "Export",
        "Import"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Feature_classification\\Building_a_dataset_for_feature_classification.htm",
      "text": " Building a dataset for feature classification For an overview of the many considerations you should make when building a dataset, see Chapter 48: Datasets. Create your dataset context Allocate a dataset context to hold all of your image data (source dataset), using MclassAlloc() with M_DATASET_FEATURES. Populate the source dataset context Add class definitions to the source dataset, using MclassControl() with M_CLASS_ADD. These are the classes that will be represented in your dataset. Optionally, you can specify settings to help manage class definitions, using MclassControl(). For example, you can assign a color (M_CLASS_DRAW_COLOR) and an icon image (M_CLASS_ICON_ID) to class definitions. This allows you to draw and visually identify them with MclassDraw(). Add entries to the source dataset, using MclassControl() with M_ENTRY_ADD. Each entry must refer to a set of features (an array of values) and must identify its ground truth (the class label that identifies the entry). Specify a set of features for an entry using MclassControlEntry() with M_RAW_DATA. Although there is no realistic limit on the number of feature values that you can provide, or what they represent, every entry must have the same number of feature values, and they must be in the same order. For example, if entry 0 specifies three feature values, and the first is length, the second is width, and the third is height, then every entry must specify those three values in that order. While the feature values might trace back back to an image, the image itself is not included in a features dataset. Set the class label for each entry using MclassControlEntry() with M_CLASS_INDEX_GROUND_TRUTH. The table below illustrates the components of a features dataset. Entry Features Label Entry 0 Feature 0 (length), Feature 1 (width), Feature 2 (height) Class 0 Entry 1 Feature 0 (length), Feature 1 (width), Feature 2 (height) Class 1 Entry 2 Feature 0 (length), Feature 1 (width), Feature 2 (height) Class 0 Splitting your dataset When training for feature classification, the development dataset is optional. Typically, only the training dataset is used. MIL uses bootstrap aggregating to train such classifiers and, inherent to this process, is a bagging technique, which randomly selects the dataset entries with which to train (in-the-bag) and the dataset entries with which to regulate the training (out-of-bag). For more information, see the Tree ensemble classifier subsection of the Classifiers, what they are and what they do section of Chapter 47: Machine learning with the MIL Classification module. You can call MclassSplitDataset() to split a portion of your dataset into the development and testing datasets prior to training if you want to use them. Augmentation and other data preparations Augmentation and preparation with MclassPrepareData() is not supported for a features dataset. An entry in a features dataset can still be augmented by other means. For example, if one of the features (numerical values) in a dataset entry refers to the width of a blob, you can add entries that are a certain percentage bigger or smaller. Those additional entries should be considered augmented. Additionally, entries in a features dataset could have been added from a blob analysis that you performed on images. If some of those images were augmented, then the corresponding features should be considered augmented also. Note that you should only allow entries with augmented features in the training dataset. Exporting and importing a dataset Exporting and importing your datasets allows you to make your datasets portable and organized. This will allow you to easily reuse or combine your datasets. For more information about importing data, see the Importing data from a folder or CSV file section of Chapter 48: Datasets. Export After you build a dataset, export it using MclassExport(). It is recommended that you export it with M_FORMAT_CSV. To export the entire dataset, call the function three times with M_AUTHORS, M_CLASS_DEFINITIONS, and M_ENTRIES. Import You can import a features dataset from a CSV file into a dataset context by calling MclassImport() and specifying what to import (for example, M_AUTHORS, M_CLASS_DEFINITIONS, and M_ENTRIES). You will typically be importing data that was previously exported from MIL. You can also use MclassRestore() to restore a dataset that was previously saved to a file using MclassSave() or MclassStream(). Building a dataset for feature classification Create your dataset context Populate the source dataset context Splitting your dataset Augmentation and other data preparations Exporting and importing a dataset Export Import ",
      "wordCount": 726,
      "subEntries": []
    },
    {
      "id": "UG_ML_Feature_classification_Classifier_and_training_settings_for_feature_classification",
      "version": null,
      "title": "Classifier and training settings for feature classification",
      "subTitles": [
        "Setting up a classifier",
        "Feature importance",
        "Modes",
        "Proximity matrix",
        "Class weights"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Feature_classification\\Classifier_and_training_settings_for_feature_classification.htm",
      "text": " Classifier and training settings for feature classification Before you can start training, you need to allocate a classifier context and training objects, and set training-related settings. Allocate a training context, using MclassAlloc() with M_TRAIN_TREE_ENSEMBLE. A training context holds the settings with which to train a classifier context, such as training modes. You will also need to allocate a classification result buffer to hold training results, using MclassAllocResult() with M_TRAIN_TREE_ENSEMBLE_RESULT. Setting up a classifier Allocate a tree ensemble classifier context by calling MclassAlloc() with M_CLASSIFIER_TREE_ENSEMBLE. When you allocate a tree ensemble classifier context, it is essentially empty and ready for training. By default, the tree ensemble uses 10 trees and has no maximum depth (there is no limit to the number of levels a tree can have). To modify these training settings, and others that affect the internal architecture of the tree ensemble, call MclassControl() and specify the tree ensemble training context. By default, MIL uses a bootstrap aggregating (bagging) process to train the tree ensemble. You can call MclassControl() and specify the tree ensemble training context to adjust that process. For example, you can decide whether randomly selected entries are available for reselection (whether to bootstrap with or without replacement) or whether to use out-of-bag dataset entries to estimate the generalization accuracy. Note, bagging information is typically unreliable if your training dataset has augmented entries. Also note that, you can either train a tree ensemble classifier from the ground up (using an empty tree ensemble classifier context), or you can continue training a previously trained tree ensemble classifier (this is referred to as a warm start). To continue training a previously trained tree ensemble classifier, you must copy the classification result buffer that MclassTrain() produced into a classifier context, using MclassCopyResult(), and then pass that trained tree ensemble context back to MclassTrain(). Feature importance For feature classification, every entry in a features dataset refers to a set of features. For example, every entry can refer to a set of blob features, such as area, perimeter, and Feret diameter. Specific values for these features are specified, for each entry, using MclassControlEntry() with M_RAW_DATA. By specifying a feature importance mode, MIL establishes, during training, whether certain features are more important than others in determining the class to which the input data belongs. For example, the perimeter feature can end up being very important to establishing a successful classification, while the area feature can end up being almost irrelevant. To specify (or disable) the feature importance mode, call MclassControl() with M_FEATURE_IMPORTANCE_MODE. M_FEATURE_IMPORTANCE_MODE does not directly affect training. It allows you to retrieve which features are more important; you can then use this information to modify your dataset (for example, you can specify only the important features) and retrain. Modes By default, MIL uses a decreasing impurity process (M_MEAN_DECREASE_IMPURITY) to establish the feature importance. In this case, the more a feature affects a proper node splitting, the more important it is. Proper splitting means that the two output sets resulting from splitting the node are (on average) significantly purer (closer to agreeing on the final class) than the node's input set. Alternatively you can use a drop column or permutation process to establish the feature importance. With a drop column process, the more the elimination of a feature affects accuracy, the more importance that feature is given. With a permutation process, the more the shuffling of a feature affects accuracy, the more importance that feature is given. To specify a drop column or permutation importance, you must train with a development dataset or compute out-of-bag results (that is, enable M_COMPUTE_OUT_OF_BAG_RESULTS). To specify the set with which to calculate a drop column or permutation importance, use M_FEATURE_IMPORTANCE_SET. In general, the fastest modes with which to establish the feature importance are M_MEAN_DECREASE_IMPURITY, M_PERMUTATION, and M_DROP_COLUMN, while the modes with which to most accurately establish the feature importance are M_DROP_COLUMN, M_PERMUTATION, and M_MEAN_DECREASE_IMPURITY. Note, if you disable the feature importance mode, you cannot retrieve any information about the feature importance. Proximity matrix The proximity measure matrix tells you a measure of the similarity between pairs of entries in your training dataset, based on the terminal nodes of the decision trees. For example, if entries i and j are in the same terminal node, their proximity increases. To calculate the proximity measure matrix when building trees, you must enable M_COMPUTE_PROXIMITY_MATRIX with MclassControl(). Class weights You can control how the class weights are set in your training context by calling MclassControl() with M_CLASS_WEIGHT_MODE. The default setting for feature classification is M_BALANCE, which adjusts the weights for each class to be inversely proportional to the frequency of the class in the training dataset. If you need more control over the weights for each class, you can manually set the weight factor for each class using M_USER_DEFINED and M_CLASS_WEIGHT. For more information about class weights, see the Class weights subsection of the Fundamental decisions and settings section of Chapter 49: Training. Once you have established your training settings for your training context, you must preprocess the context by calling MclassPreprocess() with the identifier of the training context. Classifier and training settings for feature classification Setting up a classifier Feature importance Modes Proximity matrix Class weights ",
      "wordCount": 866,
      "subEntries": []
    },
    {
      "id": "UG_ML_Feature_classification_Training_and_analysis_for_feature_classification",
      "version": null,
      "title": "Training and analysis for feature classification",
      "subTitles": [
        "Hook functions",
        "Train your classifier",
        "Results",
        "Training analysis",
        "Confusion matrix",
        "Feature importance",
        "Proximity matrix"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Feature_classification\\Training_and_analysis_for_feature_classification.htm",
      "text": " Training and analysis for feature classification Once you have established your training related settings, your classifier can be trained. For more information on the training process, and training analysis, see the Analysis, adjustment, and additional settings section of Chapter 49: Training. Hook functions You can save time and improve the training process by using MclassHookFunction() to hook a function to a training event. Call MclassGetHookInfo() to get information about the event that caused the hook-handler function to be called. Training can take a long time, and you can use hook functions to monitor the training process. Train your classifier When you call MclassTrain(), the classifier context will be trained with the settings specified in the training context, and trained using the data in the training dataset and development dataset, if one is specified. The results from training will be stored in the classification result buffer. These must all be specified when you call MclassTrain(). If you are not using a development dataset, set the DevDatasetContextClassId to M_NULL. MIL will not automatically split your dataset into a development dataset when training a tree ensemble classifier. This must be done explicitly with MclassSplitDataset(). While your classifier is training, you can get the information from the events that caused the hook-handler function to execute by using MclassGetHookInfo(). Typically, you should expect to monitor the training process for proper convergence, and to make modifications to the process. You might need to abort or restart it, if required. Results After training is completed, retrieve your training results by calling MclassGetResult() with the training result buffer that MclassTrain() produced. You will often get results related to accuracy, such as the accuracy of the training dataset (M_TRAIN_DATASET_ACCURACY), the development dataset (M_DEV_DATASET_ACCURACY) and the out-of-bag set (M_OUT_OF_BAG_ACCURACY). The out-of-bag accuracy represents the generalizability of the classifier on data not seen during training. You can also get training results from a specific entry in the training, development, or out-of-bag dataset by calling MclassGetResultEntry(). To do this, you must first copy the dataset results from the result buffer that MclassTrain() produces to a dataset using MclassCopyResult(). If your training results are not as you expected (for example, if the classifier is clearly performing poorly by over-fitting to the development dataset), then you can make adjustments and train again. Copy the classification result buffer into a classifier context, using MclassCopyResult() with M_TRAINED_CLASSIFIER. Once copied, the classifier context is considered trained. If necessary, you can always continue to adjust training settings and contexts, and call MclassTrain() with the trained classifier context. Training analysis Analyzing your training results is critical to building a well-performing classifier. Based on the result information, you can modify your dataset and set of features and retrain, which can help improve the tree ensemble classifier's performance and accuracy. Confusion matrix A confusion matrix tells you information about how many entries were correctly and incorrectly classified during training in the training or development dataset. It can be used to identify weaknesses in your classifier, particularly when dealing with an unbalanced dataset. To retrieve the confusion matrix, call MclassGetResult() with M_TRAIN_DATASET_CONFUSION_MATRIX, M_DEV_DATASET_CONFUSION_MATRIX, or M_OUT_OF_BAG_CONFUSION_MATRIX. Feature importance To retrieve the importance of features, call MclassGetResult() with M_FEATURE_IMPORTANCE. Proximity matrix To retrieve the proximity measure matrix, call MclassGetResult() with M_PROXIMITY_MATRIX. Training and analysis for feature classification Hook functions Train your classifier Results Training analysis Confusion matrix Feature importance Proximity matrix ",
      "wordCount": 559,
      "subEntries": []
    },
    {
      "id": "UG_ML_Feature_classification_Prediction_for_feature_classification",
      "version": null,
      "title": "Prediction for feature classification",
      "subTitles": [
        "Prepare for prediction",
        "Predict",
        "Results",
        "Drawing",
        "Assisted labeling"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Feature_classification\\Prediction_for_feature_classification.htm",
      "text": " Prediction for feature classification MclassPredict() uses a trained classifier context to make class predictions on a target. For a trained tree ensemble classifier, your target is either a set of features, or a features dataset. For more information about prediction, see the Prediction settings, results, and drawings section of Chapter 50: Prediction. Prepare for prediction Allocate a classification result buffer to hold the prediction results, using MclassAllocResult() with M_PREDICT_TREE_ENSEMBLE_RESULT. Before predicting, preprocess your trained classifier context using MclassPreprocess(). Predict Perform the prediction operation with the trained classifier context and the target data that you want to classify using MclassPredict(). Note, if you have a testing dataset, you should predict with it, using MclassPredict(). As previously discussed, predicting with a testing dataset serves as a quarantined final check for your trained classifier. If the results are what you expect (they should be approximately the same as your training results), you can continue with prediction using your trained classifier. If the results are not what you expect, it is a sign that you should continue training. When performing the prediction operation with a dataset as your target, you can hook functions to prediction events, using MclassHookFunction(). To prevent the classification process from taking too long, you can set a maximum calculation time for MclassPredict(), by calling MclassControl() with M_TIMEOUT. You can also stop the current execution of MclassPredict() (from another thread of higher priority), by specifying M_STOP_PREDICT. Results Retrieve the required results from the classification result buffer, using MclassGetResult(). You can also get results from a specific entry in a dataset using MclassGetResultEntry(). Typically, the most important prediction results to retrieve are the best predicted class (M_BEST_CLASS_INDEX) and its score (M_BEST_CLASS_SCORE). Drawing For feature classification, you can only specify drawing operations for a dataset context (for example, M_DRAW_CLASS_ICON). You cannot draw prediction results. Assisted labeling To perform assisted labeling on your dataset, call MclassPredict() with a trained classifier context and a target dataset context. After prediction, you need to add the new labels within your dataset. Set the ground truth of an entry (M_CLASS_INDEX_GROUND_TRUTH) to the predicted label from MclassGetResultEntry(). For more information about assisted labeling, see the Assisted labeling subsection of the Advanced techniques section of Chapter 50: Prediction. Prediction for feature classification Prepare for prediction Predict Results Drawing Assisted labeling ",
      "wordCount": 382,
      "subEntries": []
    },
    {
      "id": "UG_ML_Feature_classification_Feature_classification_example",
      "version": null,
      "title": "Feature classification example",
      "subTitles": null,
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Feature_classification\\Feature_classification_example.htm",
      "text": " Feature classification example The example ClassTreeEnsembleTrain.cpp demonstrates how to use blob feature values to train a tree ensemble classifier to classify different shapes. The example also demonstrates how this method can be used to classify digits. To run this example, use the Matrox Example Launcher in the MIL Control Center. To view this example, refer to the following: classtreeensembletrain.cpp Feature classification example ",
      "wordCount": 64,
      "subEntries": []
    }
  ]
}]