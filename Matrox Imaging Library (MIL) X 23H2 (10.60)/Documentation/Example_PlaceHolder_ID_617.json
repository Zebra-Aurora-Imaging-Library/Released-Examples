[{
  "id": "Example_PlaceHolder_ID",
  "version": "2023100322",
  "title": "Example_PlaceHolder_Title",
  "wordCount": 0,
  "subEntries": [
    {
      "id": "Examples_BoardSpecific_clarityuhd_MultiCameraDisplay_CPP_mdighandler_cpp",
      "version": "2023100322",
      "title": "mdighandler.cpp",
      "location": "Sample Code from MIL Examples",
      "text": " Top /***************************************************************************************/ /* * File name: MdigHandler.cpp * Location: See Matrox Example Launcher in the MIL Control Center * * * Synopsis: The digitizer handler is used to manage MIL digitizers, buffers and * displays. * It handles the start and stop of the grab using MdigProcess. * The grabbed buffers are sent to the associated display in the callback function. * * Copyright (C) Matrox Electronic Systems Ltd., 1992-2023. * All Rights Reserved */ #include &lt;mil.h&gt; #include &lt;iomanip&gt; #include &lt;algorithm&gt; using namespace std; #include \"MdigHandler.h\" // utility function to round up an integer to the next multiple. template&lt;typename T&gt; T roundUp(T numToRound, size_t multiple) { if (multiple == 0) return numToRound; T remainder = numToRound % multiple; if (remainder == 0) return numToRound; return numToRound + T(multiple) - remainder; } #if M_MIL_UNICODE_API #include &lt;codecvt&gt; #endif // wrapper function to convert std::string to MIL_STRING. MIL_STRING str2Mstr(const std::string&amp; str) { #if M_MIL_UNICODE_API std::wstring_convert&lt;std::codecvt_utf8&lt;wchar_t&gt;, wchar_t&gt; converterX; return converterX.from_bytes(str); #else return str; #endif } // wrapper function to convert MIL_STRING to std::string. std::string Mstr2str(const MIL_STRING&amp; milstr) { #if M_MIL_UNICODE_API std::wstring_convert&lt;std::codecvt_utf8&lt;wchar_t&gt;, wchar_t&gt; converterX; return converterX.to_bytes(milstr); #else return milstr; #endif } // Function to allocate a MIL digitizer with the default DCF. // returns true on success. bool CMILDigitizerHandler::DigAlloc() { _pixelFormatString.clear(); MdigAlloc(_milSystemId, _digDevNum, GetDCFName().c_str(), M_DEFAULT, &amp;_milDigitizerId); if (_milDigitizerId) { MdigInquire(_milDigitizerId, M_SIZE_BAND, &amp;_sizeBand); MdigInquire(_milDigitizerId, M_SIZE_X, &amp;_sizeX); MdigInquire(_milDigitizerId, M_SIZE_Y, &amp;_sizeY); if (MdigInquire(_milDigitizerId, M_CAMERA_PRESENT, M_NULL) == M_NO) { MdigFree(_milDigitizerId); _milDigitizerId = M_NULL; _inputDescription.clear(); _inputDescriptionBrief.clear(); } // Disable MdigProcess grab monitor since disconnecting a camera will result in an // error message. MdigControl(_milDigitizerId, M_PROCESS_GRAB_MONITOR, M_DISABLE); if (_pdisplay &amp;&amp; (_tileId == 0)) { _tileId = _pdisplay-&gt;TileAlloc(int(_sizeX), int(_sizeY)); std::stringstream tilestr; tilestr &lt;&lt; GetInputDescriptionBrief().c_str(); _pdisplay-&gt;TileIdentificationString(_tileId, tilestr.str().c_str()); } } return (_milDigitizerId ? true : false); } // Function to free an allocated digitizer with all the associated buffers. void CMILDigitizerHandler::DigFree() { _pixelFormatString.clear(); // Free tiles. if (_pdisplay &amp;&amp; _tileId) _pdisplay-&gt;TileFree(_tileId); _tileId = 0; if (_milDigitizerId) { if (_isGrabbing) StopGrab(); MdigControl(_milDigitizerId, M_GC_FEATURE_BROWSER, M_CLOSE); MdigFree(_milDigitizerId); } // Free buffers. FreeBuffers(); _inputDescription.clear(); _inputDescriptionBrief.clear(); _milDigitizerId = M_NULL; _pdisplay = NULL; } // Function to allocate a MIL buffer for direct display grabbing. void CMILDigitizerHandler::AllocateBuffer(eBUFFER_MAPPING mapping, PIXEL_FORMAT pixelFormat, MIL_INT sizeBand, MIL_INT dynamicSizeByte, MIL_ID &amp;milBuffer, int &amp;gpuBuffer) { MIL_INT64 Attribute = 0; MIL_INT sizeX = _sizeX; MIL_INT sizeY = _sizeY; // find equivalent MIL attribute from pixelFormat. switch (pixelFormat) { case eMono8: Attribute = 0; break; case eYUV422: Attribute = M_YUV16 + M_PACKED; break; case eYUV422_10p: Attribute = M_DYNAMIC; break; case eRGB24_planar: Attribute = M_RGB24 + M_PLANAR; break; case eBGR32: Attribute = M_BGR32 + M_PACKED; break; case eBGRa10p: Attribute = M_DYNAMIC; break; case eYUV411_8p: Attribute = M_DYNAMIC; break; default: break; } if ((Attribute &amp; M_DYNAMIC) &amp;&amp; dynamicSizeByte == 0) { MosPrintf(MIL_TEXT(\"Buffer allocation error when allocate DYNAMIC buffer on dig num %d. \\n\"), _digDevNum); return; } // MIL buffer mapped on GPU. if (mapping == eMIL_BUFFER_MAPPED_ON_A_GPU_BUFFER) { void *pHostAddress[3] = { NULL, NULL, NULL }; int pitchByte = 0; gpuBuffer = _pdisplay-&gt;BufAlloc(int(sizeX), int(sizeY), pixelFormat, &amp;pitchByte, pHostAddress); if (gpuBuffer) { // Map MIL buffer on GPU buffer. MbufCreateColor(_milSystemId, sizeBand, sizeX, sizeY, 8, M_IMAGE + M_PROC + M_GRAB + M_PAGED + Attribute, M_HOST_ADDRESS + M_PITCH_BYTE, pitchByte, pHostAddress, &amp;milBuffer); if (milBuffer == M_NULL) { // Cannot map MIL buffer so free gpu buffer. _pdisplay-&gt;BufFree(gpuBuffer); gpuBuffer = 0; } } } else if (mapping == eGPU_BUFFER_MAPPED_ON_A_MIL_BUFFER) { // Allocate MIL buffer aligned on 4K memory because GPUs are more efficient this way. auto pitchPixel = sizeX; if (dynamicSizeByte) { MbufAlloc1d(_milSystemId, dynamicSizeByte, 8, M_IMAGE + M_GRAB + M_DYNAMIC, &amp;milBuffer); } else { MIL_INT _4KAlignement = (M_ALIGNMENT_RESERVED_BITS &amp; 0xA); MbufCreateColor(_milSystemId, sizeBand, sizeX, sizeY, 8, M_IMAGE + M_PROC + M_GRAB + Attribute, M_ALLOCATION + M_PITCH + _4KAlignement, pitchPixel, NULL, &amp;milBuffer); if (milBuffer == M_NULL) { // if allocation failed... try again with pitch multiple of 128 (some GPUs are more restrictive then others). pitchPixel = MIL_INT(roundUp(sizeX, 128)); MbufCreateColor(_milSystemId, sizeBand, sizeX, sizeY, 8, M_IMAGE + M_PROC + M_GRAB + Attribute, M_ALLOCATION + M_PITCH + _4KAlignement, pitchPixel, NULL, &amp;milBuffer); } } // Now map a GPU buffer on top of the MIL buffer. if (milBuffer) { void *pHostAddress[3] = { NULL, NULL, NULL }; MIL_INT pitchByte = 0; // Inquire host address MbufInquire(milBuffer, M_HOST_ADDRESS, pHostAddress); if (pixelFormat == eYUV411_8p) { // In 2 band YUV420 the second plane starts at the next 4k address. pitchByte = roundUp(int(_sizeX), 128); auto plane1address = ((MIL_INT64)pHostAddress[0]) + (pitchByte * sizeY); pHostAddress[1] = (void *)roundUp(plane1address, 0x1000); } // If the host address is null then we must get the address for each plane. if (pHostAddress[0] == NULL) for (int ii = 0; ii &lt; sizeBand; ii++) { MIL_ID bandID; MIL_INT bandValue[3] = { M_RED, M_GREEN, M_BLUE }; MbufChildColor(milBuffer, bandValue[ii], &amp;bandID); MbufInquire(bandID, M_HOST_ADDRESS, &amp;pHostAddress[ii]); MbufFree(bandID); } MbufInquire(milBuffer, M_PITCH_BYTE, &amp;pitchByte); // now create the GPU buffer with our host address. gpuBuffer = _pdisplay-&gt;BufCreate(int(sizeX), int(sizeY), pixelFormat, int(pitchByte), pHostAddress); } } else if ((mapping == eMIL_BUFFER_HOST) || (mapping == eMIL_BUFFER_ON_BOARD)) { bool isOnBoard = (mapping == eMIL_BUFFER_ON_BOARD) ? true : false; if (dynamicSizeByte) MbufAlloc1d(_milSystemId, dynamicSizeByte, 8, M_IMAGE + M_GRAB + M_DYNAMIC + (isOnBoard?M_ON_BOARD:0), &amp;milBuffer); else MbufAllocColor(_milSystemId, sizeBand, sizeX, sizeY, 8, M_IMAGE + M_GRAB + Attribute + (isOnBoard ? M_ON_BOARD : M_PROC), &amp;milBuffer); } } // Function to allocate grab buffers with their associated display buffer. // The buffers are either: // 1: allocated by the GPU and then MIL buffers are mapped on them. // 2: allocated by MIL and GPU buffers mapped on the MIL buffers. // 3: allocated in frame grabber memory and copied in a GPU buffer (optimized for encoding). void CMILDigitizerHandler::AllocateBuffers() { // Free allocated buffers (if any). FreeBuffers(); // Alloc buffers. MIL_INT dynamicBufferSizeByte = 0; // sizeX must be multiple of 4; _sizeX = roundUp(int(_sizeX), 4); auto grabPixelFormat = _pixelFormat; // if the pixel format is not supported, change it! { auto pixelFormats = SupportedPixelFormats(); auto ispixelFormatSupported = (std::find(pixelFormats.begin(), pixelFormats.end(), _pixelFormat) != pixelFormats.end()); if (!ispixelFormatSupported) grabPixelFormat = *pixelFormats.begin(); } auto sizeBand = _sizeBand; // If mono digitizer, force mono buffers. if (sizeBand == 1) grabPixelFormat = eMono8; if (grabPixelFormat == eMono8) sizeBand = 1; // Set M_PFNC_TARGET_FORMAT for PFNC buffers when calculate memory size. switch (grabPixelFormat) { case eYUV411_8p: // YUV420 8-bit packed. { MdigControl(GetDigId(), M_PFNC_TARGET_FORMAT, PFNC_YCbCr411_8); int pitchByte = roundUp(int(_sizeX), 128); dynamicBufferSizeByte = (pitchByte * _sizeY) + ((pitchByte *2) * (_sizeY / 2)) + 0x1000; // the uv plane must start on a multiple of 4k. } break; case eYUV422_10p: // YUV422 10-bit packed. { MdigControl(GetDigId(), M_PFNC_TARGET_FORMAT, PFNC_YCbCr422_10p); MIL_INT stride = ((_sizeX + 47) / 48) * 128; int pitchByte = roundUp(int(stride), 128); dynamicBufferSizeByte = pitchByte * _sizeY * 2; } break; case eBGRa10p: // BGR 10-bit packed. { MdigControl(GetDigId(), M_PFNC_TARGET_FORMAT, PFNC_BGRa10p); int pitchByte = roundUp(int(_sizeX), 128); dynamicBufferSizeByte = pitchByte * _sizeY * 4; } break; } int bufSize = 0; if (IsEncoding()) bufSize = _bufferingSizeWhenEncoding; else bufSize = _bufferingSizeWhenGrabbing; // Allocate the buffers for direct grabbing on display, processing and encoding. for (int i = 0; i &lt; bufSize; i++) { BUFFER buf; int gpuBuffer = 0; MIL_ID milBuffer = M_NULL; // case 1: For PFNC (M_DYNAMIC) buffers, we must first allocate the MIL buffer and then map the GPU buffer on it. if (dynamicBufferSizeByte) AllocateBuffer(eGPU_BUFFER_MAPPED_ON_A_MIL_BUFFER, grabPixelFormat, 1, dynamicBufferSizeByte, milBuffer, gpuBuffer); else { // Does the grabber support grabbing in paged memory? If yes the buffers are allocated in GPU memory and we create a MIL buffer on them. // case 2: MIL buffers mapped over GPU. if (IsGrabInPagedMemorySupported() &amp;&amp; _pdisplay-&gt;isAllocBufferSupported()) AllocateBuffer(eMIL_BUFFER_MAPPED_ON_A_GPU_BUFFER, grabPixelFormat, sizeBand, 0, milBuffer, gpuBuffer); // case 3: If previous case failed then try allocating GPU buffers mapped over MIL. if (milBuffer == M_NULL) AllocateBuffer(eGPU_BUFFER_MAPPED_ON_A_MIL_BUFFER, grabPixelFormat, sizeBand, 0, milBuffer, gpuBuffer); } // If the buffer was allocated, allocate another one to be used when we activate the processing or the encoding. if (milBuffer) { buf.dispid = gpuBuffer; buf.tileId = (int)_digDevNum; buf.pixelFormat = grabPixelFormat; buf.milGrabBufferForProcessing = M_NULL; buf.milGrabBufferMappedOnDisplay = milBuffer; MbufClear(buf.milGrabBufferMappedOnDisplay, M_COLOR_DARK_BLUE); // Allocate a grab buffer to be used for processing (planar is the most efficient format for processing). MbufAllocColor(_milSystemId, sizeBand, _sizeX, _sizeY, 8, M_IMAGE + M_GRAB + M_PROC, &amp;buf.milGrabBufferForProcessing); MbufClear(buf.milGrabBufferForProcessing, M_COLOR_DARK_BLUE); // Allocate a grab buffer to be used when encoding. if (IsEncoding()) { int gpuBufferNotUsed; if(_seqHandler.isH264Board()) AllocateBuffer(eMIL_BUFFER_ON_BOARD, grabPixelFormat, sizeBand, dynamicBufferSizeByte, buf.milGrabBufferForEncoding, gpuBufferNotUsed); else AllocateBuffer(eMIL_BUFFER_HOST, grabPixelFormat, sizeBand, dynamicBufferSizeByte, buf.milGrabBufferForEncoding, gpuBufferNotUsed); } _allocatedBuffers.push_back(buf); } else { MosPrintf(MIL_TEXT(\"Buffer allocation error on dig num %d.\\n\"), _digDevNum); break; } } } // Set the display to be used for the grabbed images. void CMILDigitizerHandler::SetDisplay(IMilDisplayEx *pdispOpenGL) { // Free current tile if display changes. if (_pdisplay &amp;&amp; _tileId &amp;&amp; _pdisplay != pdispOpenGL) { _pdisplay-&gt;TileFree(_tileId); _tileId = 0; } _pdisplay = pdispOpenGL; if (_pdisplay &amp;&amp; _tileId == 0) { _tileId = _pdisplay-&gt;TileAlloc(int(_sizeX), int(_sizeY)); std::stringstream tilestr; tilestr &lt;&lt; GetInputDescriptionBrief().c_str(); _pdisplay-&gt;TileIdentificationString(_tileId, tilestr.str().c_str()); SetOverlayText(GetInputDescriptionBrief()); } } // The functions frees all the grab and display buffers. void CMILDigitizerHandler::FreeBuffers() { // First stop the grab. if (_isGrabbing) StopGrab(); // Free buffers; for (auto iterBuf = _allocatedBuffers.begin(); iterBuf != _allocatedBuffers.end(); ++iterBuf) { if (_pdisplay) _pdisplay-&gt;BufFree(iterBuf-&gt;dispid); if (iterBuf-&gt;milGrabBufferForProcessing) MbufFree(iterBuf-&gt;milGrabBufferForProcessing); if (iterBuf-&gt;milGrabBufferForEncoding) MbufFree(iterBuf-&gt;milGrabBufferForEncoding); MbufFree(iterBuf-&gt;milGrabBufferMappedOnDisplay); } _allocatedBuffers.clear(); } // The function start the grab using MdigProcess. void CMILDigitizerHandler::StartGrab() { _pixelFormatString.clear(); _milDigProcessBuffers.clear(); _frameCountTotal = 0; _frameRateCurrent = 0.0; _startTime = 0; _skipNextDisplay = false; // Cannot grab if dig is not allocated. if ((_milDigitizerId == M_NULL) || (_pdisplay == nullptr)) return; // if buffers are not allocated then allocate them. if (_allocatedBuffers.size() == 0) AllocateBuffers(); if (_allocatedBuffers.size()) { _milDigProcessBuffers.clear(); _milDigProcessBufferMap.clear(); for (auto iterBuf = _allocatedBuffers.begin(); iterBuf != _allocatedBuffers.end(); ++iterBuf) { MIL_ID grabBuffer = M_NULL; // If we do not have a processing or encoding buffer, disable them. if (iterBuf-&gt;milGrabBufferForProcessing == M_NULL) _processing = false; if(iterBuf-&gt;milGrabBufferForEncoding == M_NULL) _encoding = false; if (MbufInquire(iterBuf-&gt;milGrabBufferMappedOnDisplay, M_EXTENDED_ATTRIBUTE, M_NULL) &amp; M_DYNAMIC) _processing = false; // cannot process in a M_DYNAMIC buffer. if (IsEncoding()) grabBuffer = iterBuf-&gt;milGrabBufferForEncoding; else if (IsProcessing()) grabBuffer = iterBuf-&gt;milGrabBufferForProcessing; else grabBuffer = iterBuf-&gt;milGrabBufferMappedOnDisplay; _milDigProcessBuffers.push_back(grabBuffer); // this map is used to retrieve the buffer structure in the dig process callback. #if !M_MIL_USE_LINUX _milDigProcessBufferMap[grabBuffer] = iterBuf._Ptr; #else _milDigProcessBufferMap[grabBuffer]= iterBuf.base(); #endif } // Start encoding engine. if (IsEncoding()) { MIL_DOUBLE frameRate; MdigInquire(_milDigitizerId, M_SELECTED_FRAME_RATE, &amp;frameRate); _seqHandler.SetFrameRate(frameRate); _seqHandler.Start(GetInputDescription(), _milDigProcessBuffers[0]); } _isGrabbing = true; MdigProcess(_milDigitizerId, &amp;_milDigProcessBuffers[0], MIL_INT(_milDigProcessBuffers.size()), M_START, M_DEFAULT, MILGrabCallbackFunction, this); } } // This function stops the grab. void CMILDigitizerHandler::StopGrab() { _isGrabbing = false; if (_milDigProcessBuffers.size()) MdigProcess(_milDigitizerId, &amp;_milDigProcessBuffers[0], MIL_INT(_milDigProcessBuffers.size()), M_STOP, M_DEFAULT, MILGrabCallbackFunction, this); // Stop encoding engine (it is ok to stop it even if it was not started). _seqHandler.Stop(); _milDigProcessBuffers.clear(); } // This function sets text on the overlay of the tile of the digitizer. void CMILDigitizerHandler::SetOverlayText(const MIL_STRING&amp; itext) { if (_tileId) _pdisplay-&gt;SetText(_tileId, Mstr2str(itext).c_str(), 10, 18); } // This function returns the text on the overlay of the tile of the digitizer. MIL_STRING CMILDigitizerHandler::GetOverlayText() const { char text[255] = { 0 }; _pdisplay-&gt;GetTile(_tileId, NULL, NULL, text, sizeof(text), NULL, NULL, NULL, NULL); return str2Mstr(text); } // The function returns a MIL_STRING containing the number of grabbed frames with the frame rate. const MIL_STRING&amp; CMILDigitizerHandler::GetGrabStats() { if (_allocatedBuffers.size() == 0) { _statText = MIL_TEXT(\"Not enough memory to allocate grab buffers.\"); } else { MIL_STRING_STREAM ss; ss &lt;&lt; _frameCountTotal &lt;&lt; MIL_TEXT(\" frames at \") &lt;&lt; std::setprecision(4) &lt;&lt; _frameRateCurrent &lt;&lt; MIL_TEXT(\" fps. \"); _statText = ss.str(); } return _statText; } // This function updates a MIL_STRING with the buffer format and color space. // The color space of YUV buffers are inquired after a grab is done // because the camera sets it. void CMILDigitizerHandler::UpdateBufferPixelFormat(BUFFER &amp;buf) { // We can only inquire the buffer pixel once the grab is started. The color space is set on the first grab. if (_pixelFormatString.size() == 0 &amp;&amp; _frameCountTotal &gt; 0) { MIL_ID bufId = buf.milGrabBufferMappedOnDisplay; MIL_INT64 Format = 0; // Get pixel format name. _pixelFormatString = str2Mstr(GetPixelFormatName((PfncFormat)buf.pixelFormat)); _bufferColorSpaceFormat = eCSC_FULL; // Inquire color space of YUV16 buffers (this is set after grab is done). MbufInquire(bufId, M_EXTENDED_FORMAT, &amp;Format); if (M_IS_FORMAT_YUV(Format) || buf.pixelFormat == PFNC_YCbCr422_10p || buf.pixelFormat == PFNC_YCbCr411_8) { MIL_INT CbCRRange = 0; MbufInquire(bufId, M_YCBCR_RANGE, &amp;CbCRRange); MIL_STRING_STREAM ss; if (CbCRRange == M_YCBCR_SD) { _bufferColorSpaceFormat = eCSC_ITU_601; ss &lt;&lt; _pixelFormatString &lt;&lt; MIL_TEXT(\" ITU-601\"); } else if (CbCRRange == M_YCBCR_HD) { _bufferColorSpaceFormat = eCSC_ITU_709; ss &lt;&lt; _pixelFormatString &lt;&lt; MIL_TEXT(\" ITU-709\"); } else if (CbCRRange == M_YCBCR_UHD) // UHD { _bufferColorSpaceFormat = eCSC_ITU_2020; ss &lt;&lt; _pixelFormatString &lt;&lt; MIL_TEXT(\" ITU-2020\"); } else { ss &lt;&lt; _pixelFormatString; _bufferColorSpaceFormat = eCSC_FULL; } _pixelFormatString = ss.str(); // now set the color space in the display buffer. for (auto iterBuffer = _allocatedBuffers.begin(); iterBuffer != _allocatedBuffers.end(); ++iterBuffer) _pdisplay-&gt;BufSetColorSpace(iterBuffer-&gt;dispid, _bufferColorSpaceFormat); } } return; } // Stops the grab, reallocate all the buffers and restart the grab. void CMILDigitizerHandler::RestartGrab() { // get current tile position on display bool tile_isMainTile = false; int tile_posX, tile_posY, tile_sizeX, tile_sizeY; tile_posX = tile_posY = tile_sizeX = tile_sizeY = 0; auto currentRenderSource = _pdisplay-&gt;GetRenderSource(); if (currentRenderSource == eRenderFromGrabCallBack) _pdisplay-&gt;SetRenderSource(eRenderFromThread); if (_tileId) _pdisplay-&gt;GetTile(_tileId, NULL, &amp;tile_isMainTile, NULL, 0, &amp;tile_posX, &amp;tile_posY, &amp;tile_sizeX, &amp;tile_sizeY); StopGrab(); FreeBuffers(); AllocateBuffers(); if (_tileId) _pdisplay-&gt;SetTile(_tileId, true, tile_isMainTile, NULL, tile_posX, tile_posY, tile_sizeX, tile_sizeY); StartGrab(); if (currentRenderSource == eRenderFromGrabCallBack) _pdisplay-&gt;SetRenderSource(eRenderFromGrabCallBack); } // Changes the grab pixel format. If a grab is in progress, it will stop-it, reallocate the buffers and restart grabbing. void CMILDigitizerHandler::SetPixelFormat(PIXEL_FORMAT pixelFormat) { _pixelFormat = pixelFormat; RestartGrab(); } // Activates image processing. void CMILDigitizerHandler::SetProcessing(bool activate) { _processing = activate; RestartGrab(); } // Activates encoding. void CMILDigitizerHandler::SetEncoding(bool activate) { _encoding = activate; RestartGrab(); } // Returns a MIL_STRING containing a description of camera. const MIL_STRING&amp; CMILDigitizerHandler::GetInputDescription() { if (_milDigitizerId &amp;&amp; _inputDescription.size() == 0) { MIL_INT sizeX; MIL_INT sizeY; MIL_INT scanMode; MIL_DOUBLE FrameRate; auto brief = GetInputDescriptionBrief(); MdigInquire(_milDigitizerId, M_SIZE_X, &amp;sizeX); MdigInquire(_milDigitizerId, M_SIZE_Y, &amp;sizeY); MdigInquire(_milDigitizerId, M_SCAN_MODE, &amp;scanMode); MdigInquire(_milDigitizerId, M_SELECTED_FRAME_RATE, &amp;FrameRate); FrameRate += 0.01; MIL_STRING_STREAM ss; ss &lt;&lt; GetInputDescriptionBrief() &lt;&lt; MIL_TEXT(\" \") &lt;&lt; sizeX &lt;&lt; MIL_TEXT(\"x\") &lt;&lt; sizeY &lt;&lt; (scanMode == M_INTERLACE ? MIL_TEXT(\"i\") : MIL_TEXT(\"p\")) &lt;&lt; std::setprecision(4) &lt;&lt; FrameRate; _inputDescription = ss.str(); } return _inputDescription; } // MdigProcess call back function. // This function is called at each grabbed frame. // It is responsible to update the display and encode the image if needed. MIL_INT MFTYPE CMILDigitizerHandler::MILGrabCallbackFunction(MIL_INT HookType, MIL_ID HookId, void* HookDataPtr) { CMILDigitizerHandler *pThis = (CMILDigitizerHandler *)HookDataPtr; pThis-&gt;GrabCallbackFunction(HookType, HookId); return 0; } void CMILDigitizerHandler::GrabCallbackFunction(MIL_INT HookType, MIL_ID HookId) { if (HookType == M_MODIFIED_BUFFER) { // If the grab is stopping then do not update the display. if (!_isGrabbing) return; // Retrieve the MIL_ID of the grabbed buffer. MIL_ID ModifiedBufferId; MIL_DOUBLE grab_hw_timestamp = 0.0; MdigGetHookInfo(HookId, M_MODIFIED_BUFFER + M_BUFFER_ID, &amp;ModifiedBufferId); MdigGetHookInfo(HookId, M_TIME_STAMP, &amp;grab_hw_timestamp); if (ModifiedBufferId) { // calculate frameRate at every 120 frames. const auto frameRateCount = 120; if (_frameCountTotal % frameRateCount == 0) { if (_startTime) { auto deltaTime = grab_hw_timestamp - _startTime; _frameRateCurrent = frameRateCount / deltaTime; } _startTime = grab_hw_timestamp; } // Get the buf structure containing all the buffer information. auto buf_iter = _milDigProcessBufferMap.find(ModifiedBufferId); if (buf_iter != _milDigProcessBufferMap.end()) { auto &amp;buf = *buf_iter-&gt;second; // If we have an associated display buffer, update the display. if (buf.dispid) { // Get and update the pixel format and color-space on the first grabbed frame (the color-space is not knowned before). if (_frameCountTotal == 1) UpdateBufferPixelFormat(buf); _frameCountTotal++; if (!_skipNextDisplay) { // Perform image process if activated. // When doing image processing instead of grabbing directly on the display buffer, we grab in a MIL buffer then // the destination of the processing is the display buffer. if (IsProcessing()) MimArith(ModifiedBufferId, M_NULL, buf.milGrabBufferMappedOnDisplay, M_NOT); else if (IsEncoding()) MbufCopy(ModifiedBufferId, buf.milGrabBufferMappedOnDisplay); _pdisplay-&gt;UpdateDisplay(_tileId, buf.dispid, grab_hw_timestamp); } // is encoding activated? if (IsEncoding() &amp;&amp; _frameCountTotal &gt; 30) _seqHandler.Feed(ModifiedBufferId); } } //To reduce latency we need to drop frames when the internal buffering is growing. //The internal buffering is the difference between the total number of buffers and //the number of pending buffers. if (_skipNextDisplay == false) { MIL_INT buffering_size_total = MdigInquire(_milDigitizerId, M_PROCESS_TOTAL_BUFFER_NUM, M_NULL); MIL_INT buffering_size = MdigInquire(_milDigitizerId, M_PROCESS_PENDING_GRAB_NUM, M_NULL); MIL_INT currentGrabbedFrames = buffering_size_total - buffering_size; if (currentGrabbedFrames &gt; getFrameBufferingLatency()) _skipNextDisplay = true; } else _skipNextDisplay = false; } } return; } ",
      "wordCount": 2591
    },
    {
      "id": "Examples_BoardSpecific_clarityuhd_MultiCameraDisplay_CPP_mseqhandler_cpp",
      "version": "2023100322",
      "title": "mseqhandler.cpp",
      "location": "Sample Code from MIL Examples",
      "text": " Top /***************************************************************************************/ /* * File name: MseqHandler.cpp * Location: See Matrox Example Launcher in the MIL Control Center * * * Synopsis: The sequence handler is used to manage the encoding of streams. * * Copyright (C) Matrox Electronic Systems Ltd., 1992-2023. * All Rights Reserved */ #include &lt;mil.h&gt; #include &lt;ctime&gt; #include &lt;list&gt; #include \"MseqHandler.h\" CseqHandler::CseqHandler(MIL_ID milSystemId) : _milSystemId(milSystemId), _milSeqId(M_NULL) { _useAutoSettings = true; _frameRate = 60.0; _level = M_LEVEL_5_1; _gop = 90; _bitRate = 15000; _bitRateMax = 30000; _isH264Board = false; MIL_INT boardType = 0; MsysInquire(milSystemId, M_BOARD_TYPE, &amp;boardType); if (boardType &amp; M_H264) _isH264Board = true; } CseqHandler::~CseqHandler() { if (_milSeqId) { auto seqId = _milSeqId; _milSeqId = M_NULL; MseqFree(seqId); } } // returns the pixel formats that are supported by the encoder. std::list&lt;PIXEL_FORMAT&gt; CseqHandler::SupportedPixelFormats() const { if (_isH264Board) { // In order or preference. static const PIXEL_FORMAT pf[] = { eYUV411_8p, eYUV422, eYUV422_10p, eRGB24_planar, eMono8 }; std::list&lt;PIXEL_FORMAT&gt; pixelFormats(pf, pf + sizeof(pf) / sizeof(pf[0])); return pixelFormats; } else { static const PIXEL_FORMAT pf[] = { eRGB24_planar, eYUV422, eBGR32, eMono8}; std::list&lt;PIXEL_FORMAT&gt; pixelFormats(pf, pf + sizeof(pf) / sizeof(pf[0])); return pixelFormats; } } // Returns the most efficient buffer format MIL_INT64 CseqHandler::BestBufferFormat(PIXEL_FORMAT pixelFormat) { MIL_INT64 bestFormat = 0; if (_isH264Board) { if (pixelFormat == eMono8) bestFormat = M_ON_BOARD; else if ((pixelFormat == eYUV422_10p) || (pixelFormat == eYUV411_8p)) bestFormat = M_DYNAMIC + M_ON_BOARD; else bestFormat = M_YUV12 + M_PLANAR + M_ON_BOARD; } else if (pixelFormat == eMono8) bestFormat = 0; else bestFormat = M_RGB24 + M_PLANAR; return bestFormat; } // Start the encoding sequence. void CseqHandler::Start(MIL_STRING fileName, MIL_ID bufSampleId) { if (_milSeqId == M_NULL) MseqAlloc(_milSystemId, M_DEFAULT, M_SEQ_COMPRESS, M_DEFAULT, M_DEFAULT, &amp;_milSeqId); Set(_useAutoSettings, _frameRate, _level, _gop, _bitRate, _bitRateMax); // get current time to put in file name. time_t rawtime; struct tm timeinfo; char buffer[128]; time(&amp;rawtime); #if !M_MIL_USE_LINUX localtime_s(&amp;timeinfo, &amp;rawtime); #else localtime_r(&amp;rawtime, &amp;timeinfo); #endif strftime(buffer, sizeof(buffer), \"_%Y_%m_%d_%Hh%Mm%S\", &amp;timeinfo); MIL_STRING milcurtime = str2Mstr(buffer); _fileName = fileName + milcurtime + MIL_TEXT(\".mp4\"); MseqDefine(_milSeqId, M_SEQ_OUTPUT(0) + M_SEQ_DEST(0), M_FILE, _fileName.c_str(), M_FILE_FORMAT_MP4); MseqControl(_milSeqId, M_CONTEXT, M_BUFFER_SAMPLE, bufSampleId); /* Start the encoding process, waits for buffer to be fed for encoding. */ MseqProcess(_milSeqId, M_START, M_ASYNCHRONOUS); } // Stop the encoding sequence. void CseqHandler::Stop() { if (_milSeqId) { MseqProcess(_milSeqId, M_STOP, M_WAIT); MseqFree(_milSeqId); _milSeqId = M_NULL; } } // Sets the encoding parameters. Must be done before the start. void CseqHandler::Set(bool useAutoSettings, MIL_DOUBLE frameRate, MIL_INT level, MIL_INT gop, MIL_INT bitRate, MIL_INT bitRateMax) { _useAutoSettings = useAutoSettings; _frameRate = frameRate; if (useAutoSettings) { if (_milSeqId) { MseqControl(_milSeqId, M_CONTEXT, M_SETTING_AUTO_ADJUSTMENT, M_ENABLE); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_FRAME_RATE, _frameRate); } } else { _level = level; _gop = gop; _bitRate = bitRate; _bitRateMax = bitRateMax; if (_milSeqId) { MseqControl(_milSeqId, M_CONTEXT, M_SETTING_AUTO_ADJUSTMENT, M_DISABLE); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_PROFILE, M_DEFAULT); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_BIT_RATE_MODE, M_VARIABLE); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_GROUP_OF_PICTURE_SIZE, _gop); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_FRAME_RATE, _frameRate); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_FRAME_RATE_MODE, M_VARIABLE); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_LEVEL, _level); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_BIT_RATE_MAX, _bitRateMax); MseqControl(_milSeqId, M_CONTEXT, M_STREAM_BIT_RATE, _bitRate); } } } // Feeds a buffer in the sequence. Must be done after the Start(). void CseqHandler::Feed(MIL_ID buffer) { if (_milSeqId) MseqFeed(_milSeqId, buffer, M_DEFAULT); } ",
      "wordCount": 489
    },
    {
      "id": "Examples_BoardSpecific_clarityuhd_MultiCameraDisplay_CPP_multicameradisplay_cpp",
      "version": "2023100322",
      "title": "multicameradisplay.cpp",
      "location": "Sample Code from MIL Examples",
      "text": " Top /***************************************************************************************/ /* * File name: MultiCameraDisplay.cpp * Location: See Matrox Example Launcher in the MIL Control Center * * * Synopsis: This program detects all the cameras attached to all the installed * Matrox systems and starts grabbing from them using MdigProcess(). * * This example requires a graphic card supporting OpenGL 3.0 or higher. * * Copyright (C) Matrox Electronic Systems Ltd., 1992-2023. * All Rights Reserved */ #define M_MIL_USE_OS_SCREEN_FUNCTIONS 1 #include &lt;mil.h&gt; //**************************************************************************** // Example description. //**************************************************************************** void PrintHeader() { MosPrintf(MIL_TEXT(\"[EXAMPLE NAME]\\n\\n\")); MosPrintf(MIL_TEXT(\"MultiCameraDisplay\\n\\n\")); MosPrintf(MIL_TEXT(\"[SYNOPSIS]\\n\\n\")); MosPrintf( MIL_TEXT(\"This program detects all the cameras attached to all the installed\\n\")\\ MIL_TEXT(\"Matrox systems and starts grabbing from them using MdigProcess().\\n\\n\")\\ MIL_TEXT(\"Features include:\\n\")\\ MIL_TEXT(\" - Displaying multiple live streams from multiple boards.\\n\")\\ MIL_TEXT(\" - No tearing video output.\\n\")\\ MIL_TEXT(\" - Low latency video output.\\n\")\\ MIL_TEXT(\" - Live camera addition and removal.\\n\")\\ MIL_TEXT(\" - Changing the display between windowed and full screen mode.\\n\")\\ MIL_TEXT(\" - Changing grab buffer pixel formats.\\n\")\\ MIL_TEXT(\" - Activating image processing on a live stream.\\n\")\\ MIL_TEXT(\" - Activating H264 encoding on a live stream.\\n\")\\ MIL_TEXT(\" - Displaying the Feature browser so that the user can control the digitizer\\n\")\\ MIL_TEXT(\" and camera settings.\\n\")\\ MIL_TEXT(\"\\n\\n\")\\ MIL_TEXT(\"Press any key to start.\\n\\n\")\\ ); MosScreenRefresh(); } // Function to print the list of commands. void printCommands() { MosPrintf(MIL_TEXT(\"Matrox MultiCameraDisplay\\n\")\\ MIL_TEXT(\"-------------------------\\n\\n\")\\ MIL_TEXT(\"Cameras can be added or removed at any time.\\n\\n\")\\ MIL_TEXT(\"Commands on a specific camera(s):\\n\")\\ MIL_TEXT(\"---------------------------------\\n\")\\ MIL_TEXT(\" &lt;a&gt; to activate image processing.\\n\")\\ MIL_TEXT(\" &lt;e&gt; to activate H264 encoding.\\n\")\\ MIL_TEXT(\" &lt;b&gt; to open the feature browser.\\n\")\\ MIL_TEXT(\" &lt;d&gt; to free a camera.\\n\")\\ MIL_TEXT(\" &lt;p&gt; to change the pixel format of the grab buffers.\\n\")\\ MIL_TEXT(\" &lt;t&gt; to toggle the display of information in the overlay.\\n\\n\")\\ MIL_TEXT(\"Commands on window:\\n\")\\ MIL_TEXT(\"-------------------\\n\")\\ MIL_TEXT(\" &lt;f&gt; to switch between full-screen and windowed mode.\\n\")\\ MIL_TEXT(\" &lt;g&gt; to switch the display render source.\\n\")\\ MIL_TEXT(\" &lt;r&gt; to rearrange the tiles on the display.\\n\")\\ MIL_TEXT(\" &lt;s&gt; to toggle scaling between fit_to_screen or no-scaling.\\n\\n\")\\ MIL_TEXT(\"Other commands:\\n\")\\ MIL_TEXT(\"---------------\\n\")\\ MIL_TEXT(\" &lt;n&gt; to auto detect new cameras.\\n\")\\ MIL_TEXT(\" &lt;q&gt; to quit.\\n\\n\")\\ MIL_TEXT(\"Camera(s):\\n\")\\ MIL_TEXT(\"--------\\n\") ); MosScreenRefresh(); } #include &lt;set&gt; #include &lt;algorithm&gt; using namespace std; #include \"../DisplayGL/C++/displayGLexport.h\" #include \"MdigHandler.h\" #if M_MIL_USE_WINDOWS // windows.h included only for moving the cursor. #include &lt;Windows.h&gt; #endif // This structure contains all the information of the allocated systems, displays and cameras (digitizers). typedef struct _SYSTEM_DATA { // This structure is used to allocate the camera detection thread. typedef struct { _SYSTEM_DATA *pSystem; MIL_ID systemID; MIL_ID threadcameradetectId; } CAMERA_DETECT_PARAM; _SYSTEM_DATA() { _mutex = M_NULL; } ~_SYSTEM_DATA() { Free(); } void Free() { // Stop all the grabs. for (auto dig_iter = _digitizers.begin(); dig_iter != _digitizers.end(); ++dig_iter) (*dig_iter)-&gt;StopGrab(); // Delete the digitizers. for (auto dig_iter = _digitizers.begin(); dig_iter != _digitizers.end(); ++dig_iter) delete *dig_iter; _digitizers.clear(); // Free the display. if (_display) _display-&gt;Release(); _display = NULL; // Free the mutex. if (_mutex) MthrFree(_mutex); _mutex = M_NULL; // Free the systems. for (auto iter_system = _systemIDs.begin(); iter_system != _systemIDs.end(); ++iter_system) MsysFree(*iter_system); _systemIDs.clear(); } // container of allocated MIL systems. vector&lt;MIL_ID&gt; _systemIDs; // container of allocated cameras. list&lt;CMILDigitizerHandler *&gt; _digitizers; // display ptr. We have one display for all the cameras. Each camera is displayed in a tile (small window) on the display. IMilDisplayEx* _display; // thread ID of the camera detect thread. vector&lt;CAMERA_DETECT_PARAM&gt; _threadcameradetects; // serialization when modifying elements in the containers. MIL_ID _mutex; } SYSTEM_DATA; void ProcessUserInput(MIL_INT keyPressed, SYSTEM_DATA &amp;systemData, bool &amp;sortAndRearrangeDisplay); // Process user keyboard input selection. bool compare_digitizers_for_sorting(const CMILDigitizerHandler *first, const CMILDigitizerHandler *second); // for sorting cameras in alphabetic order. MIL_INT MFTYPE CamPresentFunction(MIL_INT HookType, MIL_ID HookId, void* HookDataPtr); // callback function of MsysHookFunction(M_CAMERA_PRESENT). void StartCameraDetectionThreads(SYSTEM_DATA &amp;systemData, bool wait); // This function starts a camera detect thread that will try to allocate all the digitizers on the system. Then the thread will terminate. void FreeCameraDetectionThreads(_SYSTEM_DATA &amp;SystemData); // This functions frees objects allocated by the StartCameraDetectionThread(). // helper class to lock a mutex on the stack. class MilMutexLockGuard { public: MilMutexLockGuard(MIL_ID mutex) { _mutex = mutex; MthrControl(_mutex, M_LOCK, M_DEFAULT); } ~MilMutexLockGuard() { MthrControl(_mutex, M_UNLOCK, M_DEFAULT); } MIL_ID _mutex; }; //***************************************************************************** // Main. //***************************************************************************** int MosMain(void) { MosScreenResize(44, 80); MosScreenInit(); PrintHeader(); MIL_ID MilApplication; SYSTEM_DATA _systemData; // Contains all the information on the allocated systems, digitizers and display. MappAlloc(M_DEFAULT, &amp;MilApplication); MappControl(M_ERROR, M_PRINT_DISABLE); MIL_INT NbAvailableSystems = 0; MappInquire(M_DEFAULT, M_INSTALLED_SYSTEM_COUNT, &amp;NbAvailableSystems); // Loop for all installed MIL systems. MIL_STRING systemDescriptor; vector&lt;MIL_STRING&gt; excluded_systems; excluded_systems.push_back(MIL_TEXT(\"M_SYSTEM_HOST\")); excluded_systems.push_back(MIL_TEXT(\"M_SYSTEM_GENTL\")); for(MIL_INT i = 0; i &lt; NbAvailableSystems; i++) { MappInquire(M_DEFAULT, M_INSTALLED_SYSTEM_DESCRIPTOR + i, systemDescriptor); // skip systems in excluded list. if (std::find(excluded_systems.begin(), excluded_systems.end(), systemDescriptor) == excluded_systems.end()) { MIL_ID milSystem = M_NULL; MIL_INT sysdevnum = 0; // Allocated all the systems device numbers we can. do { MsysAlloc(systemDescriptor.c_str(), M_DEV0 + sysdevnum, M_DEFAULT, &amp;milSystem); if (milSystem == M_NULL) break; // This example is not supported on a DMIL system (Distributed MIL). if (MsysInquire(milSystem, M_LOCATION, M_NULL) == M_REMOTE) { MsysFree(milSystem); break; } _systemData._systemIDs.push_back(milSystem); sysdevnum++; } while (milSystem); } } MosGetch(); // If we found no systems then use the host system. if (_systemData._systemIDs.size() == 0) { MIL_ID milSystem = M_NULL; MsysAlloc(M_SYSTEM_HOST, M_DEV0, M_DEFAULT, &amp;milSystem); _systemData._systemIDs.push_back(milSystem); } // Allocate synchronization mutex. MthrAlloc(M_DEFAULT_HOST, M_MUTEX, M_DEFAULT, M_NULL, M_NULL, &amp;_systemData._mutex); // Allocate a display. _systemData._display = GetMilDisplayEx(\"Matrox MultiCameraDisplay\", 0, 0); _systemData._display-&gt;SetRenderSource(eRenderFromGrabCallBack); _systemData._display-&gt;OpenWindow(); // Register a hook function on each system camera present event. // Used to: // 1- Allocate and start acquisition on a newly attached camera. // 2- Stop acquisition on a camera that has been removed. // 3- Resume acquisition on a camera that has been re-connected. // Some systems do not support the camera present hook, this will generate an error which we ignore. for (auto iter_system = _systemData._systemIDs.begin(); iter_system != _systemData._systemIDs.end(); ++iter_system) MsysHookFunction(*iter_system, M_CAMERA_PRESENT, CamPresentFunction, &amp;_systemData); // Start the camera detect thread. While it is detecting cameras, we can start grabbing on the ones that are found. StartCameraDetectionThreads(_systemData, false); // Start the main loop. MIL_INT keyPressed = 0; bool sortCameraListInConsole = true; MIL_DOUBLE startTime, currentTime; MappTimer(M_TIMER_READ, &amp;startTime); auto lastdigitizerCount = _systemData._digitizers.size(); while (keyPressed != 'q') { // Slow down loop. MosSleep(50); // First lets check if the display had been closed by the user. if (_systemData._display-&gt;IsWindowClosing()) break; // Exit. // Poll for events on the Window thread. Used for user inputs on the window (mouse, keyboard, etc). _systemData._display-&gt;PollEvents(); // Print statistics in console. // Process input keys. MappTimer(M_TIMER_READ, &amp;currentTime); if (keyPressed || ((currentTime - startTime) &gt; 1.0)) { startTime = currentTime; // Process user key inputs. if (keyPressed) { MosScreenScroll(TRUE); ProcessUserInput(keyPressed, _systemData, sortCameraListInConsole); keyPressed = 0; } // If a camera was added or removed, clean up the display. if (lastdigitizerCount != _systemData._digitizers.size()) { sortCameraListInConsole = true; lastdigitizerCount = _systemData._digitizers.size(); } // Reorder the list of cameras by name. if (sortCameraListInConsole) { MilMutexLockGuard Lock(_systemData._mutex); _systemData._digitizers.sort(compare_digitizers_for_sorting); MosScreenClear(); printCommands(); sortCameraListInConsole = false; } // Print camera descriptions starting at line 27 (after the list of commands). int i = 0; MosScreenSetPosition(0,27); { MilMutexLockGuard Lock(_systemData._mutex); for (auto dig_iter = _systemData._digitizers.begin(); dig_iter != _systemData._digitizers.end(); ++dig_iter) { auto pdig = *dig_iter; auto bufferFormat = pdig-&gt;GetPixelFormatString(); MIL_STRING processing; if (pdig-&gt;IsProcessing()) processing = MIL_TEXT(\"proc \"); if (pdig-&gt;IsEncoding()) processing += MIL_TEXT(\"encoding \"); MIL_STRING description = pdig-&gt;GetInputDescription(); description.resize(20, ' '); MIL_STRING_STREAM sstats; MIL_STRING stat = sstats.str(); stat.resize(79, ' '); // limit MIL_STRING size to display properly in 80 col. MosPrintf(MIL_TEXT(\"%s\\n\"), stat.c_str()); MosScreenRefresh(); } } // Display render source. // When rendering from an independent thread, the rendering rate is controlled by display refresh rate. // When rendering from the grab callback then the rendering follows the rate of the camera. The grab callback is from the camera selected // on the main window. This selection should be used when using AMD FreeSync technology. auto renderSource = _systemData._display-&gt;GetRenderSource(); if (renderSource == eRenderFromThread) MosPrintf(MIL_TEXT(\"\\nDisplay rendered from independent thread (rendering at display rate). \\n\")); else MosPrintf(MIL_TEXT(\"\\nDisplay rendered from grab callback (rendering at frame rate). \\n\")); MosScreenRefresh(); // Display latency statistics if enabled. // The calculation of the latency is only possible when a display output is connected on the input of a Matrox Clarity UHD // and the display is in full screen on that display. // When this condition is met, the latency calculation is automatically started and the statistics printed. { int latencyCount = 0; int latencyDropCount = 0; double curavgLatency_ms = 0; double avgLatency_ms = 0; const char *latencySrc = NULL; const char *latencyDest = NULL; if (_systemData._display-&gt;LatenciesGet(&amp;latencySrc, &amp;latencyDest, curavgLatency_ms, latencyCount, latencyDropCount, avgLatency_ms)) { MosPrintf(MIL_TEXT(\"\\nLatency in ms between input %s and display %s:\\n\"), latencySrc, latencyDest); MosPrintf(MIL_TEXT(\" Avg latency of %.2f (cur: %.2f) on %d grabbed frames, %d frame(s) drop. \\n\"), avgLatency_ms, curavgLatency_ms, latencyCount, latencyDropCount); } } } MosScreenScroll(FALSE); // Check if a key is pressed. if (MosKbhit()) keyPressed = tolower((int)MosGetch()); } MosPrintf(MIL_TEXT(\"\\nExiting.\\n\")); // Free thread objects allocated by the StartCameraDetectionThread(). FreeCameraDetectionThreads(_systemData); // Unhook the camera present callback function. // Some systems do not support the camera present hook, this will generate an error which we ignore. for (auto iter_system = _systemData._systemIDs.begin(); iter_system != _systemData._systemIDs.end(); ++iter_system) MsysHookFunction(*iter_system, M_CAMERA_PRESENT + M_UNHOOK, CamPresentFunction, &amp;_systemData); // Free everything in the system. _systemData.Free(); MosScreenRelease(); MappFree(MilApplication); return 0; } // This function is used for sorting the digitizers in alphabetic order. bool compare_digitizers_for_sorting(const CMILDigitizerHandler *first, const CMILDigitizerHandler *second) { if (*first &lt; *second) return true; return false; } // This thread is called to search for allocated cameras on a particuliar system. // It is used at the start of the process to start grabbing immediately when // at least one camera is found. The grab starts before all cameras are found. MIL_UINT32 MFTYPE CameraDetectThread(void *pCAMERA_DETECT_PARAM_VOID) { _SYSTEM_DATA::CAMERA_DETECT_PARAM *pcameraDetectParam = (_SYSTEM_DATA::CAMERA_DETECT_PARAM *)pCAMERA_DETECT_PARAM_VOID; if (pcameraDetectParam) { MIL_INT numberOfDigitizers = 0; CmilDigitizerFactory dig_factory; auto psystem = pcameraDetectParam-&gt;pSystem; // loop on the number of digitizers available on this system. MsysInquire(pcameraDetectParam-&gt;systemID, M_DIGITIZER_NUM, &amp;numberOfDigitizers); for (int i = 0; i &lt; numberOfDigitizers; i++) { auto pdig = dig_factory.AllocateMILDigHandler(pcameraDetectParam-&gt;systemID, i); if (pdig-&gt;DigAlloc()) { // A camera is present on this digitizer... use it. MilMutexLockGuard Lock(psystem-&gt;_mutex); psystem-&gt;_digitizers.push_back(pdig); pdig-&gt;SetDisplay(psystem-&gt;_display); pdig-&gt;StartGrab(); } else delete pdig; } // wait a little then rearrange the new grabs (tiles) on the screen so it will look nice. psystem-&gt;_display-&gt;RearrangeTiles(eSIDE_BY_SIDE_BOTTOM); } return 0; } // This function starts a camera detect thread (one per system) that will try to allocate all the digitizers on the system. Then the threads will terminate. void StartCameraDetectionThreads(_SYSTEM_DATA &amp;SystemData, bool wait) { // wait for the camera detect thread to finish. for (auto itcamDetect = SystemData._threadcameradetects.begin(); itcamDetect != SystemData._threadcameradetects.end(); ++itcamDetect) { MthrWait(itcamDetect-&gt;threadcameradetectId, M_THREAD_END_WAIT, M_NULL); MthrFree(itcamDetect-&gt;threadcameradetectId); } SystemData._threadcameradetects.clear(); // If the mutex is not yet allocated, allocate it. if (SystemData._mutex == M_NULL) MthrAlloc(M_DEFAULT_HOST, M_MUTEX, M_DEFAULT, M_NULL, M_NULL, &amp;SystemData._mutex); // We allocate a camera detect thread per system. for (auto itsystem = SystemData._systemIDs.begin(); itsystem != SystemData._systemIDs.end(); ++itsystem) { _SYSTEM_DATA::CAMERA_DETECT_PARAM param = { &amp;SystemData, *itsystem, 0 }; SystemData._threadcameradetects.push_back(param); } // Start all the threads. for (auto itcamDetect = SystemData._threadcameradetects.begin(); itcamDetect != SystemData._threadcameradetects.end(); ++itcamDetect) { auto &amp;cameraDetectParam = *itcamDetect; MthrAlloc(M_DEFAULT_HOST, M_THREAD, M_DEFAULT, &amp;CameraDetectThread, &amp;cameraDetectParam, &amp;cameraDetectParam.threadcameradetectId); } if (wait) FreeCameraDetectionThreads(SystemData); } // Free the objects allocated when starting the CameraDetectionThread(). void FreeCameraDetectionThreads(_SYSTEM_DATA &amp;SystemData) { // wait for the camera detect thread to finish. for (auto itcamDetect = SystemData._threadcameradetects.begin(); itcamDetect != SystemData._threadcameradetects.end(); ++itcamDetect) { MthrWait(itcamDetect-&gt;threadcameradetectId, M_THREAD_END_WAIT, M_NULL); MthrFree(itcamDetect-&gt;threadcameradetectId); } SystemData._threadcameradetects.clear(); } // Callback function of MsysHookFunction(M_CAMERA_PRESENT) called when a camera is plugged or unplugged. MIL_INT MFTYPE CamPresentFunction(MIL_INT HookType, MIL_ID HookId, void* HookDataPtr) { MIL_ID milsystem; MobjInquire(HookId, M_OWNER_SYSTEM, &amp;milsystem); if (HookType == M_CAMERA_PRESENT) { auto &amp;systemData = *(SYSTEM_DATA *)HookDataPtr; MilMutexLockGuard Lock(systemData._mutex); MIL_INT isCamPresent = 0; MIL_INT digitizerDeviceNbr = 0; auto &amp;digitizers = systemData._digitizers; // Inquire the camera present state (present or not present). MsysGetHookInfo(milsystem, HookId, M_CAMERA_PRESENT, &amp;isCamPresent); // Inquire the camera's digitizer device number. MsysGetHookInfo(milsystem, HookId, M_NUMBER, &amp;digitizerDeviceNbr); // Find if the camera is already allocated. CMILDigitizerHandler *pcurrentDig = NULL; auto iter_dig = digitizers.begin(); for (; iter_dig != digitizers.end(); ++iter_dig) { if (((*iter_dig)-&gt;GetSysId() == milsystem) &amp;&amp; ((*iter_dig)-&gt;GetDevNum() == digitizerDeviceNbr)) { // The camera already exists. pcurrentDig = *iter_dig; break; } } // Is this a hook of camera being detected? if (isCamPresent) { // The camera is already allocated and we receive a hook of camera present... reallocate it. if (pcurrentDig) { pcurrentDig-&gt;DigFree(); if (pcurrentDig-&gt;DigAlloc()) { pcurrentDig-&gt;StartGrab(); } else { // cannot allocate digitizer (no camera) so remove it. delete pcurrentDig; digitizers.erase(iter_dig); } } else { // This is a new camera. CmilDigitizerFactory dig_factory; // This is a new camera, allocate it. The dig will be allocated in the main loop. auto dig = dig_factory.AllocateMILDigHandler(milsystem, M_DEV0 + digitizerDeviceNbr); if (dig &amp;&amp; dig-&gt;DigAlloc()) { // A camera is present on this digitizer... use it. digitizers.push_back(dig); dig-&gt;SetDisplay(systemData._display); dig-&gt;StartGrab(); } } } // The camera is disconnected. else if (pcurrentDig) { delete pcurrentDig; digitizers.erase(iter_dig); } } return 0; } // Process user keyboard input selection. void ProcessUserInput(MIL_INT keyPressed, SYSTEM_DATA &amp;systemData, bool &amp;sortAndRearrangeDisplay) { // Process commands that are performed on the display. auto &amp;digitizers = systemData._digitizers; decltype(systemData._digitizers) supportedDigitizers; PIXEL_FORMAT pixelFormat = eMono8; // Pixel to set (only used when key 'p' is pressed). sortAndRearrangeDisplay = true; switch (keyPressed) { // Process commands that are performed on a specific camera. case 'a': // toggle image processing. case 'd': // free the digitizer. case 'e': // toggle encoding. case 'b': // feature browser. case 't': // toggle text overlay. case 'p': // pixel format. { // pixel format if (keyPressed == 'p') { std::set&lt;PIXEL_FORMAT&gt; pixelFormats; // populate list of supported pixel formats. for (auto iter_dig = digitizers.begin(); iter_dig != digitizers.end(); ++iter_dig) { auto dig = *iter_dig; auto digpixelFormats = dig-&gt;SupportedPixelFormats(); for (auto iter_pixelformats = digpixelFormats.begin(); iter_pixelformats != digpixelFormats.end(); ++iter_pixelformats) pixelFormats.insert(*iter_pixelformats); } int i = 0; MosPrintf(MIL_TEXT(\"\\n\\nSelect pixel format: \\n\")); for (auto iter_pf = pixelFormats.begin(); iter_pf != pixelFormats.end(); ++iter_pf) { MIL_STRING_STREAM pixelformat; pixelformat &lt;&lt; i++ &lt;&lt; \": \" &lt;&lt; GetPixelFormatName(PfncFormat(*iter_pf)) &lt;&lt; \"\\t\\t\" &lt;&lt; GetPixelFormatDescription(PfncFormat(*iter_pf)) &lt;&lt; std::endl; MosPrintf(MIL_TEXT(\"%s\"),pixelformat.str().c_str()); } MosScreenRefresh(); auto secondKey = tolower((int)MosGetch()); auto pixelFormatNumber = int(secondKey - '0'); if (pixelFormatNumber &gt;= 0 &amp;&amp; pixelFormatNumber &lt; int(pixelFormats.size())) pixelFormat = PIXEL_FORMAT(*std::next(pixelFormats.begin(), pixelFormatNumber)); } // Inquire which camera to perform the command. CMILDigitizerHandler *pselectedCamera = NULL; bool allCameras = false; if (digitizers.size() &gt; 1) { MosPrintf(MIL_TEXT(\"\\nSelect camera number (0 - %d) or 'a' for all cameras: \"), (int)digitizers.size() - 1); MosScreenRefresh(); MIL_INT Key = tolower((int)MosGetch()); int cameraNumber = int(Key - '0'); if (Key == 'a') allCameras = true; else if (cameraNumber &gt;= 0 &amp;&amp; (cameraNumber &lt; int(digitizers.size()))) { MilMutexLockGuard Lock(systemData._mutex); // Get the selected camera. auto it = digitizers.begin(); std::advance(it, cameraNumber); pselectedCamera = *it; } } else if (digitizers.size() == 1) { // Only one camera, do not ask the user which camera when we only have one. allCameras = true; } // Is the selected camera valid? if (pselectedCamera || allCameras) { MilMutexLockGuard Lock(systemData._mutex); auto iter = digitizers.begin(); while (iter != digitizers.end()) { auto current = iter++; auto dig = *current; if (allCameras || pselectedCamera == dig) { if (keyPressed == 'd') // Free the digitizer. { delete dig; digitizers.erase(current); } else if (keyPressed == 'b') // Open the feature browser. MdigControl(dig-&gt;GetDigId(), M_GC_FEATURE_BROWSER, M_OPEN + M_ASYNCHRONOUS); else if (keyPressed == 'p') // Change pixel format. dig-&gt;SetPixelFormat(pixelFormat); else if (keyPressed == 'a') // activate image processing. dig-&gt;SetProcessing(!dig-&gt;IsProcessing()); else if (keyPressed == 'e') // activate image encoding. { // Do we have an encoding license? if (!(MappInquire(M_DEFAULT, M_LICENSE_MODULES, M_NULL) &amp; M_LICENSE_JPEGSTD)) { MosPrintf(MIL_TEXT(\"Sorry, no encoding license present. Press any key to continue.\\n\")); MosScreenRefresh(); MosGetch(); } else { dig-&gt;SetEncoding(!dig-&gt;IsEncoding()); } } else if (keyPressed == 't') // toggle display of text overlay. { if (dig-&gt;GetOverlayText().size()) dig-&gt;SetOverlayText(MIL_TEXT(\"\")); else dig-&gt;SetOverlayText(dig-&gt;GetInputDescriptionBrief()); } } } } } break; case 'r': // Rearrange the tiles on the display. systemData._display-&gt;RearrangeTiles(eNEXTPATTERN); break; case 'g': // Toggle the display render thread (render from grab callback or from independent thread). { auto renderSource = systemData._display-&gt;GetRenderSource(); if (renderSource == eRenderFromThread) systemData._display-&gt;SetRenderSource(eRenderFromGrabCallBack); else systemData._display-&gt;SetRenderSource(eRenderFromThread); } break; case 'f': // Switch the window between full-screen and windowed mode. { int monitorcount = systemData._display-&gt;GetMonitorCount(); MosPrintf(MIL_TEXT(\"\\nSelect monitor number to display window (0 - %d): \\n\"), monitorcount - 1); MosPrintf(MIL_TEXT(\"0: Windowed mode\\n\")); for (int i = 1; i &lt; monitorcount; i++) { MIL_STRING_STREAM monitorstr; monitorstr &lt;&lt; i &lt;&lt; \": \" &lt;&lt; systemData._display-&gt;GetMonitorName(i) &lt;&lt; std::endl; MosPrintf(MIL_TEXT(\"%s\"),monitorstr.str().c_str()); } MosScreenRefresh(); auto secondKey = tolower((int)MosGetch()); auto monitorNumber = int(secondKey - '0'); if((monitorNumber &gt;= 0) &amp; (monitorNumber &lt; monitorcount)) systemData._display-&gt;SetWindowMonitor(monitorNumber); } break; case 's': // Switch scale to fit window. { auto FitToScreen = systemData._display-&gt;GetScalingFitToWindow(); FitToScreen = !FitToScreen; systemData._display-&gt;SetScalingFitToWindow(FitToScreen); } break; case 'n': { // Restart the camera detect thread. StartCameraDetectionThreads(systemData, false); MosPrintf(MIL_TEXT(\"\\nDetecting new cameras... please wait...\\n\")); } break; default: // invalid selection... do nothing. sortAndRearrangeDisplay = false; } } ",
      "wordCount": 2686
    }
  ]
}]