[{
  "id": "UG_3D_processing_and_analysis_overview",
  "version": "2024020714",
  "title": "3D processing and analysis overview",
  "subTitles": null,
  "location": "MIL UG P05: 3D processing and analysis",
  "pageURL": "content\\UserGuide\\3D_processing_and_analysis_overview\\ChapterInformation.htm",
  "text": " Chapter 32: 3D processing and analysis overview This chapter provides an overview of the 3D processing and analysis modules. MIL 3D processing and analysis overview What you need to know Basic concepts for 3D processing and analysis ",
  "wordCount": 39,
  "subEntries": [
    {
      "id": "UG_3D_processing_and_analysis_overview_MIL_3D_processing_and_analysis_overview",
      "version": null,
      "title": "MIL 3D processing and analysis overview",
      "subTitles": [
        "What you need to know"
      ],
      "location": "MIL UG P05: 3D processing and analysis",
      "pageURL": "content\\UserGuide\\3D_processing_and_analysis_overview\\MIL_3D_processing_and_analysis_overview.htm",
      "text": " MIL 3D processing and analysis overview You can perform a variety of procedures to process and analyze 3D information. The MIL 3D modules support display, processing, and analysis of 3D data (depth maps and point clouds). You can generate depth maps from point cloud data, or convert a depth map to a point cloud. You can also create and work with 3D geometries, such as a 3D box, cylinder, or sphere. You can perform arithmetic and statistical operations, as well as comparative measurements between point clouds, depth maps, and 3D geometries. For example, you can fit a 3D geometry to a point cloud or depth map and calculate distances between points and the fitted surface. You can also register points obtained from multiple views of the same 3D scene so that the same point in a scene has the same coordinates when represented in different point clouds (pairwise registration). You can scale, rotate, and translate 3D data, compute 3D profiles to examine a cross-section of data, and merge multiple point clouds. You can also sample a subset of points or reconstruct surfaces (meshes) for point clouds. Most MIL 3D functions work with 3D data stored in a MIL container, which itself holds information in components. Each component is a MIL object that stores an aspect of the 3D data in a buffer. For example, the range component stores the world coordinates of 3D points. For processing and display of 3D data, a container must be in a MIL 3D-processable or 3D-displayable format, respectively. A point cloud or 3D geometry is not associated with a calibration context. Instead, 3D coordinates are expected to be real world values. When working with a depth map using the 3D processing and analysis modules, it must be in a calibrated image buffer and be fully corrected. You can grab point clouds from a 3D sensor or generate point clouds from a laser line profiling setup. You can also load point clouds from PLY and STL files, or create them manually in your application. PLY and STL are 3D data formats that can be used to store point clouds acquired from 3D sensors or generated from CAD drawings. Using the MIL 3D Reconstruction module, you can also extract 3D information from 2D images to create a point cloud that you can pass to other 3D modules for processing and analysis. The 3D Reconstruction module can also perform stereo vision triangulation to compute the 3D world coordinates of points from their pixel location in the image plane of two or more cameras. What you need to know Before using the MIL 3D modules, you should read the Working with 3D section of Chapter 2: Building an application. If you require in-depth information while working, you can refer to Part 6 of the MIL User Guide. The above-mentioned sections in Chapter 2: Building an application and Part 6 elaborate on the following concepts: 3D data containers and grabbing, converting 3D data for processing and 3D display, displaying 3D data and graphics, calibration, storing the output of 3D functions, regions of interest, fixturing in 3D, using the 3D geometry module, and 3D reconstruction using laser line profiling. MIL 3D processing and analysis overview What you need to know ",
      "wordCount": 541,
      "subEntries": []
    },
    {
      "id": "UG_3D_processing_and_analysis_overview_Basic_concepts",
      "version": null,
      "title": "Basic concepts for 3D processing and analysis",
      "subTitles": null,
      "location": "MIL UG P05: 3D processing and analysis",
      "pageURL": "content\\UserGuide\\3D_processing_and_analysis_overview\\Basic_concepts.htm",
      "text": " Basic concepts for 3D processing and analysis The basic concepts and vocabulary conventions for 3D processing and analysis are: 3D-displayable container. A container that has the M_DISP attribute and components correctly formatted for it to be shown in a 3D display (using functions from the M3ddisp...() module). 3D geometry object. A MIL object that stores one of several 3D shapes (box, cylinder, line, plane, or sphere). The MIL object is allocated and defined for use in 3D functions to limit or define the processing region of a point cloud or depth map. 3D-processable container. A container that has the M_PROC attribute and components correctly formatted for it to be used as a source for 3D processing functions. 3D reconstruction setup. A physical setup used to extract 3D information from images. 3D virtual model. A CAD software model of an object, where the dimensions of the model are to scale. Camera calibration context. A MIL object that stores the mapping between the pixel coordinate system and the world coordinate system, as well as information about the camera calibration setup, and the initial locations of all the coordinate systems. Camera-laser triangulation (see laser line profiling). Camera setup. The camera's position relative to the object in the physical setup used to acquire images. Depth. A measurement extending from the surface of the object to the XY plane (that is, the z=0 plane), in world units. Depth map. An image where the gray value of a pixel represents its depth in the world. Fully corrected depth map. A depth map that accurately represents the height and shape of portrayed objects; its pixels represent a constant size in X and Y in the world. Note that, when dealing with depth maps, the size of the pixels is not necessarily square. Laser line profiling. A process whereby grabbed images of objects passing through a sheet of light or laser plane permit the reconstruction of 3D information about the objects in the form of a point cloud or depth map. The object under the laser light displaces the laser line, and the degree of displacement reveals height (depth) information about the object. Partially corrected depth map. A depth map that accurately represents the height of portrayed objects, but not their shape. Point cloud. A set of 3D points representing objects in a scene. Pose. The established position and orientation of an object in space. Reference plane. A plane with a known height and orientation, and used as a measure against which to compute distances, angles, volumes, or other calculations. Stereo vision triangulation. A process that calculates a point's (X, Y, Z) coordinates in the world if it is seen by at least two calibrated camera setups. Transformation matrix object. A MIL object that stores a 4x4 matrix that defines a required modification, such as transforming coordinates to fixture a point cloud or 3D geometry to a required position and orientation. XY-plane. The plane defined by the equation Z=0 in a world coordinate system. XZ-plane. The plane defined by the equation Y=0 in a world coordinate system. Basic concepts for 3D processing and analysis ",
      "wordCount": 518,
      "subEntries": []
    }
  ]
}]