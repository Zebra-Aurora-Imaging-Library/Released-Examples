[{
  "id": "UG_3D_analysis_using_planar_views_of_an_object",
  "version": "2024020714",
  "title": "3D analysis using planar views of an object",
  "subTitles": null,
  "location": "MIL UG P05: 3D processing and analysis",
  "pageURL": "content\\UserGuide\\3D_analysis_using_planar_views_of_an_object\\ChapterInformation.htm",
  "text": " Chapter 34: 3D analysis using planar views of an object This chapter describes how to use the 3D processing and analysis modules when working with planar views of an object. 3D analysis using planar views of an object overview Moving the relative coordinate system to account for height Measuring two features displaced by a known height Accounting for thickness of camera calibration grids in 3D setups Establishing the position and orientation of an object Using a grid Obtaining results Performing stereo vision triangulation Matching common points to perform stereo vision triangulation ",
  "wordCount": 93,
  "subEntries": [
    {
      "id": "UG_3D_analysis_using_planar_views_of_an_object_3D_analysis_using_planar_views_of_an_object_overview",
      "version": null,
      "title": "3D analysis using planar views of an object overview",
      "subTitles": null,
      "location": "MIL UG P05: 3D processing and analysis",
      "pageURL": "content\\UserGuide\\3D_analysis_using_planar_views_of_an_object\\3D_analysis_using_planar_views_of_an_object_overview.htm",
      "text": " 3D analysis using planar views of an object overview MIL offers a variety of procedures to perform 3D analysis of planar views of an object (assuming the images have been calibrated using a 3D mode). If your setup has objects that rest on surfaces of different heights, comparative measurements can be difficult to obtain due to perspective distortion. Using MIL's 3D-based camera calibration modes, the Z-coordinate is assigned a real-world height based on the distance of the camera to the camera calibration plane. This allows you to displace the relative coordinate system to the known height of an object in your image before performing measurements, allowing dimensions of different features in the image to be compared. If you are trying to manipulate an object that can move freely in a camera's field of view, you might need to know its pose (that is, its position and orientation) in the world. Using 3D-based camera calibration modes, you can use the Camera Calibration module to establish the pose of an object in the absolute coordinate system, if you have a 3D virtual model of the object, defined using CAD software, and you can find characteristics on the object for which you know their position relative to the origin of the 3D virtual model. If you want to construct a 3D representation of an object, MIL's 3D Reconstruction module allows you to extract 3D information from images taken from two types of 3D reconstruction setups: A laser line profiling setup. A stereo vision triangulation of points setup. Using images taken from a 3D reconstruction setup built for laser line profiling, the module can generate a cloud of 3D points (point cloud) of an object. Using images taken from a 3D reconstruction setup for the stereo vision triangulation of points, the module can calculate the world coordinates of a point when two or more cameras, for which you have camera calibration contexts, are used. This chapter discusses how to perform most of the above-mentioned 3D analysis using planar views of an object. For information when using a laser line profiling setup, see Chapter 46: 3D reconstruction using laser line profiling. If you have a point cloud or, in some cases, a fully corrected depth map, you can use the 3D modules that perform 3D processing and analysis instead of using the methods described in this chapter. 3D analysis using planar views of an object overview ",
      "wordCount": 403,
      "subEntries": []
    },
    {
      "id": "UG_3D_analysis_using_planar_views_of_an_object_Moving_the_relative_coordinate_system_to_account_for_height",
      "version": null,
      "title": "Moving the relative coordinate system to account for height",
      "subTitles": [
        "Measuring two features displaced by a known height",
        "Accounting for thickness of camera calibration grids in 3D setups"
      ],
      "location": "MIL UG P05: 3D processing and analysis",
      "pageURL": "content\\UserGuide\\3D_analysis_using_planar_views_of_an_object\\Moving_the_relative_coordinate_system_to_account_for_height.htm",
      "text": " Moving the relative coordinate system to account for height When using 3D camera calibration modes, the Z-coordinate of the relative and absolute coordinate system can have a physical meaning in terms of a height, even if all points in an image are assumed to be on the same plane (even if that plane is slanted) and all results (except those from the Camera calibration module and the 3D reconstruction module) are returned to a 2D coordinate system. For example, the area of an object in real-world units will be different if the relative coordinate system is moved to a different height. Consequently, it is important to consider where the absolute coordinate system is placed and how measurements are taken. Measuring two features displaced by a known height All results are returned in the relative coordinate system, so you must move it to the location where you need to measure. However, two objects can be located in different planes and suffer from perspective distortion. Although the camera calibration context will account for two dimensional perspective distortion in a single plane, it cannot account for a difference in height as well. For example, two identical rings sitting on boxes of different heights will appear to have a different size and perhaps shape from the camera's view point. To ensure that measurements are comparable, the relative coordinate system can be moved to the correct plane before a measurement is taken for each object. To displace the relative coordinate system, perform the following: Determine the location of the object to be measured. Displace the relative coordinate system to its corresponding plane using McalSetCoordinateSystem(). For information, see the Moving coordinate systems to reflect camera setup changes section of Chapter 28: Calibrating your camera setup. Measure the feature(s) of interest. Repeat steps 1 through 3 for each object to be measured that is on a different plane. The following images depict two rings sitting on boxes of different height, from the camera and side view respectively. Note that if your object is located on a plane that is on a slant, the relative coordinate system must be positioned on that slant. Accounting for thickness of camera calibration grids in 3D setups Even when using a 3D-based camera calibration context, you can use grids to provide calibration points. However, the grid used in the camera calibration has a certain thickness. Depending on your application, you should correct for this thickness and ensure that the XY (Z=0) plane of the absolute coordinate system is well placed. This is important if you are using the camera calibration context with a 3D reconstruction setup where measurements in height will be taken. To account for the thickness of the camera calibration grid, specify the height of the grid using McalGrid() with GridOffsetZ. Moving the relative coordinate system to account for height Measuring two features displaced by a known height Accounting for thickness of camera calibration grids in 3D setups ",
      "wordCount": 490,
      "subEntries": []
    },
    {
      "id": "UG_3D_analysis_using_planar_views_of_an_object_Establishing_the_position_and_orientation_of_an_object",
      "version": null,
      "title": "Establishing the position and orientation of an object",
      "subTitles": [
        "Using a grid",
        "Obtaining results"
      ],
      "location": "MIL UG P05: 3D processing and analysis",
      "pageURL": "content\\UserGuide\\3D_analysis_using_planar_views_of_an_object\\Establishing_the_position_and_orientation_of_an_object.htm",
      "text": " Establishing the position and orientation of an object If you are trying to manipulate an object that can move freely in a camera's field of view, you might need to know its pose (that is, its position and orientation) in the world. Using 3D-based camera calibration modes, you can use the Camera Calibration module to establish the pose of an object in the absolute coordinate system, if you have a 3D virtual model of the object, defined using CAD software, and you can find characteristics on the object for which you know their position relative to the origin of the 3D virtual model. You can search for the unique features on the object and then pass the pixel position of these features and the position that they should have in the relative coordinate system to McalList() with M_DISPLACE_RELATIVE_COORD; the relative coordinate system will move so that the pixel positions correspond to the correct coordinates in the relative coordinate system. Note that in this case, the absolute coordinate system will not be displaced. Since you are specifying the pixel positions of the 3D virtual model's features, the relative coordinate system will be placed where the reference coordinate system of the 3D virtual model (0,0) would be with respect to the feature locations provided. You can then establish how that relative coordinate system is situated in the absolute coordinate system using McalGetCoordinateSystem(). To establish the pose of an object, you must satisfy the following conditions: The camera calibration context must be allocated using McalAlloc() with M_TSAI_BASED or M_3D_ROBOTICS. The camera calibration context must be configured using McalGrid() or McalList() with M_FULL_CALIBRATION. The object must have at least 4 features that can be identified and whose feature positions are known in a 3D virtual model (CAD) relative to the model's origin. The following is an image depicting unique features (attributes) that you could use to establish the pose of your object. The following images depict a 3D virtual model of a car door, an image of the door, and the resulting position of the relative coordinate system with respect to the absolute coordinate system. Using a grid If a grid is provided on your object, you can call McalGrid() with M_DISPLACE_RELATIVE_COORD and specify the grid's physical dimensions. McalGrid() will perform the feature extraction and displace the relative coordinate system to align with the top row and left most column of the found grid points (unless an offset has been specified). Note that the function searches for an exact match to the number of rows and columns that have been specified; therefore, if the grid is only partially visible, it will not be found. For more information, see the Calibrating using calibration points from a grid section of Chapter 28: Calibrating your camera setup. Obtaining results After the relative coordinate system has been moved to the object's position at the correct orientation (as defined, for example, by the coordinate system of the 3D virtual model of the object), you can inquire the new location of the relative coordinate system relative to any other world coordinate system. To do so, use McalGetCoordinateSystem() with the target coordinate system set to M_RELATIVE_COORDINATE_SYSTEM. For more information, see the Inquiring about your camera calibration section of Chapter 28: Calibrating your camera setup. Establishing the position and orientation of an object Using a grid Obtaining results ",
      "wordCount": 558,
      "subEntries": []
    },
    {
      "id": "UG_3D_analysis_using_planar_views_of_an_object_Performing_stereo_vision_triangulation",
      "version": null,
      "title": "Performing stereo vision triangulation",
      "subTitles": [
        "Matching common points to perform stereo vision triangulation"
      ],
      "location": "MIL UG P05: 3D processing and analysis",
      "pageURL": "content\\UserGuide\\3D_analysis_using_planar_views_of_an_object\\Performing_stereo_vision_triangulation.htm",
      "text": " Performing stereo vision triangulation Stereo vision triangulation (stereophotogrammetry) is the process of finding an object's location in 3D space, using two or more planar views of the object. In stereo vision triangulation, an object's feature must be seen by at least two cameras. If the positions of the cameras in 3D space are known, the feature's location on each camera's image plane and the camera's location in the world are used to calculate the feature's location in the world. In MIL, you can perform stereo vision triangulation using M3dmapTriangulate(). The following image shows the projection of point A on the image plane of two cameras. The intersection of point B and C's projection line results in the location of point A in 3D space. However, in reality, the projection of a point on a camera's image plane is not perfect. Rounding and extraction errors prevent point A from being projected with accuracy on the cameras' image planes. Points B' and C' will be the points used in the calculation and point D is the resulting approximation of A. Additional cameras increase the accuracy of the result. However, not all cameras need to see the point; only two cameras are necessary for stereo vision triangulation, but the more cameras involved, the more accurate the result. Matching common points to perform stereo vision triangulation To do stereo vision triangulation, M3dmapTriangulate() requires that you match points (features) common in at least two images. That is, you must identify common points which are seen by at least two cameras, identify the points' coordinates in their respective images and supply the coordinates to M3dmapTriangulate(). For example, in the following image, the points (X A0, Y A0), (X B0, Y B0), and (X C0, Y C0) are paired together. (X A1, Y A1) and (X B1, Y B1) are paired together, but camera C does not see this point. You can pair multiple points with a single call to M3dmapTriangulate() by specifying their coordinates. To pair the points given in the previous example, you would give the following arguments to M3dmapTriangulate(): Since camera C cannot see one of the points, you need to specify M_INVALID_POINT for the appropriate indices. Note that you also need to specify the identifier of the camera calibration contexts for the different camera setups. The order in which you specify the identifiers must match the order in which you specify the coordinates. Note that stereo vision triangulation requires that all the cameras be calibrated in a 3D mode using McalAlloc() with M_TSAI_BASED or M_3D_ROBOTICS. All cameras must also share a common 3D coordinate system. For more information on calibrating your camera setup, see Chapter 28: Calibrating your camera setup. Performing stereo vision triangulation Matching common points to perform stereo vision triangulation ",
      "wordCount": 461,
      "subEntries": []
    }
  ]
}]