[{
  "id": "UG_ML_Anomaly_detection",
  "version": "2024020714",
  "title": "Anomaly detection",
  "subTitles": null,
  "location": "MIL UG P08: Machine learning tasks",
  "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\ChapterInformation.htm",
  "text": " Chapter 54: Anomaly detection This chapter explains how to perform anomaly detection using machine learning with the MIL Classification module. Anomaly detection overview Testing with the trained threshold and statistics Steps to perform anomaly detection Perform all required allocations Build and populate your dataset Train your classifier context Evaluate your trained classifier Threshold and statistics Predict with your classifier Save your classification contexts Free your allocated objects Building a dataset for anomaly detection Populate the source dataset context Splitting your dataset Augmentation and other data preparations Exporting and importing a dataset Export Import Classifier and training settings for anomaly detection Training objects and folders Training modes and related settings Training and analysis for anomaly detection Monitoring the training process Results Adjusting the trained threshold and calculating statistics Score threshold Prediction for anomaly detection Prepare for prediction Predict Results Drawing results Assisted labeling Anomaly detection example ",
  "wordCount": 147,
  "subEntries": [
    {
      "id": "UG_ML_Anomaly_detection_Anomaly_detection_overview",
      "version": null,
      "title": "Anomaly detection overview",
      "subTitles": [
        "Testing with the trained threshold and statistics"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\Anomaly_detection_overview.htm",
      "text": " Anomaly detection overview This chapter explains how to perform anomaly detection using machine learning with the MIL Classification module. Note that this chapter expands on topics previously discussed in Machine learning fundamentals. It is recommended to review these topics if you have not already done so. For the most recent documentation of this chapter, particularly as it relates to statistical analysis (MclassStatCalculate()), check for an updated version of the MIL Help online at zebra.com/aurora-imaging-library-help. Anomaly detection lets you identify invalid images (for example, images with defects), after having trained the classifier on valid images (for example, images without defects). This can be particularly useful when valid images are plentiful and easy to acquire, while invalid images are rare and can have a variety of abnormalities that make them invalid, such as scratches, chips, dents, and foreign objects. Since only valid (non-anomlaous) images are used in training, there is no labeling required for your datasets. This can be quite advantageous, as labeling is typically a long and costly process. You can also use preexisting datasets that have already been labeled, such as datasets built for image classification, defect detection, and object detection. In these cases, anomaly detection uses each entry as non-anomalous (existing labels remain unaffected). In addition to identifying anomalous images, anomaly detection can also localize the anomalies by identifying their coarse pixel location. Note that with anomaly detection, you can retrieve image type results (similar to image classification) or pixel type results (similar to segmentation). For example, you can retrieve whether an image is anomalous, or which pixels in an image are anomalous. Although effective as a stand-alone machine learning task, anomaly detection can also be useful as a preliminary training step for other machine learning tasks, such as image classification, segmentation, and object detection. For example, if you ultimately want to identify a variety of different defects in an image, you can use anomaly detection to find all defective images first. This lets you know which images should be sent for manual labeling so the specific defective class description can be assigned, and which images do not need any manual labeling since you have already determined they are defect free. Reliably reducing the amount of image data that requires manual labeling can often cut costs and development time significantly. Testing with the trained threshold and statistics Once the anomaly detection classifier is trained, a threshold is established to differentiate the anomalous images from the non-anomalous ones. At this point, you can optionally use the trained classifier to predict on your testing dataset. Since the testing dataset is intended to mimic a real life scenario, it must contain some anomalous images. If after testing you are satisfied with your results, it means the trained threshold needs no adjustment and you can deploy. If you are not identifying all the anomalous images you expect, or if you are misidentifying good images as anomalous, then you can adjust your trained threshold, and rerun the prediction testing (there is no retraining needed). Adjusting the threshold is often done with performing a statistical analysis of your dataset (MclassStatCalculate). That is, you can analyze a trained classifier's performance by computing metrics on predicted datasets, which can give you some guidance on adjusting the threshold. For more information, see the Adjusting the trained threshold and calculating statistics section later in this chapter. Anomaly detection overview Testing with the trained threshold and statistics ",
      "wordCount": 569,
      "subEntries": []
    },
    {
      "id": "UG_ML_Anomaly_detection_Steps_to_perform_anomaly_detection",
      "version": null,
      "title": "Steps to perform anomaly detection",
      "subTitles": [
        "Perform all required allocations",
        "Build and populate your dataset",
        "Train your classifier context",
        "Evaluate your trained classifier",
        "Threshold and statistics",
        "Predict with your classifier",
        "Save your classification contexts",
        "Free your allocated objects"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\Steps_to_perform_anomaly_detection.htm",
      "text": " Steps to perform anomaly detection The following steps provide a basic methodology to perform anomaly detection with the MIL Classification module: Perform all required allocations. Build and populate your dataset. Train your classifier context. Evaluate your trained classifier (this includes adjusting the threshold and calculating statistics). Predict with your classifier. If necessary, save your classification contexts. Free your allocated objects. Perform all required allocations These allocations are required to perform anomaly detection. In many cases, some of these allocations will be imported or restored from previous work, using MclassImport() or MclassRestore(). Allocate an anomaly detection classifier context, using MclassAlloc() with M_CLASSIFIER_ANO_PREDEFINED and M_ADNET. Note, MclassTrain() can automatically allocate a classifier context if none is specified. Allocate an images dataset context to hold all of your data (source dataset), using MclassAlloc() with M_DATASET_IMAGES. Alternatively, you can restore an images dataset context, using MclassRestore(), or you can import data into an images dataset context, using MclassImport(). Allocate an anomaly detection training context, using MclassAlloc() with M_TRAIN_ANO. A training context holds the settings with which to train a classifier context. Allocate an anomaly detection training result buffer to hold training results, using MclassAllocResult() with M_TRAIN_ANO_RESULT. Allocate an anomaly detection result buffer to hold the prediction results, using MclassAllocResult() with M_PREDICT_ANO_RESULT. Object allocation for anomaly detection is summarized in the table below: MIL allocation Classifier context M_CLASSIFIER_ANO_PREDEFINED Specific predefined classifier context M_ADNET Dataset context M_DATASET_IMAGES Data preparation context None¹ Training context M_TRAIN_ANO Training result buffer M_TRAIN_ANO_RESULT Prediction result buffer M_PREDICT_ANO_RESULT ¹There is no dedicated data preparation for anomaly detection. However it can be possible to use M_PREPARE_IMAGES_CNN, M_PREPARE_IMAGES_SEG, or M_PREPARE_IMAGES_DET to prepare your data. In this case, it is important to select the data preparation context that is consistent with your labeling. Build and populate your dataset It is recommended that you build and manage your datasets interactively, using MIL CoPilot. For example, MIL CoPilot lets you interactively create, label, modify, import, and export datasets. When using MIL CoPilot, ensure that you have installed all related MIL updates. For more information, see the Requirements, recommendations, and troubleshooting section of Chapter 47: Machine learning with the MIL Classification module. If you restore or import a dataset that is fully built, you can skip this step. If you are not importing a dataset, or are importing a dataset that you want to adjust, refer to the steps below: Add class definitions to the source dataset, using MclassControl() with M_CLASS_ADD. By default, every dataset entry is considered good (that is, not anomalous). Note that no class definitions are required for training and any entry not assigned to a class is considered good. To specify class definitions as anomalous (for the test dataset only), call MclassControl() with M_CLASS_INDEX() and M_ANOMALOUS set to M_TRUE. Add entries to the source images dataset, using MclassControl() with M_ENTRY_ADD. Entries in an images dataset require image data (paths to where images are stored). To specify the location from which to get an entry's image data, use MclassControlEntry() with M_ENTRY_IMAGE_PATH. Optionally, specify the class definition (ground truth) that is represented for each entry, using MclassControlEntry() with M_CLASS_INDEX_GROUND_TRUTH. If you do not specify a class definition, MIL assumes that it represents a good class (that is, not an anomalous class). Pre-existing datasets, such as those created for image classification, segmentation, and object detection can be used without having to alter them, or only specifying a class index as anomalous (for the test dataset). This step is known as labeling your data. For anomaly detection, this type of labeling is not required for training and, even when it is done (for testing), it is typically simpler than other machine learning tasks, since you would only need to explicitly label the anomalous entries (which is optional). You must properly set up your data before training. The quality and quantity of accurate data that is representative of the problem you are trying to solve is critical to building a good dataset. For anomaly detection, it is essential that every image in your development and training dataset is a good image. Specifying one or more anomalous images during training can result in an improperly trained classifier. Since anomaly detection considers every image is good by default, be especially careful to not inadvertently include anomalous training data. Split your source dataset into the training, development, and testing datasets. You can split datasets manually, using MclassSplitDataset(). Anomaly detection requires an explicit training and development dataset (that is, you cannot pass a single dataset to MclassTrain()). When using MclassSplitDataset() to split a dataset with anomalous entries (that is, the source dataset has classes with M_ANOMALOUS set to M_TRUE), all anomalous entries will be in the second destination dataset (DstSecondDatasetContextClassId). In this case, the specified percentage (Percentage) controls what percentage of good (non-anomalous) entries go into the first and second destination datasets. Note that datasets with anomalous entries cannot be used for training. Optionally, prepare your data by cropping or resizing images, and adding augmented images to a dataset. As with other machine learning tasks, all images must be the same size for anomaly detection. Using smaller images, provided they have enough details for an accurate analysis, can result in faster training and prediction (inference), and can reduce your memory requirements for training. To resize, crop, or augment your images, you can use MclassPrepareData() or MIL CoPilot. Note that there is no dedicated data preparation for anomaly detection. However it is possible to use M_PREPARE_IMAGES_CNN, M_PREPARE_IMAGES_SEG, or M_PREPARE_IMAGES_DET to prepare your data with MclassPrepareData() (or MIL CoPilot). In this case, it is important to select the data preparation context that is consistent with your labeling. After calling MclassPrepareData(), the resulting images in the destination dataset or buffer can be used for anomaly detection. After you build a dataset, you can export it using MclassExport() so you can train a classifier with it at a later time. It is recommended that you export it with M_IMAGE_DATASET_FOLDER. You can use MclassImport() to import previously defined and exported datasets (for example, from a folder or a CSV file). If you have exported your dataset with M_IMAGE_DATASET_FOLDER, then you should import it with M_IMAGE_DATASET_FOLDER as well. It is recommended that you familiarize yourself with how dataset information (such as images) is stored on disk, and how you can ensure that information is well organized and portable. For more information, see the Guidelines for managing an images dataset section of Chapter 48: Datasets. Train your classifier context To train your classifier context on your datasets, perform the following: Modify training settings, using MclassControl(). Optionally, hook functions to training events, using MclassHookFunction(). Preprocess the training context, using MclassPreprocess(). Perform the training operation, using MclassTrain(). Optionally, get information about training events that caused the hook-handler function to execute, using MclassGetHookInfo(). If results indicate that the current training operation will be unsuccessful, stop the training, and modify your training settings and if necessary your dataset, and re-train. Get the status result of your training (M_STATUS), as well as other training results, using MclassGetResult(). For other types of training tasks, you would typically evaluate your training results; if you are unsatisfied with them (for example, the classifier performed poorly on the development dataset), you would modify your training settings, and if necessary your dataset, and re-train. For anomaly detection, this type of analysis is done with the trained classifier and MclassStatCalculate(), as explained later. Copy the trained classifier context from the train result buffer that MclassTrain() produced into a classifier context, using MclassCopyResult(). Once copied, the classifier context is considered trained. Evaluate your trained classifier To evaluate your trained classifier, perform the following: Call MclassPredict() with the test dataset (which must contain anomalous entries) and the trained classifier. If you get the prediction results you expect (for example, all anomalous images/pixels are predicted and with good scores), and there are no good images/pixels incorrectly predicted as anomalous, it is possible to deploy. If your training results are unsatisfactory, you can adjust the trained threshold, by calling MclassControl() with the identifier of the trained classifier context, and lowering or increasing the M_SCORE_THRESHOLD setting. Lowering the M_SCORE_THRESHOLD value can allow you to detect more anomalous cases, but at the potential cost of incorrectly detecting good/non-anomalous images as anomalous ones. Increasing the M_SCORE_THRESHOLD value can decrease the likelihood of incorrectly detecting good/non-anomalous cases as anomalous, but at the potential cost of missing actual anomalous ones. For more information, see the Adjusting the trained threshold and calculating statistics section later in this chapter. Once you modified the trained threshold, call MclassPredict() again with the test dataset and the trained classifier. You can repeat this process of adjusting the threshold and predicting on the test dataset until you get the results you expect (at which point, you can deploy). If you cannot get the prediction results you expect from your threshold adjustments, you can evaluate the performance of the trained classifier on the test dataset, using MclassStatCalculate(). This is a high level statistical analysis that can help guide your understanding of why you are not getting the training results you want, and help you find the most optimal threshold value to set (that is, you can calculate statistics across different thresholds to find the best one). If you are unable to find a satisfactory threshold once you complete this analysis, you will likely have to adjust your training (for example, you might need to add more images to your training and development datasets, and retrain). Threshold and statistics To help determine how different an image can be, before it is considered anomalous, MIL automatically establishes a threshold for the trained classifier, which you can modify (fine tune) to help fit your application's needs. The threshold level is based on score, and by increasing or decreasing it (for example, with a test dataset), you can influence which images are or are not considered anomalous. Fine tuning the threshold is done post training, and is done in such a way that it results in preferable statistics. Since you can calculate statistics (MclassStatCalculate()) across different thresholds, you can use this methodology to find the ideal threshold that meets your requirements. Note that the default threshold has been selected to minimize false positives (good images predicted as anomalous) as the anomalous detection task is typically performed in scenarios where anomalous images are difficult to acquire. If you find that, after adjusting the threshold and calculating statistics, the classifier still keeps detecting many false positives, you will need more (and more diverse) training images. Similarly, if the classifier keeps detecting many false negatives (anomalous images being predicted as good), there is likely a resolution issue with the images; for example, the defects are too small or you potentially have bad images in your training or development dataset. A high number of false positives or true negatives requires updating your datasets and retraining. Calculating statistics helps you evaluate the performance of a trained classifier and using those statistics to fine tune the threshold is typically done when the threshold that was automatically established during training is not working as well as you require. You must have some anomalous images (in the test dataset) to realistically adjust the threshold and calculate statistics. Calculating statistics can also shed some light on other improvements that you can make at training. For more information about how to fine tune the threshold and calculate statistics (MclassStatCalculate()), see the Adjusting the trained threshold and calculating statistics section later in this chapter. Predict with your classifier To predict with the trained classifier context, perform the following: Preprocess the trained classifier context, using MclassPreprocess(). Perform the prediction operation with the trained classifier context and the target data that you want to classify (for example, target images), using MclassPredict(). If you perform the prediction operation with a dataset as your target, you can hook functions to prediction events, using MclassHookFunction(). If you are predicting with a test dataset and the results are not what you expect, when compared to what is labeled anomalous in the test dataset, you can adjust your training setup, and continue the training process. Retrieve the required results from the prediction result buffer, using MclassGetResult(). You can also draw prediction results, using MclassDraw(). Save your classification contexts If necessary, save your classification contexts, using MclassSave() or MclassStream(). Free your allocated objects Free all your allocated objects, using MclassFree(), unless M_UNIQUE_ID was specified during allocation. Steps to perform anomaly detection Perform all required allocations Build and populate your dataset Train your classifier context Evaluate your trained classifier Threshold and statistics Predict with your classifier Save your classification contexts Free your allocated objects ",
      "wordCount": 2095,
      "subEntries": []
    },
    {
      "id": "UG_ML_Anomaly_detection_Building_a_dataset_for_anomaly_detection",
      "version": null,
      "title": "Building a dataset for anomaly detection",
      "subTitles": [
        "Populate the source dataset context",
        "Splitting your dataset",
        "Augmentation and other data preparations",
        "Exporting and importing a dataset",
        "Export",
        "Import"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\Building_a_dataset_for_anomaly_detection.htm",
      "text": " Building a dataset for anomaly detection This section discusses specific options for building the images dataset needed for anomaly detection. For an overview of the many considerations you should make when building a dataset, see Chapter 48: Datasets. It is recommended that you use MIL CoPilot to create, label, modify, augment, and export your dataset interactively. Populate the source dataset context For anomaly detection, you must have both a training and a development image dataset; a testing dataset is optional. The training dataset is used to learn the representation of good (for example, defect-free) images. The development dataset is used to determine the threshold that differentiates the good images from the anomalous ones. The testing dataset is used to evaluate the trained classifier, adjust the threshold, and calculate statistics. Ideally, good images should typically be split among the datasets equally (1/3 in the development dataset, 1/3 in the testing dataset, and 1/3 in the training dataset). The following table summarizes the use of valid (not anomalous) and invalid (anomalous) images in a dateset when performing anomaly detection. Images Used in training Used in testing to tweak/validate training (optional) Used in prediction (deployment) Not anomalous (Valid, good, acceptable) Yes - many, no labeling required. Yes - some, no labeling required. If possible, there should be as many good images in testing as there was in training. Yes - there should be many and they should be similar to images used in training/testing. Anomalous (Invalid, bad, unacceptable) No - in fact, there must be any. Yes - a few, identified as anomalous. You should provide as many as possible, if you have them. Yes - there should be few and, though they need not be similar to images used in testing, it can be difficult to determine performance on anomalous type images that were not tested. You must only specify good (non-anomalous) images in the development and training datasets. That is, entries in the datasets used for training (the development and training datasets) cannot have a class definition that has M_ANOMALOUS set to M_TRUE. This control is set to M_FALSE by default and can optionally be set to true for some entries in a test dataset to help adjust the trained threshold and calculate statistics after training is done. For more information, see the Adjusting the trained threshold and calculating statistics section later in this chapter. It is possible that the datasets for anomaly detection hold images representing many classes, often from datasets used for other machine learning tasks, such as image classification, segmentation, and object detection. Anomaly detection only checks for the M_ANOMALOUS value, while all other machine learning tasks ignore M_ANOMALOUS. Splitting your dataset You can call MclassSplitDataset() to split a dataset into two smaller datasets. You can do this to create a training, development, and testing dataset out of your source dataset. If you want to use a testing dataset, you should first split a portion of the source dataset into a testing dataset by calling MclassSplitDataset() with M_SPLIT_ANO_CONTEXT_DEFAULT or M_SPLIT_ANO_CONTEXT_FIXED_SEED. After isolating the testing dataset, you can then create the development and training datasets. When using MclassSplitDataset() to split a dataset with anomalous entries (that is, the source dataset has classes with M_ANOMALOUS set to M_TRUE), all anomalous entries will be in the second destination dataset (DstSecondDatasetContextClassId). In this case, the specified percentage (Percentage) controls what percentage of good (non-anomalous) entries go into the first and second destination datasets. Note that datasets with anomalous entries cannot be used for training. When training an anomaly detection classifier, you must explicitly specify both a development dataset and a training dataset (you cannot, for example, specify a single dataset when calling MclassTrain()). The development dataset must not contain data (image entries) that are in the training dataset. Also, only the training dataset can have augmented entries (the development dataset and the testing dataset must not). For more information about the different datasets, see the Different datasets and how they are split section of Chapter 48: Datasets. Augmentation and other data preparations Optionally, you can add augmented images to the training dataset, using MimAugment(). You can, for example, increase the entries in your training dataset by randomly rotating, translating, and blurring images. As with any machine learning task, anomaly detection requires images that are the same size. It is therefore common practice to prepare your data by cropping or resizing images. Augmentation, although not required, is also quite common. To resize, crop, or augment your images, you can use MclassPrepareData() (which can also be done from MIL CoPilot). To use MclassPrepareData(), you can specify a data preparation context that is for image classification, segmentation, or object detection (note that there is no dedicated data preparation for anomaly detection). The resulting images in the destination dataset or buffer can then be used for anomaly detection. In this case, it is important to select the data preparation context that is consistent with your labeling. For more information, see the Data augmentation and other data preparations section of Chapter 48: Datasets. Exporting and importing a dataset Exporting and importing a dataset allows you to make it portable and organized. This will let you to easily reuse or combine your datasets. It is not uncommon to use preexisting datasets for anomaly detection, such as datasets already created for other machine learning tasks, like image classification or segmentation. For more information, see the Guidelines for managing an images dataset section of Chapter 48: Datasets. Export After you build a dataset, export it using MclassExport(). It is recommended that you export it with M_IMAGE_DATASET_FOLDER to create an organized folder than can be easily imported and reused. Import You can use a folder or CSV file to define data for a dataset. To import it to a dataset context, use MclassImport() and specify what to import (for example, M_IMAGE_DATASET_FOLDER or M_COMPLETE). For more information about importing data, see the Importing data from a folder or CSV file section of Chapter 48: Datasets. You can also use MclassRestore() to restore a dataset that was previously saved to a file using MclassSave() or MclassStream(). Building a dataset for anomaly detection Populate the source dataset context Splitting your dataset Augmentation and other data preparations Exporting and importing a dataset Export Import ",
      "wordCount": 1041,
      "subEntries": []
    },
    {
      "id": "UG_ML_Anomaly_detection_Classifier_and_training_settings_for_anomaly_detection",
      "version": null,
      "title": "Classifier and training settings for anomaly detection",
      "subTitles": [
        "Training objects and folders",
        "Training modes and related settings"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\Classifier_and_training_settings_for_anomaly_detection.htm",
      "text": " Classifier and training settings for anomaly detection Before you can start training, you need to allocate a classifier context and training objects, and set training related settings. For more information on training settings, see the Fundamental decisions and settings section of Chapter 49: Training. Training objects and folders Allocate a training context, using MclassAlloc() with M_TRAIN_ANO. A training context holds the settings with which to train a classifier context, such as the training mode. You will also need to allocate a training result buffer to hold training results, using MclassAllocResult() with M_TRAIN_ANO_RESULT. Training modes and related settings For anomaly detection, you must perform a complete training; that is, each training session is a fresh and total training of the classifier. MIL automatically sets the settings related to the complete training. You can also modify these by calling MclassControl(). For example, you can adjust the: Mode in which the samples are selected (M_TRAIN_MODE). By default, this is automatically set to a global selection (M_GLOBAL_SAMPLING). Size of each mini-batch (M_MINI_BATCH_SIZE). The default size is 1. MIL uses mini-batches to split the training dataset to help make the training process more efficient. Number of mini-batches loaded into memory before sampling (M_MINI_BATCHES_PER_SAMPLING) when M_TRAIN_MODE is set to M_ITERATIVE_SAMPLING. The default number is 1. Number of patches to determine the sample size (M_SAMPLES_FIXED_SIZE). The default number is 4000. By default, MIL tries to perform a global type of training, with M_TRAIN_MODE being set to M_GLOBAL_SAMPLING, but this can lead to running out of GPU memory. In this case, it is recommended to set M_TRAIN_MODE to M_ITERATIVE_SAMPLING, and then increase M_MINI_BATCHES_PER_SAMPLING until you maximize GPU usage. Such training mode controls are also known as hyperparameters. If your classifier is not performing as expected, you can adjust them and retrain (specifically, M_SAMPLES_FIXED_SIZE can affect the classifier's performance). Once you have established your training mode controls (and all other settings for your training context), you must preprocess the context by calling MclassPreprocess() with the identifier of the training context before training. Classifier and training settings for anomaly detection Training objects and folders Training modes and related settings ",
      "wordCount": 351,
      "subEntries": []
    },
    {
      "id": "UG_ML_Anomaly_detection_Training_and_analysis_for_anomaly_detection",
      "version": null,
      "title": "Training and analysis for anomaly detection",
      "subTitles": [
        "Monitoring the training process",
        "Results"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\Training_and_analysis_for_anomaly_detection.htm",
      "text": " Training and analysis for anomaly detection When you call MclassTrain(), the classifier context will be trained with the settings specified in the training context, and trained on the data in the training and development datasets. The results from training will be stored in the classification result buffer. These must all be specified when you call MclassTrain(). For more information on the training process, and training analysis, see the Analysis, adjustment, and additional settings section of Chapter 49: Training. Monitoring the training process You can save time and improve the training process by using MclassHookFunction() to hook a function to a training event, such as M_SAMPLE_ADDED. While your classifier is training, you can get the information from the events that caused the hook-handler function to execute by using MclassGetHookInfo(). Training can take a long time, and you can use hook functions to monitor the training process. For most machine learning tasks, you should typically expect to monitor the training process for proper convergence, and to make modifications to the process. You might need to abort or restart it, if required. Anomaly detection, however, does not converge in the same way. The sample loss is essentially guaranteed to go down with each sample added. It is likely that you probably want a sample's fixed size that is large enough for the sample loss to almost plateau (note, however, that it will not actually plateau). Results After the training process is done, you can retrieve your training results by calling MclassGetResult() with the training result buffer that MclassTrain() produced. For example, you can retrieve which images in the development dataset (M_DEV_DATASET_USED_ENTRIES) and training dataset (M_TRAIN_DATASET_USED_ENTRIES) were used during training. To retrieve the status of the training, use M_STATUS. If your training results are not what you expect, then you can make adjustments and train again. To do so, copy the classification result buffer into a classifier context, using MclassCopyResult() with M_TRAINED_CLASSIFIER. Training and analysis for anomaly detection Monitoring the training process Results ",
      "wordCount": 331,
      "subEntries": []
    },
    {
      "id": "UG_ML_Anomaly_detection_Adjusting_the_trained_threshold_and_calculating_statistics",
      "version": null,
      "title": "Adjusting the trained threshold and calculating statistics",
      "subTitles": [
        "Score threshold"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\Adjusting_the_trained_threshold_and_calculating_statistics.htm",
      "text": " Adjusting the trained threshold and calculating statistics Ideally, training images contain all expected variations of good images, and any difference would be an anomaly. In practice, this is rarely the case. To help determine how different an image can be, before it is considered anomalous, MIL automatically establishes a threshold for the trained classifier, which you can optionally modify (fine tune) to help fit your application's needs. Evaluating the threshold requires using the trained classifier to predict on your testing dataset. Since this is intended to mimic a real life scenario, the testing dataset must contain some anomalous images. If after testing you are satisfied with your results, it means the trained threshold needs no adjustment and you can deploy. To specify anomalous data in your testing dataset, you must call MclassControl() with M_CLASS_INDEX(), and set M_ANOMALOUS to M_TRUE. By default, every dataset entry is considered not anomalous, unless you explicitly identify it this way; that is, you specify that one or more classes are anomalous (for example, you set M_ANOMALOUS to M_TRUE for Class01), and then you assign entries in the dataset to that class (for example, the class of anomalous entries have their ground truth set to Class01). If multiple classes are identified as anomalous (for example, Class01, Class02, and Class03 all have M_ANOMALOUS set to M_TRUE), their anomalous data is used as a type of super-anomalous-class. Adjusting the threshold is often done with performing a statistical analysis of your dataset (MclassStatCalculate()). That is, you can analyze a trained classifier's performance by computing metrics on predicted datasets, which can give you some guidance on adjusting the threshold. Additional anomaly detection documentation, such as how to calculate statistics, will be added to the MIL Help that is available online at zebra.com/aurora-imaging-library-help. Score threshold The trained classifier's threshold level is based on an internal calculation established during training that evaluates scores, and when they more likely indicate that a result is anomalous or not. By increasing or decreasing the trained classifier's threshold (score evaluation) control, which you would do prior to performing a prediction on a test dataset with the trained classifier, you can influence which images and pixels are or are not anomalous. To fine tune the trained threshold, you must call MclassControl() with the identifier of the trained classifier context and adjust the M_SCORE_THRESHOLD setting (this is done post training). Lowering the M_SCORE_THRESHOLD value can allow you to detect more anomalous cases, but at the potential cost of incorrectly detecting good (non-anomalous) cases as anomalous ones. Conversely, increasing the M_SCORE_THRESHOLD value can decrease the likelihood of incorrectly detecting good non-anomalous cases as anomalous, but at the potential cost of missing actual anomalous ones. The following is an example of a score analysis in a real-life scenario, such as a testing dataset, and therefore contains anomalous results. With regards to this example, note: If you perform this score analysis on another real life scenario, such as another testing dataset or on prediction results from a production line, the trained threshold would not land at the same location as in this example (where it lands depends on the target images in that scenario). If you perform this score analysis on the development dataset, there would be no anomalous score results (red line), since the development dataset must only have good images (since there are only good images, no labeling is needed). Also, in the development dataset, the trained threshold is going to be to the right of the highest score. If you perform this score analysis in an ideal scenario, the curves (anomalous/non-anomalous) would not overlap. As previously discussed, there are no labeling requirements for the training and development datasets. Optionally, the testing dataset is labeled with anomalous images only if you want to evaluate the threshold and compute statistics (MclassStatCalculate()). It can be labeled as a classification or segmentation dataset depending on the type of statistics you need; that is, if you need image statistics or pixel statistics. Also, as previously discussed, the trained classifier's threshold level (M_SCORE_THRESHOLD) is based on an internal calculation established during training. This value is always represented as 50 initially, as this is the convention for indicating the relative point from which you can make adjustments. For example, to make it easier to find anomalous cases, you can lower M_SCORE_THRESHOLD to 45, and to make it harder to find anomalous cases, you can increase it to 55. At any time you can put back the originally trained threshold by setting M_SCORE_THRESHOLD to 50 (or M_DEFAULT). To get a real-life sense for the classifier's performance after analyzing different statistics, you can perform a variety of drawing operations, such as drawing anomalous pixels, scores, heat maps, and contours. For more information, see the Drawing results subsection of the Prediction for anomaly detection section later in this chapter. For more information about adjusting the threshold and calculating statistics, refer to the MIL Help that is available online at zebra.com/aurora-imaging-library-help. You can also refer to the following example: classanomalydetectioncompletetrain.cpp Adjusting the trained threshold and calculating statistics Score threshold ",
      "wordCount": 842,
      "subEntries": []
    },
    {
      "id": "UG_ML_Anomaly_detection_Prediction_for_anomaly_detection",
      "version": null,
      "title": "Prediction for anomaly detection",
      "subTitles": [
        "Prepare for prediction",
        "Predict",
        "Results",
        "Drawing results",
        "Assisted labeling"
      ],
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\Prediction_for_anomaly_detection.htm",
      "text": " Prediction for anomaly detection MclassPredict() uses a trained classifier context to make class predictions on a target. For a trained anomaly detection classifier, your target can be either an image or a dataset of images. For more information about prediction, see the Prediction settings, results, and drawings section of Chapter 50: Prediction. Prepare for prediction To allocate a classification result buffer to hold the prediction results, call MclassAllocResult() with M_PREDICT_ANO_RESULT. Anomaly detection with ADNet classifiers require target images that are the same size as the images used during training. The size of the training images can be inquired using MclassInquire() with M_SIZE_X and M_SIZE_Y. Before predicting, preprocess your trained classifier context using MclassPreprocess(). Predict Perform the prediction operation with the trained classifier context and the target data that you want to classify using MclassPredict(). If your training images were prepared by cropping and resizing, then the target image must also be prepared in the same way. This maintains consistency between the training data and the target data. As mentioned, the size of the target images at prediction must be the same as the images used to train your ADNet classifier. When performing the prediction operation with a dataset as your target, you can hook functions to prediction events, using MclassHookFunction(). Results With anomaly detection, you can retrieve image type results (similar to image classification) or pixel type results (similar to segmentation). For example, you can call MclassGetResult() to retrieve whether an image is anomalous (M_IMAGE_PREDICTED_ANOMALOUS) or whether each pixel in the image is anomalous (M_MASK_IMAGE). Regardless of how many classes you have in your datasets, images or pixels are predicted as either anomalous or not, and the resulting anomalous scores are calculated. Getting the score of the anomalous results (that is, M_IMAGE_SCORE and M_PIXEL_SCORES) can help shed some light on the accuracy of those results. Note that if M_IMAGE_SCORE &gt;= M_SCORE_THRESHOLD, the image will be anomalous. Similarly, pixels will be anomalous if M_PIXEL_SCORES &gt;= M_SCORE_THRESHOLD. You can also get results from a specific entry in a dataset using MclassGetResultEntry(). Drawing results To draw results, you can call MclassDraw(). For example, you can draw the anomalous pixels (M_DRAW_ANOMALY_MASK), the anomaly scores (M_DRAW_ANOMALY_SCORES), the anomaly scores projected as a heat map (M_DRAW_ANOMALY_HEATMAP), and the contour of the anomalies (M_DRAW_ANOMALY_CONTOUR_MASK). You can also draw prediction results from a specific entry in a dataset using MclassDrawEntry(). In general, drawing operations for prediction results can prove particularly useful when performing an anomaly detection prediction with a child buffer or a buffer with a region. Drawing can also give you a real-life sense for the classifier's performance after analyzing different stats. Assisted labeling You can perform assisted labeling for anomaly by adding prediction results to your dataset. For more information about assisted labeling, see the Assisted labeling subsection of the Advanced techniques section of Chapter 50: Prediction. Prediction for anomaly detection Prepare for prediction Predict Results Drawing results Assisted labeling ",
      "wordCount": 486,
      "subEntries": []
    },
    {
      "id": "UG_ML_Anomaly_detection_Anomaly_detection_example",
      "version": null,
      "title": "Anomaly detection example",
      "subTitles": null,
      "location": "MIL UG P08: Machine learning tasks",
      "pageURL": "content\\UserGuide\\ML_Anomaly_detection\\Anomaly_detection_example.htm",
      "text": " Anomaly detection example The example ClassAnomalyDetectionCompleteTrain.cpp demonstrates how to train a predefined (Matrox defined) anomaly detection classifier context to detect defects on the top of glass bottles. This example also shows you how to evaluate the performance of the trained classifier on the test dataset, using MclassStatCalculate(). To run this example, use the Matrox Example Launcher in the MIL Control Center. To view this example, refer to the following: classanomalydetectioncompletetrain.cpp Anomaly detection example ",
      "wordCount": 75,
      "subEntries": []
    }
  ]
}]