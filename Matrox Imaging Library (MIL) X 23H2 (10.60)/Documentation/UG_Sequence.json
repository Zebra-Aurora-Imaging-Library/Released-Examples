[{
  "id": "UG_Sequence",
  "version": "2024020714",
  "title": "Sequences",
  "subTitles": null,
  "location": "MIL UG P04: 2D related information",
  "pageURL": "content\\UserGuide\\Sequence\\ChapterInformation.htm",
  "text": " Chapter 31: Sequences This chapter describes how to perform operations on sequences of images. MIL Sequences module overview Steps to performing a sequence operation Basic concepts for the MIL Sequences module Setting your inputs and outputs Compressing and decompressing a sequence of images Inputs and outputs of an H.264 compression or decompression Controlling an H.264 compression Frame rate Resolution Bit rate Compression level Compression profile Compression priority Group-of-pictures size Guidelines for setting H.264 compression controls ",
  "wordCount": 77,
  "subEntries": [
    {
      "id": "UG_Sequence_Sequences_overview",
      "version": null,
      "title": "MIL Sequences module overview",
      "subTitles": null,
      "location": "MIL UG P04: 2D related information",
      "pageURL": "content\\UserGuide\\Sequence\\Sequences_overview.htm",
      "text": " MIL Sequences module overview The MIL Sequences module allows you to perform operations on sequences of images. Depending on your settings, the Sequences module will perform one of two operations: H.264 compression or decompression. H.264 compression uses predictive encoding to compress sequences of images. You can feed the images to process all at once or individually. The H.264 compression that the Sequences module performs is highly customizable and you can tweak it for your application. For example, you can decide whether to put more emphasis on the quality of the elementary video stream or its resulting size. The module can also decompress an H.264 compressed stream and save the result in one or many files or buffer lists. If you want to save your sequence such that the elementary video stream does not use predictive encoding, you can use MbufExportSequence() to save images in MJPEG, MIL, and non-compressed DIB format. You can use MbufImportSequence() to import a sequence saved in one of these three formats into separate image buffers. MIL Sequences module overview ",
      "wordCount": 175,
      "subEntries": []
    },
    {
      "id": "UG_Sequence_Steps_to_performing_a_sequence_operation",
      "version": null,
      "title": "Steps to performing a sequence operation",
      "subTitles": null,
      "location": "MIL UG P04: 2D related information",
      "pageURL": "content\\UserGuide\\Sequence\\Steps_to_performing_a_sequence_operation.htm",
      "text": " Steps to performing a sequence operation The following steps provide a basic methodology for using the MIL Sequences module: Allocate a sequence context using MseqAlloc(). The sequence context is required to indicate the sequence operation that the Sequences module should perform and to hold the sequence operation settings. When allocating the context, choose the required sequence operation, and select the underlying hardware or software that the operation should use. Define the source of each input and the destination(s) of each output of your sequence operation, using MseqDefine(); each output can have multiple destinations. By default, the source of an input is set to M_USER_FEED; in which case, MIL expects the images to be passed individually (manual image feed). By default, the destination of an output is set to M_USER_HOOK; in which case, MIL assumes that you will retrieve the images individually from the processing operation's internal output buffer, using a hook function. If the destination of an output is a hook-based retrieval, hook a function to the event that occurs when a frame has finished being processed, using MseqHookFunction(). Specify the processing operation settings and any additional settings for your sources and destinations, using MseqControl(). Start the sequence processing session, using MseqProcess() with M_START. You must also specify whether the session will run synchronously or asynchronously. If you specify M_SYNCHRONOUS, your application will wait until the sequence operation has finished before executing the next function; this option is not available if the source of an input is a manual image feed. If you specify M_ASYNCHRONOUS, other functions can execute while the sequence operation is performed in a background thread. If the source of an input is a manual image feed, feed each image to the sequence processing operation, using MseqFeed(). Stop the sequence processing session, using MseqProcess() with M_STOP specifying M_WAIT. The sequence processing session will finish performing the specified operation before stopping. Free your sequence context, using MseqFree(), unless M_UNIQUE_ID was specified during allocation. Steps to performing a sequence operation ",
      "wordCount": 333,
      "subEntries": []
    },
    {
      "id": "UG_Sequence_Basic_concepts_for_the_MIL_sequences_module",
      "version": null,
      "title": "Basic concepts for the MIL Sequences module",
      "subTitles": null,
      "location": "MIL UG P04: 2D related information",
      "pageURL": "content\\UserGuide\\Sequence\\Basic_concepts_for_the_MIL_sequences_module.htm",
      "text": " Basic concepts for the MIL Sequences module The basic concepts and vocabulary conventions for the MIL Sequences module are: Destination. The location in which the output of the specified operation is saved. Elementary video stream. A video composed of a sequence of frames containing no audio component. Video container format. A format that can contain an elementary video stream, as well as other elements such as audio and subtitles. AVI and MP4 are video container formats. Frame. One of the successive images forming a video. H.264 compression. An advanced compression standard that uses predictive frames to maximize compression efficiency. I-frame. A frame containing all the data necessary to decode it independently of other frames. I-frames are the least compressible H.264 frames. Operation. An action performed on a certain number of inputs and having a certain number of outputs. The H.264 compression and decompression operations each have one input and one output. Predictive frame (P-frame) and bi-predictive frame (B-frame). A frame contained within an elementary video stream that cannot be indepently decoded into a full image. It must refer to other frames in the stream during playback to be properly decoded. P- and B-frames are more compressible than I-frames. Source. The location from which the input of the operation is taken. Basic concepts for the MIL Sequences module ",
      "wordCount": 219,
      "subEntries": []
    },
    {
      "id": "UG_Sequence_Setting_your_inputs_and_outputs",
      "version": null,
      "title": "Setting your inputs and outputs",
      "subTitles": null,
      "location": "MIL UG P04: 2D related information",
      "pageURL": "content\\UserGuide\\Sequence\\Setting_your_inputs_and_outputs.htm",
      "text": " Setting your inputs and outputs Once you have allocated your sequence context and specified the operation to perform, you must set the sources and destinations of the inputs and outputs of your operation, respectively, using MseqDefine(). The specified operation is characterized by a certain number of inputs and a certain number of outputs. Each input can only take one source, but each output can be saved in multiple destinations. To define the source of an input, choose the source of which input to define using M_SEQ_INPUT() and then select the type of its source. To define a destination of an output, use M_SEQ_OUTPUT() + M_SEQ_DEST() to select which destinations of an output to set and then select the type of this destination; each output can have 32 destinations. The source of the input can be a file (M_FILE), a buffer list (M_BUFFER_LIST), or a manual image feed, where the images are passed individually (M_USER_FEED). The destination(s) of an output can be files, buffer lists, or the data can be retrieved from the internal output buffer of the sequence processing operation using a hook function (M_USER_HOOK). A buffer list is essentially a list of image buffers, whose individual buffer identifiers are passed using a user array. AVI, MP4, and elementary H.264 are supported formats for file sources and destinations. Depending on the operation, certain types might not be supported as a source of an input or a destination of an output; for example, a buffer list cannot be used as the source of an input for a decompression operation or as the destination of an output for a compression operation. By default, when you allocate your sequence context, MIL defines an M_USER_FEED source for each input and an M_USER_HOOK destination for your output(s). If the source of an input is set to a file or buffer list, the operation will be performed as soon as the sequence processing operation is started using MseqProcess(). However, if the source is an image feed, you must perform additional steps after starting the operation. If the source of an input is an image feed, you must feed each image individually. Feeding your images individually is useful when your images are available gradually. For example, you might want to perform the sequence processing operation on an image immediately after it has been grabbed, preprocessed, and/or analyzed. To feed an image, call MseqFeed() with the identifier of the buffer in which the image is stored. As soon as an image is fed, it is copied to the internal queue of the sequence processing operation where it waits to be operated on. Images can only be fed if M_ASYNCHRONOUS is specified when starting the operation. If using MdigProcess() to grab, process, and/or analyze each image on which you want to perform a sequence processing operation (for example, sequence compression), you can make the call to MseqFeed() from the hook function of MdigProcess(). If your images are fed faster than they are operated on by the sequence operation, the queue will fill and MseqFeed() will wait for the queue to free up before returning control to the calling thread. This will cause your processing function to stall, and frames might be dropped. Once images are operated on by the sequence processing operation, they are written to an internal output buffer before being copied to the specified destination. If you set M_USER_HOOK as the destination and this is the only destination, the output of the operation will be lost unless you retrieve it with a hook function. You can use MseqHookFunction() with M_FRAME_END to hook a user-defined function that will be called every time the internal output buffer is modified. You can call MseqGetHookInfo() with M_MODIFIED_BUFFER + M_BUFFER_ID from within your user-defined function to inquire the MIL identifier of the internal output buffer. You can use hook functions to retrieve data about the internal output buffer, even if a file and/or buffer list destination is specified. Setting your inputs and outputs ",
      "wordCount": 663,
      "subEntries": []
    },
    {
      "id": "UG_Sequence_Compressing_and_decompressing_a_sequence_of_images",
      "version": null,
      "title": "Compressing and decompressing a sequence of images",
      "subTitles": [
        "Inputs and outputs of an H.264 compression or decompression",
        "Controlling an H.264 compression",
        "Frame rate",
        "Resolution",
        "Bit rate",
        "Compression level",
        "Compression profile",
        "Compression priority",
        "Group-of-pictures size",
        "Guidelines for setting H.264 compression controls"
      ],
      "location": "MIL UG P04: 2D related information",
      "pageURL": "content\\UserGuide\\Sequence\\Compressing_and_decompressing_a_sequence_of_images.htm",
      "text": " Compressing and decompressing a sequence of images The Sequences module allows you to compress and decompress sequences of images using the H.264 standard. To compress a sequence, you must allocate a sequence context using MseqAlloc() with M_SEQ_COMPRESS; to decompress a sequence, you must allocate a sequence context using MseqAlloc() with M_SEQ_DECOMPRESS. When allocating the sequence context, you must also specify whether the compression and decompression will be performed in hardware or software. By default, MIL will select the most appropriate option for your computer. If your processor supports Intel's Quick Sync Video (QSV), the compression and decompression will be hardware accelerated. If your processor does not have a QSV engine, the Sequences module will perform the compression or decompression in software. H.264 video encoding is optimized for Intel CPUs and can be subject to performance and stability issues when used with other CPUs. H.264 compression algorithms achieve high compression ratios by eliminating redundant information between frames. In many videos, changes from one frame to the next are relatively minor. Objects present in one frame are often present in the next. Even if they have moved, the pixels forming the objects themselves are the same. Therefore, it is a waste to allocate space for these unchanging objects in every frame. H.264 achieves compression by dividing the frames into groups, where the first frame of the group, known as the I-frame, contains all the data necessary to regenerate the original image that it represents. The other frames in the group are composed of B- and P-frames, which are defined relative to I-frames or other B- and P- frames. H.264 compression further segments frames into macroblocks, and only the differences in macroblocks between frames are recorded in the B- and P-frames. Inputs and outputs of an H.264 compression or decompression Both a sequence compression and a sequence decompression operation take a single input and produce a single output. The compression operation outputs an elementary video stream composed of fully defined I-frames, and referential P- and B-frames. The data of these frames can be retrieved individually in raw format from the internal output buffer using a hook function and/or saved as a sequence in raw format in an H.264 elementary video data file (M_FILE_FORMAT_H264). The frames can also be saved as a sequence wrapped in an AVI (M_FILE_FORMAT_AVI) or MP4 (M_FILE_FORMAT_MP4) video container file. Viewing the H.264 file (in either its raw form or in a video container format) on a computer requires the use of an H.264 compliant-third party media player such as VLC. The decompression operation outputs an elementary video stream composed entirely of fully defined uncompressed images. You can access each image individually using a hook function or save them in an AVI file or buffer list. Controlling an H.264 compression Once you have allocated your sequence context for a compression operation, you can customize the compression operation using MseqControl(). For example, to fit the requirements of your application, you can select the appropriate: Frame rate of the elementary video stream. Resolution of the I-frames. Bit rate of the elementary video stream. Compression level. Compression profile. Compression priority. Group-of-pictures size. Frame rate An elementary video stream is composed of a sequence of images called frames. The number of frames per second of video is referred to as the frame rate. In some applications, a low frame rate will suffice. For example, a slideshow with an image being displayed every five seconds will have a frame rate of 0.2 frames per second (frames/sec). In other applications such as movies, a higher frame rate is required to give viewers the illusion of movement. Increasing the frame rate requires a higher bit rate to maintain the stream's quality since more information is being output per second. You can set the frame rate using MseqControl() with M_STREAM_FRAME_RATE. If you are using M_FILE destination types, and are uncertain if the processor can encode at the specified frame rate during a live grab, you can use MseqControl() with M_STREAM_FRAME_RATE_MODE set to M_VARIABLE to have the average encoding frame rate written in the header of the file as the decoding frame rate. This will allow playback at more natural speeds. For example, if you are grabbing at a rate of 40 frames/sec but the processor is encoding at a rate of 20 frames/sec, 20 frames will be missed per second. If you playback the compressed sequence at a rate of 40 frames/sec, the 20 frames that were encoded will be played back unnaturally fast (that is, in the first half-second). Using M_STREAM_FRAME_RATE_MODE set to M_VARIABLE, would set the playback rate to 20 frames/sec so that the 20 frames would be played back at a more natural speed (even if there are frames missing). Resolution You can set the size of the images to compress into the elementary video stream by specifying a sample image buffer. Passing a sample image buffer is useful because it improves the performance of the sequence operation, by initializing the engine before the first image is fed. Set the resolution of your images by passing a sample image buffer using MseqControl() with M_BUFFER_SAMPLE. Note that this operation only saves information about the image and does not save the image itself. Bit rate The bit rate is the amount of data, in kbits, used to represent one second of the elementary video stream. You can determine the total size of the elementary stream in kbits by multiplying its average bit rate by its duration in seconds. You can choose either a constant or variable bit rate. If you choose a constant bit rate using MseqControl() with M_STREAM_BIT_RATE_MODE set to M_CONSTANT, the same number of bits will be used to represent each second of video. In this case, you must specify the bit rate value using M_STREAM_BIT_RATE. If you choose a variable bit rate using M_VARIABLE, the bit rate will fluctuate and a different number of bits will be used to represent each second of the elementary video stream. In this case, you must specify the target average bit rate using M_STREAM_BIT_RATE. It is usually more efficient to use a variable bit rate instead of a constant bit rate because some sections of an elementary video stream are generally more compressible than others. For example, a scene with a lot of movement is less compressible than a scene that is mainly stationary. With a variable bit rate, more bits will be allocated to the less compressible sections of the video, and less bits will be allocated to the more compressible sections of the video. When using a variable bit rate, you must also specify the maximum possible bit rate the elementary video stream can have using M_STREAM_BIT_RATE_MAX. This will limit the bit rates of less compressible sections of video. This is important because if the bit rate exceeds the available bandwidth of an Internet or network connection, the video will lag. M_STREAM_BIT_RATE_MAX is ignored if you use a constant bit rate. The maximum bit rate of your elementary video stream should not exceed the maximum bit rate allowed by the specified compression level and profile. For information on appropriate bit rate values, see Guidelines for setting H.264 compression controls. Compression level H.264 compression divides each frame into groups of 256 pixels (16x16) called macroblocks. The compression level limits the number of macroblocks per second, which restricts the possible frame rate and resolution that you can specify for your elementary video stream. The compression level also limits the bit rate that you can specify. Setting the compression level prevents devices from attempting to playback streams that would require too much processing power and memory to decode. You can set the compression level using MseqControl() with M_STREAM_LEVEL. For information on setting the correct compression level, see Guidelines for setting H.264 compression controls. Compression profile The compression profile determines the allowed complexity of the compression operation. For example, a high profile (M_PROFILE_HIGH) will allow the compression operation to make use of the more sophisticated features of the H.264 standard. This will improve the compression ratio, but more processing power will be required to decode the elementary video stream. It might be necessary to chose a lower profile if the stream might be played back on devices with limited processing power. To set the profile, use MseqControl() with M_STREAM_PROFILE. Compression priority The compression priority determines whether more importance is placed on reducing the time it takes to compress the sequence or maximizing the quality of the resulting elementary video stream. You can set the compression priority using MseqControl() with M_STREAM_QUALITY. Group-of-pictures size A group of pictures contains one I-frame followed by several P- and B- frames. I-frames contain all the data necessary to regenerate the original image that it represents. In contrast, P- and B-frames contain only the changes between consecutive images. Therefore, I-frames are more accurate, but less compressible. Reducing the group-of-pictures size reduces the time it takes to recover from a decrease in quality caused by a dropped frame, but it will also increase the required bit rate. In most cases, the default size of the group of pictures (MseqControl() with M_STREAM_GROUP_OF_PICTURE_SIZE) is appropriate. However, if you want more control over your compression, you can specify a custom group-of-pictures size. Guidelines for setting H.264 compression controls The frame rate, bit rate, compression profile, and compression level of your H.264 elementary video stream are interdependent and specifying a certain value for one of these settings can restrict the range of acceptable values for the other settings, as well as supported image resolutions. For example, as previously discussed, the compression level will limit the maximum possible bit rate of your stream. If you specify a bit rate not supported by the compression level, or specify any set of incompatible settings, an error will be generated or your settings will be internally modified, potentially producing unintended results. Therefore, you should take note of the following guidelines when setting up your H.264 compression. If you set M_SETTING_AUTO_ADJUSTMENT to M_DISABLE, using MseqControl(), the Sequences module will not automatically adjust incompatible settings; instead, it will generate an error. If you set M_SETTING_AUTO_ADJUSTMENT to M_ENABLE, the Sequences module will automatically adjust incompatible settings. In this case, you can inquire the values used internally using MseqInquire() with the M_EFFECTIVE_VALUE combination constant. In general, you should first specify the required frame rate for your elementary video stream (M_STREAM_FRAME_RATE) and, if possible, the resolution of your images (M_BUFFER_SAMPLE). With these settings, you can calculate the number of macroblocks per second it will contain, using the following equation: MacroblocksPerSecond = ceil(Width/16) * ceil(Height/16) * FrameRate Once you calculate the number of macroblocks per second, refer to the table below to choose an appropriate compression level. For example, if your resolution is 320×240 pixels and your frame rate is 36.0 frames/sec, your stream will contain 10,800 macroblocks per second, and you must set your compression level to 1.3 or higher. Next, determine the compression profile that should be used by the compression operation based on how computationally intensive you want the decoding process to be. You can then refer to your compression level to specify a bit rate for your elementary video stream. Although the compression level specifies the maximum bit rate allowed at a given frame rate and resolution, it is often possible to achieve high quality with a lower bit rate. If the quality of the resulting stream is not satisfactory, you can raise the bit rate or lower the resolution and/or frame rate of your stream. Finally, you can choose an appropriate compression priority, and if necessary, a group-of-pictures size. The following table indicates the maximum bit rate and number of macroblocks per second for each H.264 compression level. Sample resolution and frame rate combinations are provided for each compression level. Compression level Maximum number of macroblocks per second Maximum bit rate in kbit/sec (baseline and main profiles) Maximum bit rate in kbit/sec (high profile) Examples of maximum supported resolutions for given frame rates 1 1,485 64 80 128×96@30.9. 176×144@15.0. 1b 1,485 128 160 128×96@30.9. 176×144@15.0. 1.1 3,000 192 240 176×144@30.3. 320×240@10.0. 352×288@7.5. 1.2 6,000 384 480 320×240@20.0. 352×288@15.2. 1.3 11,880 768 960 320×240@36.0. 352×288@30.0. 2 11,880 2,000 2,500 320×240@36.0. 352×288@30.0. 2.1 19,800 4,000 5,000 352×480@30.0. 2.2 20,250 4,000 5,000 352×480@30.7. 720×576@12.5. 3 40,500 10,000 12,500 352×480@61.4. 720×576@25.0. 3.1 108,000 14,000 17,500 720×576@66.7. 1280×720@30.0. 3.2 216,000 20,000 25,000 1,280×720@60.0. 1,280×1,024@42.2. 4 245,760 20,000 25,000 1,280×720@68.3. 1,920×1,080@30.1. 4.1 245,760 50,000 62,500 1,280×720@68.3. 1,920×1,080@30.1. 4.2 522,240 50,000 62,500 1,280×720@145.1. 1,920×1,080@64.0. 2,048×1,080@60.0. 5 589,824 135,000 168,750 1,920×1,080@72.3. 2,048×1,080@67.8. 5.1 983,040 240,000 300,000 1,920×1,080@120.5. 4,096×2,304@26.7. Compressing and decompressing a sequence of images Inputs and outputs of an H.264 compression or decompression Controlling an H.264 compression Frame rate Resolution Bit rate Compression level Compression profile Compression priority Group-of-pictures size Guidelines for setting H.264 compression controls ",
      "wordCount": 2125,
      "subEntries": []
    }
  ]
}]