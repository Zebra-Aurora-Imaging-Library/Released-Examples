[{
  "id": "UG_blob",
  "version": "2024020714",
  "title": "Blob analysis",
  "subTitles": null,
  "location": "MIL UG P03: 2D processing and analysis",
  "pageURL": "content\\UserGuide\\blob\\ChapterInformation.htm",
  "text": " Chapter 6: Blob analysis This chapter describes the basic steps to extract connected regions of pixels (blobs) within an image. Blob analysis overview MIL and blob analysis Steps to performing blob analysis Identifying blobs Segmenting the blob image Preprocessing Adjusting blob analysis processing controls Controlling the image lattice Pixel aspect ratio Setting the blob identification mode and calculations on blobs Returning partial results Selecting blobs Enabling features for calculation Area and perimeter Dimensions Determining the shape Finding the blob location and its bounding box Points of the bounding box aligned with the pixel coordinate system Minimum-area and minimum-perimeter bounding box points Points with respect to the relative world coordinate system Chained pixels Moments Features related to depth maps Features of depth maps Examples Location, length and number of runs Blob reconstruction Merging results A simple merge Border blobs Inclusion state Other remarks Blob analysis example ",
  "wordCount": 147,
  "subEntries": [
    {
      "id": "UG_blob_Blob_analysis_overview",
      "version": null,
      "title": "Blob analysis overview",
      "subTitles": [
        "MIL and blob analysis"
      ],
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Blob_analysis_overview.htm",
      "text": " Blob analysis overview Blob analysis allows you to identify connected regions of pixels within an image, then calculate selected features of those regions. The regions are commonly known as blobs. Blobs are areas of touching pixels that are in the same logical pixel state. This pixel state is called the foreground state, while the alternate state is called the background state. Typically, the background has the value zero and the foreground is everything else (although some control is generally provided to reverse the sense). In many applications, we are interested only in blobs whose features satisfy certain criteria. Since computation is time-consuming, blob analysis is often performed as an elimination process whereby only blobs of interest are considered in further analysis. The steps involved in feature extraction are: Analyze an image and exclude or delete blobs that don't meet determined criteria. Analyze the remaining blobs to extract further features and determine their criteria. Repeat these steps, as necessary, until you have all the blob measurement results you need. Reducing the raw data to just a few feature measurements generally produces more comprehensible and useful results. MIL and blob analysis The MIL package includes a Blob Analysis module that can extract a wide assortment of blob features, such as the blob area, perimeter, maximum diameter at a given angle (Feret diameter), minimum bounding box, and compactness. MIL uses a user-specified blob identifier image to discriminate between blobs and the background. Controls are provided to allow you to specify how this identifier image is interpreted (which pixels are part of which blob). Blobs are considered to consist of either zero or non-zero pixels, depending on the foreground control setting. The non-zero pixels can either have any value or must be set to the maximum value of the buffer (for example, 0xff for an 8-bit image), depending on the identifier type (grayscale or binary). In addition, MIL provides controls to take into account such blob image information as the pixel aspect ratio. For binary feature extractions, such as those that pertain to the overall shape of the blob, the blob identifier image is used for both identification and computation. For grayscale extractions (for example, the mean pixel value in a blob), you must also provide a grayscale image whose pixel values will be used in computation. MIL also allows you to combine computation results and merge them together into one result. It is also sometimes desirable to merge blobs with specific characteristics. MIL supports this feature as well. The module provides some support for camera calibration. Although most results are calculated in pixels, if the blob identifier image has been associated with a camera calibration context, positional results can be returned in calibrated real-world units. If a grayscale image has also been provided, it must have the same camera calibration context for the results to be calibrated. With MIL, you can perform blob analysis on 1-bit, 8-bit or 16-bit unsigned buffers. Blob analysis overview MIL and blob analysis ",
      "wordCount": 497,
      "subEntries": []
    },
    {
      "id": "UG_blob_Steps_to_performing_blob_analysis",
      "version": null,
      "title": "Steps to performing blob analysis",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Steps_to_performing_blob_analysis.htm",
      "text": " Steps to performing blob analysis The following steps provide a basic methodology for using the MIL Blob Analysis module: Allocate a context, using MblobAlloc(). This context is used to specify the features that should be calculated. By default, few features are enabled for calculation. Allocate a buffer for blob analysis results, using MblobAllocResult(). If necessary, adjust global blob analysis settings to fit your application, using successive calls to MblobControl(). Grab or load an image that was captured under the best possible conditions to minimize the amount of preprocessing required. If necessary, reduce the amount of noise in the image. Noise makes the next step more difficult. Segment the image so that blobs are separated from the background and from each other. Typically, this involves binarizing the image so that the background is in one state (zero or non-zero) and the blob pixels are in the other state. This image is known as the blob identifier image. If you plan to perform grayscale calculations, you will need the original grayscale image as well. If necessary, preprocess the blob identifier image. If there are too many noise particles, calculation time will be increased. An opening operation (for non-zero blobs) or a closing operation (for zero blobs) will remove most of the noise particles without significantly affecting real blobs. You might also need to separate touching blobs at this stage (or they will be counted as a single blob). Calculate the required features and analyze the results. This involves the following: Enable the features that should be calculated, using successive calls to MblobControl(). Select the feature(s) to use as a sorting key(s) for results, using MblobControl() with M_SORTn. The calculated results are sorted according to the sorting key selection. Calculate results for the features enabled for calculation, using MblobCalculate(). For this function, you will have to specify the blob identifier image that will be used to identify the blobs and calculate binary features, and (optionally) the grayscale image that will be used to calculate grayscale features. If necessary, exclude or delete blobs that do not meet a required criteria, using successive calls to MblobSelect(). Results for the excluded or deleted blobs will not be returned when calling MblobGetResult(). Excluded blobs will be ignored in future calculations, while deleted blobs will be removed from the blob analysis result buffer altogether and will not be re-included in future calculations. Get the number of blobs currently included, using MblobGetResult() with M_NUMBER, and then retrieve other required results from the blob result buffer, using MblobGetResult(). You can also use MblobGetLabel() to obtain the label value of a specific blob at a specified position. Note that trying to retrieve a result that is not available generates an error. If necessary, preprocess the blob identifier image. If there are too many noise particles, calculation time will be increased. An opening operation (for non-zero blobs) or a closing operation (for zero blobs) will remove most of the noise particles without significantly affecting real blobs. You might also need to separate touching blobs at this stage (or they will be counted as a single blob). You can repeat this step until you obtain all required results for the blobs of interest. Note, the process of excluding or deleting unwanted blobs and then calculating more features is the preferred method if you have many unwanted blobs. If this is not the case, it is often faster to calculate all the required features for all the blobs with a single call to MblobCalculate(), and then exclude or delete unwanted blob results afterwards. Free all your allocated objects, using MblobFree(), unless M_UNIQUE_ID was specified during allocation. Steps to performing blob analysis ",
      "wordCount": 609,
      "subEntries": []
    },
    {
      "id": "UG_blob_Identifying_blobs",
      "version": null,
      "title": "Identifying blobs",
      "subTitles": [
        "Segmenting the blob image",
        "Preprocessing"
      ],
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Identifying_blobs.htm",
      "text": " Identifying blobs The MIL blob analysis capabilities allow you to identify and extract features of connected regions of pixels (commonly known as blobs) within an image. MIL requires a user-specified blob identifier image to determine which pixels belong to which blob in the original image. Blob features involving overall shape are extracted directly from the identifier image. Features that use the actual pixel values of the blob also require the original image. For example: The MIL Blob Analysis module typically considers touching foreground pixels in the blob identifier image to be part of the same blob. Consequently, what is easily identifiable by the human eye as several distinct but touching blobs can be interpreted by MIL as a single blob. In addition, any part of a blob that is in the background pixel state, because of lighting or reflection, is considered as background during analysis. To reduce preprocessing, the blob identifier image should be acquired under the best possible circumstances. This means ensuring that blobs do not overlap and, if possible, don't touch. It also means ensuring the best possible lighting and using a background with a gray level that is very distinct from the gray level of the blobs. If noise is a problem, you might also need to filter the image after acquisition (for example, using a median filter, applying a convolution with M_SMOOTH, or using MimFilterAdaptive()). Segmenting the blob image Once the best possible image is acquired and most noise is filtered out, you must separate the different blobs from the background. Segmentation can be done in two ways: Binarize the image, using MimBinarize() or MimBinarizeAdaptive(), so that background pixels are represented as zero values and blob pixels are represented as another value. Clip all background pixels to zero, while retaining the original values of blob pixels, using MimClip(). This has the advantage of not needing a separate buffer to hold the binary image, but you will not see the result of the segmentation as clearly. MimBinarize() or MimBinarizeAdaptive() are usually better. If simple segmentation is not possible due to poor lighting or blobs with the same gray level as parts of the background, you must develop a segmentation algorithm appropriate to your particular image. Preprocessing Producing the blob identifier image frequently creates some spurious blobs or holes (for example, due to noise or lighting). Such noise blobs make it harder to interpret blob analysis results. If you have many noise blobs, you should probably preprocess the image before using it as an identifier. An opening operation (for non-zero valued blobs or holes) or a closing operation (for zero valued blobs or holes) will remove most noise without significantly affecting real features. If blobs are touching, you might try eroding the image a few times to break them apart. Preprocessing the blob identifier image might affect the accuracy of calculations because of the slight change in blob shape. If this is a problem, perform the calculations on all the blobs, including those that are actually introduced by noise, then use the results to filter out the noise. Note, however, that this might increase the memory required and the calculation time. Identifying blobs Segmenting the blob image Preprocessing ",
      "wordCount": 532,
      "subEntries": []
    },
    {
      "id": "UG_blob_Adjusting_blob_analysis_processing_controls",
      "version": null,
      "title": "Adjusting blob analysis processing controls",
      "subTitles": [
        "Controlling the image lattice",
        "Pixel aspect ratio",
        "Setting the blob identification mode and calculations on blobs",
        "Returning partial results"
      ],
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Adjusting_blob_analysis_processing_controls.htm",
      "text": " Adjusting blob analysis processing controls Before performing any blob analysis calculations, you should ensure the correct interpretation of the blob identifier image. Use MblobControl() to control how certain aspects of the blob identifier image are interpreted, for example: Which pixel values are considered to be in the foreground (M_FOREGROUND_VALUE). Whether non-zero pixels can have any value or must be set to the maximum value of the buffer, for example, 0xff for an 8-bit buffer (M_IDENTIFIER_TYPE). Whether two pixels touching at their corners are considered part of the same blob, by appropriately defining the image lattice (M_CONNECTIVITY). The pixel aspect ratio of the image (M_PIXEL_ASPECT_RATIO). Whether to produce separate results for each blob or for groups of blobs (M_BLOB_IDENTIFICATION_MODE). How many Feret angles are considered when calculating a Feret feature (M_NUMBER_OF_FERETS). Typically, the default value will be appropriate. Whether partially computed results should be returned if the processing operation is interrupted (M_RETURN_PARTIAL_RESULTS). Controlling the image lattice MIL represents images using a square lattice and considers adjacent pixels along the vertical or horizontal axis as touching. However, you can control whether two diagonally adjacent pixels are considered touching. Use MblobControl() with M_CONNECTIVITY to specify how the blob identifier image lattice should be interpreted. For example, the following is considered one blob if the lattice is set to M_8_CONNECTED, but two blobs if set to M_4_CONNECTED. Pixel aspect ratio When acquiring an image of a scene, each pixel represents some real distance both in width and in height. Ideally, this distance is the same in both directions, producing square pixels and allowing for accurate feature calculations. However, after digitization, it is quite common for a pixel to represent a different distance in each direction. In blob analysis, image distortions directly affect feature extractions. There are three ways of dealing with this problem: You can use the MIL Camera Calibration module to calibrate and correct your images. This works both for uniform and non-linear distortion. You can use MblobControl() with M_PIXEL_ASPECT_RATIO. This works only for uniform non-rotational distortion. You could use MimResize() to adjust the image to have a constant pixel aspect ratio. If you want to use the Camera Calibration module, you can use McalUniform() for uniform distortion, or McalGrid() or McalList() for any distortion. In these cases, you should correct the image using McalTransformImage() before using the Blob module if you require precise results. This is required because the module performs calculations in the pixel coordinate system even if the target is calibrated; results can be returned in either the pixel or relative coordinate system. The advantage of using this technique is that your target image is physically corrected. If your images only have uniform, non-rotational distortion, you can use MblobControl() with M_PIXEL_ASPECT_RATIO instead of calibration, to take into account the aspect ratio when calculating features. The ratio of a pixel's width to its height is called the pixel aspect ratio. For example, a pixel of equal width and height has a pixel aspect ratio of 1.0. The actual aspect ratio can be calculated using a simple procedure. Grab an image of a true circle or square and extract the M_FERET_X and M_FERET_Y features, which are enabled for calculation using MblobControl() with the M_BOX group of features. The relationship between these features represents the actual pixel aspect ratio to be used in calculations (M_FERET_Y / M_FERET_X). Note, all results are affected by the M_PIXEL_ASPECT_RATIO control type, including those that are just positions within the image. For example, to mark M_BOX_X_MIN on an image using a graphics function, such as MgraDots(), you must take the aspect ratio to which M_PIXEL_ASPECT_RATIO is set into account (in this case by dividing the returned result by the aspect ratio). However, when using MblobDraw() to draw features onto an image, the pixel aspect ratio is taken into account. Setting the blob identification mode and calculations on blobs Using MblobControl() with the blob identification mode setting (M_BLOB_IDENTIFICATION_MODE), you can control how blobs in the blob identifier image are grouped during calculations: All blobs are measured individually (M_INDIVIDUAL). All blobs are grouped together (M_WHOLE_IMAGE). Blobs which have the same label, or touching blobs with distinct labels, are grouped together (M_LABELED). Blobs which have the same label are grouped together and touching blobs with different labels are treated separately (M_LABELED_TOUCHING). When using the Blob Analysis module, you usually want to make feature calculations on each blob. For example, if you want to find the area of each cell in a tissue image, set the blob identification mode to M_INDIVIDUAL. Sometimes, however, you need calculations based on the entire image rather than individual blobs. For example, you might want to calculate the area of all the copper in a rock sample image. MIL simplifies your task by allowing you to group all foreground pixels together by setting the blob identification mode to M_WHOLE_IMAGE. Blobs in an image are treated as one blob and features are calculated for this grouped blob. If the blob identifier image is already binarized (for example, pixel values for an 8-bit image are either 0 or 0xff), you can set M_IDENTIFIER_TYPE to M_BINARY to calculate features faster. Blob identification mode M_LABELED allows you to do joint calculations on blobs with the same label value, and touching blobs with different labels. When using labeled mode, each blob must have a uniform pixel value. That is, all pixels in a blob must have the same intensity value. If the blobs that you would like to group do not have the same label, you can use MblobSelect() with M_MERGE to group blobs together and assign a common label to them. To treat touching blobs that have different labels as distinct, use the blob identification mode M_LABELED_TOUCHING. With this mode, you can perform calculations on individual blobs even though they are touching, provided each blob has a different label. When using M_LABELED or M_LABELED_TOUCHING, M_FOREGROUND_VALUE cannot be set to M_ZERO, and the blob identifier image cannot be binary (1-bit). M_LABELED is not supported when using MblobMerge(), which merges results of two separate blob result buffers into a single result buffer. M_LABELED_TOUCHING is not supported with the following: MblobCalculate(), when chain features are enabled (MblobControl() with M_CHAINS or M_ALL_FEATURES enabled). MblobDraw() with M_DRAW_BLOBS_CONTOUR, M_DRAW_HOLES_CONTOUR, or a combination of the two. MblobSelect() with M_MERGE. Returning partial results Using MblobControl() with M_RETURN_PARTIAL_RESULTS, you can control whether partial results of the blob calculation will be available if the computation is interrupted by one of the following conditions: The maximum number of blobs (M_MAX_BLOBS) has been processed. The timeout limit (M_TIMEOUT) is exceeded. Note that when partial results are requested and a timeout occurs, some results might not be available for certain blobs. Adjusting blob analysis processing controls Controlling the image lattice Pixel aspect ratio Setting the blob identification mode and calculations on blobs Returning partial results ",
      "wordCount": 1133,
      "subEntries": []
    },
    {
      "id": "UG_blob_Selecting_blobs",
      "version": null,
      "title": "Selecting blobs",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Selecting_blobs.htm",
      "text": " Selecting blobs Once all blobs are clearly identifiable by the Blob Analysis module, you are ready to perform calculations. However, in some cases, you will not want to make time-consuming feature extractions for every single blob in the blob identifier image. For example, you probably do not want to calculate features for blobs that are touching the edges of the image or that are noise artifacts. You might choose to preprocess these blobs out of your image, but you might lose a significant amount of information by doing so. In some other cases, some blobs might have been incorrectly segmented as two or more blobs. You would want to group those blobs together and calculate their features as one blob. You might also want to do a blob calculation on the whole image but excluding the noise particles. The MblobSelect() function deals with these cases. This function allows you to select (on the basis of calculations already made) a subset of blobs for which to make further calculations, and to group blobs with certain characteristics and consider them as one blob. When selecting a subset of blobs, your approach for selecting depends on whether you have few or many unwanted blobs. If you do not have too many unwanted blobs, it is usually faster to calculate all required features for all blobs. After doing this, use MblobSelect() to exclude or delete results obtained for blobs that do not meet your criteria. If you have many unwanted blobs, you will probably save time and memory by first calculating, for all blobs, only those features that allow you to distinguish between relevant and unwanted blobs. Then, exclude from future calculations (or delete altogether from the blob analysis result buffer) blobs that do not meet your criteria, using MblobSelect(). Finally, calculate all required features for remaining blobs using MblobCalculate(). If you are not able to exclude or delete a sufficient number of blobs using the second method, use the first. If the blobs were taken from a calibrated image, you can set the limits of your selection criteria in pixel units or world units. To set the units, use MblobControl() with M_INPUT_SELECT_UNITS. To group blobs that meet your criteria as one blob, use MblobSelect() with M_MERGE. Once grouped, the blobs are treated as one blob (a grouped blob) with a unique blob label. For example, if you want to calculate the area of the grouped blob, it will be the sum of the areas of the individual blobs within the group. Upon merging, only features that were calculated for all the individual blobs in the group are re-calculated for the new grouped blob; calculations are made using the results of the individual blobs in the group. In any case, you can make as many calls as necessary to MblobSelect() and MblobCalculate() to arrive at the set of blobs with the right characteristics. However, you must always give the same identifier and grayscale buffers to MblobCalculate() during this procedure. If you give different buffers or change the existing buffers in any way (for example, if you use MblobDraw() to erase blobs from the identifier image), all current results in the result buffer will be discarded the next time you call MblobCalculate(). In addition, all enabled features will be re-calculated for all blobs in the new identifier image. This means that you will have to restart the selection procedure. If you intend to calculate grayscale features during your analysis, you must include the grayscale image before starting your calculations. Selecting blobs ",
      "wordCount": 588,
      "subEntries": []
    },
    {
      "id": "UG_blob_Enabling_features_for_calculation",
      "version": null,
      "title": "Enabling features for calculation",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Enabling_features_for_calculation.htm",
      "text": " Enabling features for calculation The MIL Blob Analysis module can calculate a variety of different blob measurements or features, such as the area, perimeter, Feret diameter, and center of gravity of each selected blob. Although the MblobCalculate() function initiates the actual calculations, it is the specified context that determines which calculations are performed. When you first allocate the context using MblobAlloc(), a few features are enabled for calculation (for example, M_AREA). You must use the MblobControl() function with your Blob Analysis context to enable additional feature calculations. MblobCalculate() can calculate both binary and grayscale blob features. To calculate a binary feature, MblobCalculate() requires only a blob identifier image. To calculate a grayscale feature, you must also pass MblobCalculate() a grayscale image. The blob identifier image will identify the blobs, and the grayscale image will supply the actual blob pixel values. When you call MblobCalculate(), it scans the blob identifier image for blobs and then calculates the requested blob features. Even if only a few features are enabled for calculation, the overhead of scanning the image can be considerable. Therefore, it is usually more efficient to enable many features for calculation and make one call to MblobCalculate(), rather than to enable and calculate one feature at a time. Note, features that have already been calculated for the specified images will not be recalculated if you call MblobCalculate() again, unless any parameters of the calculation are changed. There are several considerations when enabling features for calculation: Before enabling a feature for calculation, you should take the blob shapes into consideration. Some feature calculations are more appropriate for certain blob shapes than for others. For example, some should be used for round blobs rather than long, thin ones, and vice versa. When trying to distinguish between two similar blobs, enabling certain features for calculation, rather than some other features for calculation that might also seem appropriate, might reveal a more notable difference. If two features allow you to come to the same conclusion, it is recommended that you enable the version that is calculated more quickly. For example, features derived from multiple Feret diameters tend to calculate relatively slowly, and grayscale calculations are considerably longer than binary ones. Note, for a visual representation of blobs that meet (or don't meet) certain criteria, you can use MblobDraw() or MblobLabel(), after calculating some features and calling MblobSelect(). This can fill blobs with their own label values (using MblobLabel()) or with a user-specified value (using MblobDraw() with M_DRAW_BLOBS to fill the blobs with the value, or with M_DRAW_BLOBS_CONTOUR + M_DRAW_HOLES_CONTOUR to only fill the borders of the blobs with the value). You can also use MblobDraw() to draw specific results in an image buffer or a 2D graphics list. For example, you can draw the blob's contours, holes, position, minimum and maximum Feret diameters, among other features. You can use a previously allocated 2D graphics context (see the 2D graphics context section of Chapter 26: Generating graphics) to control the drawing color, or use the default 2D graphics context (M_DEFAULT). You can draw into any supported MIL image buffer or a 2D graphics list. By drawing into a display's overlay buffer, or associating the 2D graphics list with the display, you can also annotate an image non-destructively. For more information, see the Annotating the displayed image non-destructively section of Chapter 25: Displaying an image. To get results, you can use MblobGetResult(). To specify a specific blob to MblobGetResult(), use the blob's label obtained from MblobGetLabel(), or the blob's index. The Blob Analysis module automatically calculates label values for included blobs when a call to MblobCalculate() is made. You can obtain the label value for a specific blob using MblobGetLabel(), with the blob's coordinate. If you exclude some blobs from MblobCalculate(), the labels of the excluded blobs can still be returned until they are deleted; once deleted, the blob label returned will be 0. When blob's are excluded or deleted, the index value will however be reassigned; that is, the index of blobs with indices greater than that of the excluded/deleted blob are reduced by one. This ensures that included blobs have consecutive indices. The results obtained from MblobGetResult() can be sorted in ascending or descending order, by a maximum of three features assigned as sorting keys. To specify a feature as a sorting key, you can use MblobControl() with M_SORTn, and specify the feature as the sorting key. You can then choose whether the feature is sorted in ascending or descending order with M_SORTn_DIRECTION. Replace n with 1, 2, or 3 to indicate the sorting precedence of the sorting key(s). The second and third sorting keys are only used to distinguish between blobs that have an identical value in the preceding key(s); therefore, a second or third sorting key is only used when the previous sorting key uses a discrete quantity value like M_NUMBER_OF_HOLES. Due to noise and discretization errors, positions and sizes of roughly identical objects might not give identical results. Enabling features for calculation ",
      "wordCount": 832,
      "subEntries": []
    },
    {
      "id": "UG_blob_Area_and_perimeter",
      "version": null,
      "title": "Area and perimeter",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Area_and_perimeter.htm",
      "text": " Area and perimeter Each pixel in your image represents a real width and height (for example, in millimeters). However, MblobCalculate() performs calculations and measurements (that represent a distance or area) in raw (uncalibrated) pixel units. By default, MblobCalculate() assumes that the width and height of the pixels are the same (that is, the pixel aspect ratio (width/height) equals 1.0); therefore, each pixel (P) is represented as follows: A pixel ratio of 1.0 implies that the retrieved area (M_AREA) of a single pixel blob is equal to 1 and the retrieved perimeter (M_PERIMETER) is equal to 4. When calculating the area and perimeter of a larger blob, the area would then equal the number of pixels in the blob (excluding holes), and the perimeter would equal the total number of pixel sides along the blob edges (including the edges of holes). Note, an allowance is made for the staircase effect that occurs in a digital image when representing diagonals and curves. For example, in the following blob (where F represents foreground pixels), the area is 10 and the perimeter is 14.242. When two diagonals intersect, as in the image below, the perimeter is calculated as the sum of the straight edges and of the diagonals (calculated as described above) with a correction of -1 for each intersection of diagonals. For example, in the following blob, the area is 11 and the perimeter is 17.656. If what is of more interest is the smallest area or smallest perimeter of the rectangular region that a blob occupies (bounding box), you can enable for calculation the M_MIN_AREA_BOX and M_MIN_PERIMETER_BOX group of features, respectively, using MblobControl(). For more information on bounding boxes, see the Finding the blob location and its bounding box section later in this chapter. You can also calculate an exact calculation, or an approximation, of the convex perimeter of the blobs using M_CONVEX_HULL_PERIMETER or M_CONVEX_PERIMETER respectively. These are enabled for calculation using MblobControl() with M_CONVEX_HULL and M_CONVEX_PERIMETER respectively. The convex perimeter is the perimeter of the convex hull (see below). The approximation of the convex perimeter (M_CONVEX_PERIMETER) is derived by taking the diameter of the blob (Feret diameter) at different angles. You can adjust the number of Feret diameters used for the calculation using the MblobControl() function with M_NUMBER_OF_FERETS. The greater the number of Feret diameters used, the more accurate the approximation. Note that the Feret diameters are calculated using a method which treats pixels as being round with a diameter of 1 instead of being square (see the Dimensions section later in this chapter). This can lead to results not matching the expected result. For example, when dealing with a single pixel blob, the result approaches 3.1416 (that is, Pi) which is the perimeter of a circle with a diameter of 1. When MblobControl() with M_PIXEL_ASPECT_RATIO has been set to anything other than 1.0, the aspect ratio is applied to the pixel width during calculations. Each pixel is now represented as: This affects all calculated features as if you had actually stretched the image (from the top-left corner in the X-direction only), by a factor equal to the pixel aspect ratio. We can no longer say that results are in \"pixel\" units. In fact, results are really in units of \"pixel height\" since the height is not affected by the aspect ratio. Area and perimeter ",
      "wordCount": 556,
      "subEntries": []
    },
    {
      "id": "UG_blob_Dimensions",
      "version": null,
      "title": "Dimensions",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Dimensions.htm",
      "text": " Dimensions Besides the area and perimeter, you might need to determine the dimensions of the blobs. Since blobs are not typically rectangular in shape, you will probably have to take the length (or diameter) of the blobs at various angles from the horizontal axis. This is actually one of the many definitions of the blob length, called the Feret diameter. Several Feret diameters are illustrated below. Note, the angle at which the Feret diameter is taken (relative to the horizontal axis) is specified as a subscript to the F. With MIL, you can calculate the Feret diameter at a specified angle by enabling it for calculation, using MblobControl() with M_FERET_GENERAL and then using M_FERET_GENERAL_ANGLE to specify the angle; use MblobGetResult() with M_FERET_GENERAL to retrieve the result after calculation (MblobCalculate()). To calculate the Feret diameter at 0° (horizontal Feret diameter) and at 90° (vertical Feret diameter), you could alternatively enable the M_BOX group of features for calculation using MblobControl(); after calculation, you can retrieve, among other features, M_FERET_X and M_FERET_Y, respectively, using MblobGetResult(). To determine the minimum, maximum, and average Feret diameters of the blob, enable the M_FERETS group of features for calculation, using MblobControl(); then, after calculation, you can retrieve the results using MblobGetResult() with M_FERET_MIN_DIAMETER, M_FERET_MAX_DIAMETER, and M_FERET_MEAN_DIAMETER, respectively. These diameters will be determined by testing the diameter of the blobs at several angles. Alternatively, you can set the range over which to calculate the Feret diameters (or other Feret-based features) using MblobControl() with M_FERET_ANGLE_SEARCH_START and M_FERET_ANGLE_SEARCH_END. You can use MblobControl() with M_NUMBER_OF_FERETS to change the default number of angles; these angles will start at 0° and increase in increments of 180°/n , where n is the number of Feret diameters. Increasing the number of angles that are tested increases the accuracy of the results, but also increases processing time. Note that, since memory usage increases with the number of Feret diameters, using a large number of Feret diameters in an image with many blobs might result in memory allocation errors. When the Feret is computed at 0° or 90°, the Feret diameter is equal to the exact length of the blob in that direction. However, when the Feret is computed at another angle, the Feret diameter is always smaller than the width of the blob in that direction. This is because pixels are considered circular. The approximation is at its worse at 45°. The relative difference between the Feret approximation and the exact length decreases as the blobs get bigger. The difference between the approximation and the exact length is shown in the image below. The maximum Feret diameter is not very sensitive to the number of angles; using 8 angles usually produces an accurate result. The minimum diameter, however, can be inaccurate for long thin blobs unless many angles are used. The angles at which the minimum and maximum Feret diameters were found can be retrieved using MblobGetResult() with M_FERET_MIN_ANGLE and M_FERET_MAX_ANGLE, respectively. In addition, you can retrieve the ratio of the maximum to minimum Feret diameter using the above function with M_FERET_ELONGATION. Although the Feret diameters provide a good approximation of the blob size, these features are not very good for long, thin blobs. For these, the following features, which can be enabled for calculation with MblobControl(), might provide better results: M_LENGTH: an extraction of the true length of a blob. M_BREADTH: an extraction of the true breadth of a blob. M_ELONGATION: the ratio of the length to the breadth. These features are derived from the area and perimeter, using the assumption that the blob area is equal to the [length x breadth] and the perimeter is equal to [2(length + breadth)]. These relations only hold if the length and breadth are constant throughout a blob. However, long, thin blobs generally satisfy this assumption, even if they are not straight. Note, since these features use only the area and perimeter, they are faster to calculate than Feret features. Dimensions ",
      "wordCount": 655,
      "subEntries": []
    },
    {
      "id": "UG_blob_Determining_the_shape",
      "version": null,
      "title": "Determining the shape",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Determining_the_shape.htm",
      "text": " Determining the shape Other useful features during classification are those that give you information about the blob shape. Two blobs can have similar sizes but different shapes because of a different number of holes, curves, or edges. For example, in the illustration above, the blobs have similar sizes, but can be distinguished by the shape of their holes. If you treat the holes as the actual blobs (set non-zero pixels as foreground pixels and zero pixels as background pixels), you can extract the differences in shape of the holes. Two features, enabled for calculation using MblobControl(), that can qualify the shape of these holes are: Compactness (M_COMPACTNESS). Roughness (M_ROUGHNESS). The compactness is a measure of how close all particles in the blob are from one another. It is derived from the perimeter and area. A circular blob is most compact and is defined to have a theoretical compactness measure of 1.0 (the minimum); more convoluted shapes have larger values. In practice, due to square pixel discretization, the minimum obtainable compactness is slightly above 1.0. The roughness is a measure of the unevenness or irregularity of a blob's surface. It is a ratio of the perimeter to the convex perimeter of a blob. Smooth convex blobs have a roughness of 1.0, whereas rough blobs have a higher value because their true perimeter is bigger than their convex perimeter. Although either of these features can be used in the classification process, compactness is faster to calculate since it is derived using only the area and perimeter. For a program that, among other things, distinguishes between nuts, bolts and washers by analyzing the compactness of their holes, see the Blob analysis example section later in this chapter. In some cases, you can also distinguish between blobs by determining the number of holes that they have (M_NUMBER_OF_HOLES). For example, you could distinguish between bolts and nuts in the BoltsNutsWashers.mim image by counting blob holes. However, this is not a very robust measure since a single noise pixel in a bolt blob would count as a hole. Determining the shape ",
      "wordCount": 347,
      "subEntries": []
    },
    {
      "id": "UG_blob_Finding_the_blob_location",
      "version": null,
      "title": "Finding the blob location and its bounding box",
      "subTitles": [
        "Points of the bounding box aligned with the pixel coordinate system",
        "Minimum-area and minimum-perimeter bounding box points",
        "Points with respect to the relative world coordinate system",
        "Chained pixels"
      ],
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Finding_the_blob_location.htm",
      "text": " Finding the blob location and its bounding box Finding the location of blobs in an image can sometimes be more useful than finding their shape or size. For example, if a robotic arm needs to pick up several items regardless of their type, it can use their location in an acquired image to determine their actual physical position. You can also use the blob location to determine if a blob touches any side of the image border. If there are any such blobs, you might want to adjust the camera's field of view so that all items are completely represented in the image, or you might want to exclude these blobs. Points of the bounding box aligned with the pixel coordinate system You can determine the blob's points of contact with the blob's bounding box aligned with the pixel coordinate system. To do so, enable the M_BOX, M_CONTACT_POINTS, and M_CENTER_OF_GRAVITY groups of features for calculation using MblobControl(). Use MblobGetResult() with the constants below to retrieve the corresponding point of contact after calculation. Note that for the blob in the image below, there are at least two possible ways to determine each of its contact points. This is because there is only one point of contact on each side of the blob's border. For example: Legend A1 (M_BOX_X_MIN, M_BOX_Y_MIN) A2 (M_BOX_X_MAX, M_BOX_Y_MIN) B1 (M_BOX_X_MIN, M_Y_MIN_AT_X_MIN) B2 (M_BOX_X_MAX, M_Y_MIN_AT_X_MAX) C1 (M_BOX_X_MIN, M_Y_MAX_AT_X_MIN) C2 (M_BOX_X_MAX, M_Y_MAX_AT_X_MAX) D1 (M_BOX_X_MIN, M_BOX_Y_MAX) D2 (M_BOX_X_MAX, M_BOX_Y_MAX) E1 (M_X_MIN_AT_Y_MIN, M_BOX_Y_MIN) OR (M_FIRST_POINT_X, M_FIRST_POINT_Y) E2 (M_X_MIN_AT_Y_MAX, M_BOX_Y_MAX) F1 (M_X_MAX_AT_Y_MIN, M_BOX_Y_MIN) F2 (M_X_MAX_AT_Y_MAX, M_BOX_Y_MAX) G (M_CENTER_OF_GRAVITY_X, M_CENTER_OF_GRAVITY_Y) In contrast, if there are multiple points of contact on one side of the blob border, each point of contact will be named differently, as shown in the image below. The center of gravity can be calculated in binary or grayscale mode. To calculate the latter, you must provide MblobCalculate() with a grayscale image. Minimum-area and minimum-perimeter bounding box points Besides points established from a blob's bounding box aligned with the pixel coordinate system, you can establish points from the minimum-area or the minimum-perimeter bounding box of the blob. To calculate the bounding box that has the least area, use the M_MIN_AREA_BOX group of features; whereas to calculate the bounding box that has the smallest perimeter, use the M_MIN_PERIMETER_BOX group of features. These groups of features are enabled for calculation using MblobControl(). Use MblobGetResult() with the following constants to retrieve them after calculation: Area Box Legend Perimeter Box Legend A1 (M_MIN_AREA_BOX_Xn, M_MIN_AREA_BOX_Yn) 1 A2 (M_MIN_PERIMETER_BOX_Xn, M_MIN_PERIMETER_BOX_Yn) 1 B1 (M_MIN_AREA_BOX_CENTER_X, M_MIN_AREA_BOX_CENTER_Y) B2 (M_MIN_PERIMETER_BOX_CENTER_X, M_MIN_PERIMETER_BOX_CENTER_Y) C1 M_MIN_AREA_BOX_WIDTH C2 M_MIN_PERIMETER_BOX_WIDTH D1 M_MIN_AREA_BOX_HEIGHT D2 M_MIN_PERIMETER_BOX_HEIGHT E1 M_MIN_AREA_BOX_ANGLE E2 M_MIN_PERIMETER_BOX_ANGLE 1 n stands for an integer from 1 to 4. Note that the width of the box is always the longer of the two sides. The angle of the minimum-area or minimum-perimeter bounding box is always measured from the X-axis to the side from which the width of the minimum-area or minimum-perimeter box is measured. Points with respect to the relative world coordinate system When working with calibrated images, you can retrieve the above-mentioned points with respect to the relative coordinate system, by calling MblobControl() with M_RESULT_OUTPUT_UNITS set to M_WORLD. However, in this case, the above-mentioned points are calculated in the pixel coordinate system and then the coordinates of these points are converted to the relative coordinate system. To calculate the blob's bounding box and contact points in the relative coordinate system, you must enable the calculation of the M_WORLD_BOX group of features using MblobControl(); then, use MblobGetResult() with the following constants to retrieve them after calculation: Legend A1 (M_WORLD_BOX_X_MIN, M_WORLD_BOX_Y_MIN) A2 (M_WORLD_BOX_X_MAX, M_WORLD_BOX_Y_MIN) B1 (M_WORLD_BOX_X_MIN, M_WORLD_Y_AT_X_MIN) B2 (M_WORLD_BOX_X_MAX, M_WORLD_Y_AT_X_MAX) C1 (M_WORLD_BOX_X_MIN, M_WORLD_BOX_Y_MAX) C2 (M_WORLD_BOX_X_MAX, M_WORLD_BOX_Y_MAX) D1 (M_WORLD_X_AT_Y_MIN, M_WORLD_BOX_Y_MIN) D2 (M_WORLD_X_AT_Y_MAX, M_WORLD_BOX_Y_MAX) Chained pixels You can obtain the coordinates of pixels bordering blobs or delimiting holes in blobs, in a counterclockwise or clockwise direction, respectively. These pixels are referred to as chained pixels. To calculate these pixels, enable the M_CHAINS group of features for calculation using MblobControl(). You can use the chained pixel coordinates to create a chain code. A chain code is a directional code that records an object's boundary as a discrete set of vectors, where each vector points to the next pixel in the chain. Chained pixels always form a closed chain. This implies that the starting pixel in the chain is also the closing one. If your blob has regions which are 1 pixel wide, these pixels are chained twice, once in the forward direction and then in the opposite direction. In the diagram below, the thick lines illustrate pixels that are chained twice. The diagram also illustrates chained pixels of a blob in an 8 and 4-connected lattice, where the solid lines illustrate chained pixels in an 8-connected lattice, and the dotted lines illustrate how chained pixels deviate in a 4-connected lattice. Also, note that the blob's outermost chain is identified as index 1. Chains that delimit holes in blobs are identified by subsequent indices. The M_CHAINS feature group enables five separate chain features for calculation. This allows you to retrieve the following feature results using MblobGetResult(): M_TOTAL_NUMBER_OF_CHAINED_PIXELS, which retrieves the total number of chained pixels. M_NUMBER_OF_CHAINED_PIXELS, which retrieves the total number of chained pixels for each blob or a specified blob. M_CHAIN_INDEX, which assigns an index to each chained pixel, for every chain within a blob. M_CHAIN_X and M_CHAIN_Y, which retrieves the X- and Y-coordinates of all chained pixels within a blob respectively. When retrieving results for chain features, get the results for the number of chained pixels, in total or in a particular blob first (M_TOTAL_NUMBER_OF_CHAINED_PIXELS or M_NUMBER_OF_CHAINED_PIXELS respectively). This allows you to allocate an array that is large enough for the other chain results. For the blob shown above, you would get the following results: Chain index Chain-X Chain-Y 1 4 2 1 4 3 1 4 4 1 4 5 ... ... ... 2 5 5 2 6 5 2 7 5 2 8 5 As mentioned, blobs with holes have multiple chains. To determine the chain to which a pixel coordinate (M_CHAIN_X and M_CHAIN_Y) belongs, use MblobGetResult() with M_CHAIN_INDEX. Finding the blob location and its bounding box Points of the bounding box aligned with the pixel coordinate system Minimum-area and minimum-perimeter bounding box points Points with respect to the relative world coordinate system Chained pixels ",
      "wordCount": 1049,
      "subEntries": []
    },
    {
      "id": "UG_blob_Moments",
      "version": null,
      "title": "Moments",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Moments.htm",
      "text": " Moments Using the Blob Analysis module, you can also calculate the moments used to find the center of gravity, as well as other grayscale and binary moments. To calculate a moment of a specified order in X and Y (general moment), enable the M_MOMENT_GENERAL feature for calculation using MblobControl(); then specify the X and Y order of the moment to calculate using MblobControl() with M_MOMENT_GENERAL_ORDER_X and M_MOMENT_GENERAL_ORDER_Y, respectively. Select whether to calculate the ordinary or the central moment using MblobControl() with M_MOMENT_GENERAL_MODE. Central moments use coordinates that are relative to the center of gravity of the blob, and therefore are independent of a blob's position within the image; whereas, ordinary moments are affected by the blob position because they use coordinates relative to the top-left corner of the image. Use MblobGetResult() with M_MOMENT_GENERAL to retrieve the result. You could alternatively enable the calculation of the M_MOMENT_FIRST_ORDER, M_MOMENT_SECOND_ORDER and/or M_MOMENT_THIRD_ORDER group of features for calculation using MblobControl(). These groups of features include only the more common moments (for example, MblobGetResult() with M_MOMENT_X0_Y1, M_MOMENT_X0_Y2 or M_MOMENT_X0_Y3). These common moments are calculated faster than the general moment. You could also enable the calculation of hu moment invariants using MblobControl() with M_MOMENT_THIRD_ORDER. Hu moments are a set of seven moments calculated using central moments. Hu moments are invariant to translation, rotation and scaling. Moments ",
      "wordCount": 222,
      "subEntries": []
    },
    {
      "id": "UG_blob_Features_related_to_depth_maps",
      "version": null,
      "title": "Features related to depth maps",
      "subTitles": [
        "Features of depth maps",
        "Examples"
      ],
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Features_related_to_depth_maps.htm",
      "text": " Features related to depth maps If you pass MblobCalculate() a grayscale image that is a fully corrected depth map, the function can calculate depth map related features for each blob, if the features are enabled for calculation. A depth map is an image where the grayscale value of a pixel represents its depth in the world; it is fully corrected if it accurately represents the height and shape of portrayed objects, and meets the following constraints: Calibrated image with a constant pixel size. McalControl() with M_GRAY_LEVEL_SIZE_Z is not set to M_INVALID_SCALE. The image below shows a sample depth map. You can verify that an image buffer contains a fully corrected depth map using McalInquire() with M_DEPTH_MAP. To ignore invalid pixels in the depth map, associate the image with a region of interest (ROI) that identifies the valid pixels. To do so, use MbufSetRegion() with M_RASTERIZE_DEPTH_MAP_VALID_PIXELS. You can also specify an image mask to further limit the ROI to pixels that are non-zero in the image mask buffer. The depth map must be fully corrected. Features of depth maps Before analyzing a depth map, you must enable the features that you want to calculate using MblobControl() with M_DEPTH_MAP_.... You can analyze the following depth map features with the Blob Analysis module. The maximum elevation of the blob (M_DEPTH_MAP_MAX_ELEVATION). The mean elevation of the blob (M_DEPTH_MAP_MEAN_ELEVATION). The minimum elevation of the blob (M_DEPTH_MAP_MIN_ELEVATION). The difference between the maximum and minimum elevations (M_DEPTH_MAP_SIZE_Z). The volume of the blob (M_DEPTH_MAP_VOLUME). The image below shows the minimum and maximum elevation of the blob in the depth map above. Examples The example below analyzes the volumes of blobs in a sample depth map. blobdepthmap.cpp To run this example, you can use the Matrox Example Launcher in the MIL Control Center. Features related to depth maps Features of depth maps Examples ",
      "wordCount": 306,
      "subEntries": []
    },
    {
      "id": "UG_blob_Location_length_and_number_of_runs",
      "version": null,
      "title": "Location, length and number of runs",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Location_length_and_number_of_runs.htm",
      "text": " Location, length and number of runs A run is defined as a horizontal series of consecutive foreground pixels. The Blob Analysis module can be used to calculate run-related information such as the length of a run, and the X and Y-coordinates of each run in a specific blob. Enable these features for calculation with the M_RUNS group of features using MblobControl(). To retrieve the run information, use MblobGetResult(). The retrievable run information includes the total number of runs for each blob (M_NUMBER_OF_RUNS), or for all included blobs (M_TOTAL_NUMBER_OF_RUNS), and the length and coordinates of each run in a specific blob (M_RUN_...). Location, length and number of runs ",
      "wordCount": 109,
      "subEntries": []
    },
    {
      "id": "UG_blob_Blob_reconstruction",
      "version": null,
      "title": "Blob reconstruction",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Blob_reconstruction.htm",
      "text": " Blob reconstruction Although the Blob Analysis module is used mainly for blob feature calculation purposes, some of the Mblob...() functions can be used to perform blob image reconstruction. An example of this is the MblobReconstruct() function. Blob reconstruction allows you to remove small particles in an image without distorting the shape of the remaining blobs, which can occur when successive erosion or dilation operations are performed on an image. Using the different operations of the MblobReconstruct() function, you can: Reconstruct blobs from a seed image. The M_RECONSTRUCT_FROM_SEED operation copies to the destination buffer only those blobs that have a corresponding seed pixel in the seed buffer. Blobs that are not seeded are replaced according to the selected processing mode. Note that when performing this operation in grayscale processing mode and with M_FOREGROUND_ZERO set, blobs in the source image which are not seeded are filled with the average grayscale value of the background. Delete blobs that touch a border of the image. The M_ERASE_BORDER_BLOBS operation copies only those blobs that do not touch the border to the destination buffer. Note that when performing this operation in grayscale processing mode and with M_FOREGROUND_ZERO set, border blobs are filled with the average grayscale value of the background. Fill holes in blobs. The M_FILL_HOLES operation copies the source buffer to the destination buffer, filling those blobs that contain holes according to the selected processing mode. Holes that touch the image border are not considered to be holes. Note that when performing this operation in grayscale processing mode, the holes are filled with the average grayscale value of the blob. Extract holes from blobs. The M_EXTRACT_HOLES operation copies only the holes within the blobs found in the source buffer. Holes that touch the image border are not considered to be holes. Note that when performing this operation in grayscale processing mode, the copied blob holes are filled with the average grayscale value of the blob in the source buffer. Also, when using the grayscale mode with M_FOREGROUND_ZERO set, the blobs are filled with the average grayscale value of the background. Finally, you can perform other types of blob reconstruction by calling specific MIL functions, one after the other. For example, to fill all blobs with a required value, use MblobSelect() in conjunction with MblobDraw() and/or MblobLabel(). You can use MblobLabel() to fill the blobs with their label values. You could use M_DRAW_BLOBS to fill the blobs with a user-specified value. Alternatively, you could use M_DRAW_BLOBS_CONTOUR + M_DRAW_HOLES_CONTOUR to only fill the borders of the blobs with the user-specified value. Blob reconstruction ",
      "wordCount": 428,
      "subEntries": []
    },
    {
      "id": "UG_blob_Merging_results",
      "version": null,
      "title": "Merging results",
      "subTitles": [
        "A simple merge",
        "Border blobs",
        "Inclusion state",
        "Other remarks"
      ],
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Merging_results.htm",
      "text": " Merging results In some cases, you might need to merge results from previous blob analysis calculations. For example, this might be required in an application where a line-scan camera captures a series of images of a continuous stream of rice falling off a conveyor belt as shown below. When grabbing images of the continuous stream, some objects might be split between two images. Performing blob analysis operations on these images produces erroneous results for these objects since an object split between two images is considered as two separate blobs. Results for one portion of the object will be in one result buffer and results for the other portion will be in another result buffer. To obtain valid results for these objects, you would need to merge the results of the objects that are split between two result buffers. You can use MdigProcess() to grab sequential frames of the continuous stream into a list of image buffers (or child buffers of a large parent buffer), perform the required blob analysis operation on the frames as they are being grabbed, and store the results in different blob analysis result buffers. You can then merge the results from the required result buffers using MblobMerge(). MblobMerge() merges two source result buffers at a time as if they were taken from two vertically adjacent child buffers of one image. By merging the result buffers as such, the destination result buffer uses the coordinate system of the first result buffer and positional results from the second result buffer are translated in the Y-direction to take into account this coordinate system change. In addition, border blobs that would touch if they were in one image are grouped into one grouped blob, assigned a single label, and recalculated as if the grouped blob were one blob. The merged results can be copied or moved (depending on the ControlFlag parameter of MblobMerge()) into a destination result buffer. Call MblobMerge() function as many times as necessary to merge the results of all the required result buffers to obtain an ultimate blob analysis result buffer for your continuous stream. A simple merge A simple merge operation is illustrated below. In this example, the area, perimeter, and center of gravity of blobs in two images have been calculated. After merging the results, the area and perimeter remain the same, but the center of gravity is recalculated with respect to the coordinate system of the destination result buffer. Also note that the labels of the blobs are changed after the merge to properly differentiate the blobs in the merged result buffer. The following animation demonstrates the new coordinates and center of gravity for each blob when images are merged. Border blobs Most probably, you will have border blobs in your images that would touch if they were in one image. When merging results, these blobs are grouped into one grouped blob, assigned a single label, and recalculated as if the grouped blob were one blob. For example, in the illustration below, border blob 2 in image A and border blob 1 in image B have separate results before the merge. After the merge, however, these border blobs are considered as one blob with its own results in the new coordinate system. In the event that different blob analysis calculations are performed on the two images, only features that were calculated for all the individual blobs in the grouped blob are recalculated, and these are recalculated using the results of the individual blobs in the group. This case is illustrated below. The area and center of gravity are computed for image A, but the perimeter and center of gravity are computed for image B. Upon merging the results, only the center of gravity is computed for the grouped blob (blob 2). Note that trying to retrieve a result in the destination result buffer (using MblobGetResult()) which is not available generates an error. Inclusion state In most cases, the inclusion state of the blobs remains the same after the merge. Consider the example below. The included blobs remain included after the merge, and the excluded ones remain excluded after the merge. If an included border blob is grouped with an excluded blob, the inclusion state of the merged blob is undetermined, as illustrated below. For this reason, it is not recommended that you use the merge operation under these circumstances. Note that after merging the results, you can perform a MblobSelect() operation to further include or exclude blobs in your destination result buffer, but if you perform an MblobCalculate() operation after the merge, all the results in the destination result buffer will be discarded. Other remarks For the merge operation to work properly, the results in the source result buffers must satisfy some constraints. The results in the source result buffers must have been calculated by a context that: Has the same run information saving mode (M_SAVE_RUNS set to M_ENABLE or M_DISABLE). Has the same pixel aspect ratio (M_PIXEL_ASPECT_RATIO). Has the same lattice (M_CONNECTIVITY). Has the same blob identification mode (M_BLOB_IDENTIFICATION_MODE). If the blob result buffers have M_BLOB_IDENTIFICATION_MODE set to M_LABELED, they cannot be merged. Has the same number of Ferets (M_NUMBER_OF_FERETS). Note that if you enable the calculation of a specified moment in the context (using MblobControl() with M_MOMENT_GENERAL) and M_SAVE_RUNS is disabled, M_MERGE will not be able to perform the moment calculation. Furthermore, if you specify a sorting key for result retrieval, the sorting order will not be respected after the merge. Merging results A simple merge Border blobs Inclusion state Other remarks ",
      "wordCount": 922,
      "subEntries": []
    },
    {
      "id": "UG_blob_Blob_analysis_example",
      "version": null,
      "title": "Blob analysis example",
      "subTitles": null,
      "location": "MIL UG P03: 2D processing and analysis",
      "pageURL": "content\\UserGuide\\blob\\Blob_analysis_example.htm",
      "text": " Blob analysis example The following illustrates the source image before and after binarization and noise removal operations: The example below binarizes an image, determines the center of gravity for each blob, and counts the number of bolts, nuts and washers. Note, the binarizing step produces a considerable number of spurious blobs and holes, so some processing is performed to clean up the blob identifier image before doing any calculations. mblob.cpp To run this example, use the Matrox Example Launcher in the MIL Control Center. Blob analysis example ",
      "wordCount": 89,
      "subEntries": []
    }
  ]
}]